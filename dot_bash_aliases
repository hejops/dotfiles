# shellcheck shell=bash
# vim:ft=bash
# if possible, this file should remain under 1000 LOC.

# autostart {{{

[[ -f /tmp/verse.json ]] && [[ -s /tmp/verse.json ]] &&
	ps --pid "$PPID" | grep -Fq wezterm &&
	< /tmp/verse.json jq -r '.votd | .reference, .content' |
	sed -e 's/<[^>]*>//g' |
		fold -w 65 -s

# }}}
# aliases {{{

alias dr=discogs_rate
alias ex=extract
alias gm=getmail
alias lc=leetcode.py # shadows lc binary (who?)
alias mb=musicbrainz
alias met=metronome
alias ns=notify-send
alias trk=trackratings.py
alias tt=taptempo
alias tz=trizen # if gpg fail, gpg --recv-keys <key>
alias wd=waitdie
alias xo=xdg-open

alias rab="exec yazi \"\$HDD/books\""
alias rad="exec yazi \"\$SLSK/complete\"" # TODO: investigate `ya pub`
alias rag="exec yazi \"\$HDD/guitar\""
alias ram="exec yazi \"\$MU\""
alias rat="exec yazi \"\$HDD/torrent\" \"\$HDD/movies\""

# alias csv="python -c 'import sys; import pandas; print(pandas.read_csv(sys.argv[1]))'"
# alias da="~/disq/disq -artist"
# alias lock="[[ -d /sys/class/power_supply/BAT0 ]] && systemctl suspend && slock"
# alias md="\$EDITOR -c 'set ft=markdown'"
# alias n="NO_COLOR=1 node --import=tsx"
alias au="audacious -H"
alias bh="vb -b"
alias cam="ls /dev/video* && mpv --fs av://v4l2:/dev/video0 --profile=low-latency --untimed && exit" # TODO: handle >1 video device (just increment n until file not exist)
alias cdnp="cd \"\$(files mpv | grep mp3 | largs dirname)\""
alias ci="chromium --incognito"
alias colt="column -t -s$'\t'" # align tab-containing output
alias cpu="top -b -n1 -o %CPU | grep -m10 \$USER"
alias ctz="sudo timedatectl set-timezone \$(timedatectl list-timezones | grep / | fzf)" # TODO: geolocate
alias cv="\$EDITOR ~/cv/src/index.tex"
alias dA="dc artist:"
alias datez='date -u +%FT%TZ' # utc (i.e. ignore current timezone)
alias dc="discogs_collection filter"
alias dt="discogs_collection top"
alias fzh="fzf --height=~33% --reverse" # - and ~ are not equivalent
alias li="chromium --incognito 'https://www.linkedin.com/notifications/?midToken=AQECUGJ6GKhRSg' & exit"
alias mem="top -b -n1 -o %MEM | grep -m10 \$USER"
alias or="cd ~/gripts/oar && time ./oar && waitdie mpv && vol --auto && mpv --profile=bcx ./out && rm -rI ./out ; kp"
alias pq="~/plaque/plaque"
alias synctime="sudo ntpd --quit --panicgate"
alias tf="waitdie con; fix_tags"
alias trizen="trizen --aur-results-sort-by=votes --aur-results-sort-order=ascending"
alias tx="tectonic -X"
alias tz=trizen # if gpg fail, gpg --recv-keys <key>
alias y="bash ~/gripts/disq/ytm.sh"

# cd ~/gripts/oar || :
# [[ ! -d ./out ]] && time ./oar
# waitdie mpv
# vol --auto
# mpv --profile=bcx ./out
# rm -rI ./out

# }}}
# frequent {{{

da() {
	if [[ $# -eq 1 ]]; then
		~/disq/disq -artist "$1"
	else
		~/disq/disq
	fi
}

cm() {
	if [[ $# -eq 0 ]]; then
		chezmoi cd
	else
		chezmoi "$@"
	fi
}

bx() { [[ $# -gt 0 ]] && bash -x "$@"; }

replace() {
	_in_git_repo || return

	# check correct rep binary (not the lisp thing)
	if ! command -v rep | grep -Fq .cargo; then
		return
	fi

	search=$1
	replace=$2
	_rg() {
		# --hidden will cause .git to be included!
		rg --hidden --glob='!.git/**' "$@"
	}

	if ! _rg -q -- "$search"; then
		echo "Pattern not found"
		return
	fi

	# note: backreferences use $1, not \1
	_rg --line-number -- "$search" | rep -- "$search" "$replace"
	read -r -p 'OK?' || return
	_rg --line-number -- "$search" | rep --write -- "$search" "$replace"

	git diff
}

sd() {
	: shutdown
	# uptime | grep hour || return/reboot

	waitdie mpv pacman curl
	killall firefox

	# pgrep -u $USER cron

	if pgrep nicotine; then
		pid=$(waitdie -s nicotine)
		[[ -n $pid ]] && waitdie -w nicotine
	fi
	# pkill nicotine
	# TODO: if new day (morning), just return
	echo "Shutting down..."
	sleep 3
	# pulseaudio -k
	shutdown now
}

rt() {
	: pass an array of relative paths to tagfix
	# note: dead symlinks are still displayed as if they exist

	larr() {
		# like xargs, but takes a single multi-line arg and turns it into an array
		mapfile -t args < /dev/stdin
		[[ -z ${args[*]} ]] && return # mimic xargs -r
		exec "$1" "${args[@]}" < /dev/tty
	}

	fzf --multi --reverse --preview="ls \"$MU\"/{}" < ~/.config/mpv/library |
		prepend "$MU/" |
		larr fix_tags

}

# }}}

# git {{{

alias b=git_branch # i could <leader>gB, but changing branch means context switching and probably closing vim anyway
alias bb=gb
alias cr=git_root
alias s=git_status # could be ported to vim maybe

# discouraged due to double index keypresses: gt gf gb

# alias gr=git_root
alias gl=git_log
alias gs=git_status

# alias gdnw="git diff --color-words --no-index"
alias g,=gpl # gpl is horrific to type
alias g.=gp
alias gC="git reset --soft HEAD~1"  # un-commit, but leave changes
alias gCH="git reset --hard HEAD~1" # un-commit, and undo changes (destructive!)
alias ga="git add"
alias gap="git add --patch"                      # i need to figure out how to do this in vim, because going backwards is hell
alias gdn="git diff --no-index"                  # https://stackoverflow.com/a/17433969 -- TODO: handle symlinks
alias gdnc="git diff --color-words=. --no-index" # diff by char; may be replaced with delta
alias gig="\$EDITOR \$(_get_repo_root)/.gitignore"
alias gp="git push"
alias gpl="git pull"
alias gu=gun
alias gun="git checkout --" # discard all local changes ("undo")

_get_repo_root() { git rev-parse --show-toplevel 2> /dev/null; }
_in_git_repo() { git rev-parse --is-inside-work-tree > /dev/null 2> /dev/null; }

_gmaster() {
	: get default branch, e.g. master
	# https://stackoverflow.com/a/44750379
	# default_branch=$(git symbolic-ref refs/remotes/origin/HEAD | sed 's|^refs/remotes/origin/||')
	git symbolic-ref refs/remotes/origin/HEAD 2> /dev/null | cut -d/ -f4
}

v() {
	git ls-files . |
		\xargs -d '\n' ls -1t |
		fzf -m --prompt="$(git branch --show-current): " \
			--height=~100% --reverse --preview-window='right,50%,border' |
		xargs nvim -p
}

# shellcheck disable=SC2120
gls() { git ls-files "${1:-.}"; }

git_root() {
	if _in_git_repo; then
		cd "$(_get_repo_root)" || :
	elif [[ -n $REPO ]]; then
		cd "$REPO" || :
	fi
}

gA() {
	: un-add, unstage
	# not sure which command i run more often
	set -x
	git restore --staged "$@" \
		2> /dev/null || # committed; without --staged, changes are discarded!
		git reset "$@"  # not committed yet
	set +x
}

gb() {
	: switch to new branch, or existing branch

	# no remote branches
	default_local_branch=$(_gmaster) || :
	current_local_branch=$(git branch --show-current)

	if [[ $# -eq 0 ]]; then
		if [[ $default_local_branch == "$current_local_branch" ]]; then
			echo "Already on $default_local_branch"
		else
			# func retval is not propagated to parent
			git checkout "$default_local_branch" || return 1
			timeout 30 git pull
		fi
	else

		# generally, new branches should target master. however, this
		# may not always be the case, so accept an optional 2nd arg to
		# specify target branch (should be current)
		if ! git checkout "${2:-$default_local_branch}"; then
			return 1
		fi

		timeout 30 git pull || return

		# existing remote branch > create local branch > existing local branch
		if
			git branch -r | grep "origin/$1"
		then
			# note: git hook stdout cannot be suppressed
			echo "Switching to remote branch $1"
			git switch "$1" || return 1

		elif git switch --create "$1"; then
			:

		else
			# should be infallible?
			git switch "$1" || return 1

		fi
	fi

}

git_branch() {
	# https://stackoverflow.com/a/1441062
	# --pretty=format:'%h%x09%an%x09%ad%x09%s' # no color
	# TODO: include date/author, but preserve color

	_in_git_repo || return
	if [[ $(git branch | wc -l) -eq 1 ]]; then
		echo "No other branches; create one with gb <branch>"
		return
	fi

	# TODO: handle master..master?
	prv_cmd="echo {} | sed -r 's/^[ *]+//; s/^/$(_gmaster)../' | xargs git log --oneline --color=always"
	branch=$(git branch --sort=-committerdate |
		fzf --preview="$prv_cmd" --preview-window='right,80%,border' --ansi |
		sed -r 's/^[ *]+//')
	[[ -z $branch ]] && return
	gb "$branch"
}

gbd() {
	: prune local branches that no longer exist on remote -- unstaged changes will be lost!
	# https://stackoverflow.com/a/46192689
	git branch -vv |
		grep ': gone]' |
		grep -v "\*" |
		awk '{ print $1; }' |
		xargs -r git branch -D
}

# gpick() {
# 	: cherry pick commit from other branch
#
# 	prv_cmd="echo {} | cut -d' ' -f1 | xargs git show --color=always"
# 	sha=$(git log --branches --remotes --tags --oneline --decorate |
# 		fzf --preview="$prv_cmd" --preview-window='right,60%,border' --ansi |
# 		awk '{print $1}')
#
# 	# https://stackoverflow.com/a/29788254
# 	[[ -n $sha ]] && git show "$sha" | git apply -
# }

_git_log_fzf() {
	_in_git_repo || return
	prv_cmd="echo {} | cut -d' ' -f1 | xargs git show --color=always"

	args=()

	if [[ -f $1 ]] || [[ -d $1 ]]; then
		args+=("$@")
		prv_cmd="echo {} | cut -d' ' -f1 | xargs -I{} git show --color=always {} $1" # restrict diff to selected file/dir
	elif
		# other dev branch
		[[ $# -eq 1 ]] &&
			git branch --remote | grep -Pq "^  origin/$1$"
	then
		git pull > /dev/null 2> /dev/null
		args+=("origin/$1")
	elif
		m=$(_gmaster) &&
			[[ $(git branch --show-current) == "$m" ]]
	then
		: on master
	elif [[ -n $m ]]; then # dev branch
		args+=("$m...HEAD")
	else
		: no remote yet
	fi

	# there is nothing to see in merge commits
	git log --oneline --no-merges "${args[@]}" |
		fzf -m --preview="$prv_cmd" --preview-window='right,60%,border' --ansi
}

git_log() {
	: browse git log, showing each commit\'s diff in fzf preview
	_git_log_fzf "$@" | awk '{print $1}' | xargs git show
}

grev() {
	_git_log_fzf "$@" | awk '{print $1}' | xargs git revert
}

# gsdel() {
# 	: show last state of a deleted file
# 	# https://stackoverflow.com/a/19727752
# 	f=$1
# 	git show "$(git rev-list --max-count=1 --all -- "$f")^:$f"
# }

gS() {
	: like gs+gl, for files to stage/commit

	# # porcelain v1 is -always- relative to repo root, which makes parsing harder
	# files=$(git status --porcelain)

	# https://git-scm.com/docs/git-status#_changed_tracked_entries
	# $2 is more useful for tracked files (since it more closely maps to v1
	# labels), but for untracked files this duplicates the file path, so we
	# stick to $1
	# HACK: i have no idea how to 'return' multiple columns inside a
	# ternary, so concat with a space as an ugly workaround
	files=$(git status --porcelain=2 | awk '{print ($1=="?") ? $1" "$NF : $2" "$NF}')
	# note: untracked files have no diff
	prv_cmd="echo {} | awk '{print \$NF}' | xargs git diff --color=always"
	sel=$(<<< "$files" fzf --multi --reverse --preview="$prv_cmd" --preview-window='right,60%,border' --ansi)
	echo "$sel" |
		grep -P '^\?' | # add untracked files first
		awk '{print $NF}' |
		xargs git add
	echo "$sel" | awk '{print $NF}' | xargs git commit -v
}

# gac() {
# 	: append ALL changes to most recent unpushed commit
# 	git add "$@"
# 	git commit --amend --no-edit
# }

gapc() {
	git add --patch "$@"
	git commit --amend --no-edit
}

gcf() {
	: make a new commit to be squashed with an earlier one

	# https://jordanelver.co.uk/blog/2020/06/04/fixing-commits-with-git-commit-fixup-and-git-rebase-autosquash/
	sha=$(_git_log_fzf . | cut -d' ' -f1)
	[[ -z $sha ]] && return

	# --fixup associates a new commit with an existing commit so that when
	# you do an interactive rebase, you don't have to re-order any commits
	# in order to squash them. And you don't have to change any commit
	# messages
	git commit --fixup "$sha" "$@"

	# TODO: not sure what to do yet when unstaged changes are present

	# with no arg, defaults to curr branch (NEVER use gmaster; to avoid
	# losing work, git rebase --abort immediately)
	# is -i necessary?
	git rebase -i --autosquash || gC
}

gc() {

	if [[ $# -gt 0 ]]; then

		# 1. specified files, but excluding untracked files
		# note: this loop commits renamed files, but does not commit
		# their old names
		arr=()
		for f in "$@"; do
			[[ ! -f $f ]] && continue
			git ls-files | grep -q "$(basename "$f")" && arr+=("$f")
		done

		git commit -v "${arr[@]}"

	elif
		# 2a. file(s) that have been renamed/deleted
		git status --porcelain | grep -Pq '^R.+ -> '
	then
		pushd "$(_get_repo_root)" || return
		git status --porcelain |
			grep -P '^R' |
			sed 's/^R[^ ]* //; s/->//' | # very iffy
			# ideally, i want this (to avoid pushd), but xargs cannot be used on func
			# xargs prepend "$(get_repo_root)"/ |
			# realpath --relative-to=.
			xargs git commit -v
		popd || return

	elif
		# 2b. file(s) that have been renamed/deleted
		git status --porcelain | grep -Pq '^(R | D)'
	then
		git status --porcelain | grep -P '^(R | D)' |
			awk '{print $2}' | # iffy
			xargs git commit -v

	elif
		# 3. all staged changes
		# [git diff] "exits with 1 if there were differences"
		! git diff --staged --diff-filter=AMD --quiet
	then
		git commit -v

	else
		# 4. all files that have changed in the current dir
		git diff --name-only |
			prepend "$(_get_repo_root)/" |
			grep "$PWD" |
			grep -v .gitignore |
			xargs git commit -v

	fi

}

git_status() {
	# 1. changed files (twice: porcelain, then diff stat)
	# 2. untracked files
	# 3. current number of staged commits

	# Nothing staged. Current stat:
	#
	#  sqlc/artists.sql.go | 1 +
	#  schema.sql          | 2 +-
	#  queries/artists.sql | 4 ++--
	#  main.go             | 5 +++++
	#
	# Your branch is ahead of 'origin/master' by 2 commits.

	_in_git_repo || return

	if
		# new repo
		git status | grep 'No commits yet'
	then
		echo "Files:"
		echo
		git ls-files --others --exclude-standard
		return
	fi

	# shellcheck disable=SC2164
	[[ $# -eq 1 ]] && [[ -d $1 ]] && pushd "$1" > /dev/null

	# 1

	# note: colors are lost when piping, but sort is more useful than color
	if
		# git diff only diffs unstaged files
		diffs=$(
			git diff --stat . | # generally, i only want to see the diff stat for current dir
				grep -F '|' |      # ignore summary line
				sort -n -k3        # most changes last (more useful in short terminals)
		)
		[[ -n $diffs ]]
	then
		: no changes staged yet
		# { git status --porcelain | grep -Fv '??'; } 2> /dev/null
		echo "Nothing staged. Current stat:"
		echo
		echo "$diffs"

	elif
		files=$(git status --porcelain |
			# grep '^A' | # only added files!
			grep -Fv '??' |
			awk '{print $NF}' |
			# make paths absolute (default: relative to root)
			prepend "$(_get_repo_root)/" |
			# then relativise to cwd
			largs realpath --relative-to=. 2> /dev/null) #&&
		[[ -n $files ]]
	then
		: diffing staged files

		echo "Staged:"
		echo
		<<< "$files" \xargs git diff --stat --staged |
			grep -F '|' | # ignore summary line
			sort -n -k3

	else
		: no files staged

	fi

	echo

	# 2

	if
		untracked=$(git ls-files --others --exclude-standard) &&
			num_untracked=$(<<< "$untracked" wc -l) &&
			[[ $num_untracked -ge $LINES ]]
	then
		echo "[$num_untracked untracked files]"
		echo
	elif [[ -n $untracked ]]; then
		echo "$untracked"
		echo
	fi

	# 3

	if ! git status | grep -q 'Your branch'; then
		echo "No remote yet."
	elif ! git status | grep -P '\d+ commits?'; then
		echo 'No commits staged.'
	fi

	popd > /dev/null 2> /dev/null || :
}

gmm() {

	# in case of submodule conflict:
	# cd $submodule
	# gun .
	# git merge $hash (git should tell you which hash -- how to script?)
	# git add $submodule
	# git commit

	: merge master into dev branch
	# https://stackoverflow.com/a/20103414
	git fetch origin # gets you up to date with origin
	# TODO: for forks, need to sync fork (in gh), then git pull
	git merge "origin/$(_gmaster)"
}

grbr() {
	: rebase to remote, discarding all local changes that conflict with remote
	# use case:
	# - our branch was started at the same time as another branch
	# - rewriting is simpler than resolving conflicts
	# - the other branch is much larger
	# - the other branch has been merged to master

	cr

	# first preserve files that were only added to in our branch
	# (this is a looser definition than just 'new files')
	git diff --numstat master...HEAD |
		grep -P '^\d+\t0\t' |
		cut -f3 |
		xargs git diff master...HEAD > tmp.diff

	# equivalent to `git rebase origin/master; git rebase --skip (repeatedly)`
	git rebase --strategy-option=theirs "origin/$(_gmaster)"

	git apply tmp.diff

	# git push -f
}

_git_http() {
	url=$1
	if [[ $url == http* ]]; then
		echo "$url"
	else
		tr <<< "$url" : / | sed -r 's|git@|https://|; s|.git$||'
	fi

}

gh() {
	: open remote url

	if ! repo=$(git config --get remote.origin.url); then
		echo "Current repo has no remote"
		return
	fi
	repo=${repo%*.git}

	if [[ -f $1 ]] && git ls-files --error-unmatch "$1" &> /dev/null; then
		# TODO: path must be relativised to repo root (rev-parse?)
		# i.e. realpath - repo_root

		# view file at its most recent commit
		hash=$(git log --max-count=1 --pretty=format:%h -- "$1")
		url="$repo/blob/$hash/$1"

	elif [[ -n $1 ]]; then # view repo at specific commit
		# TODO: git log oneline -> fzf
		h=$(git rev-parse --short --verify HEAD)
		url="$repo/commit/$h"

	else
		url="$repo"

	fi

	url=$(_git_http "$url")

	echo "$url"
	# ubuntu is a pita:
	# gio: ...: Failed to find default application for content type ‘text/html’
	xdg-open "$url" ||
		firefox "$url"
}

gnew() {
	: push to newly created remote

	if [[ -f files_to_add ]]; then
		if [[ -d .git ]] && [[ -d .git_old ]]; then
			echo 'new and old git histories found, remove new one first: rm -rf ./.git'
			return
		fi
		mv .git .git_old
	fi

	# echo $GIT_EMAIL
	# return

	# https://kbroman.org/github_tutorial/pages/init.html
	# set -euo pipefail

	# no repo yet
	if [[ ! -d .git ]]; then
		git init
		return
	fi

	if
		! git log > /dev/null 2> /dev/null &&
			! git status --porcelain | grep -Fv '??'
	then
		echo 'no commits made yet'
		return
	else
		# WARN: this may not be desired
		git commit -m "initial commit"
	fi

	# no remote yet
	if ! git config --get remote.origin.url; then
		git branch -M master # don't call _gmaster!
		xdg-open https://github.com/new &
		read -rp 'Repo name (not URL!): ' repo
		git remote add origin "https://github.com/hejops/$repo"
		git push -u origin master
		git status
		git remote set-head origin --auto
	fi

}

_gssh() {
	: init github ssh key
	# https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent#generating-a-new-ssh-key
	#
	# note: this key must still be added to github!
	# https://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account#adding-a-new-ssh-key-to-your-account

	# password not strictly necessary
	ssh-keygen -t ed25519 -C hejops1@gmail.com -f "$HOME/.ssh/github_$(date -I)"
	ssh -T git@github.com 2>&1 | grep -q success && echo ok

	# to actually use the key on startup, add to .xinitrc (or similar);

	# if [[ -z $SSH_AUTH_SOCK ]]; then
	# 	{
	# 		pkill ssh-agent
	# 		eval "$(ssh-agent -s)"
	# 		ssh-add "$HOME/.ssh/github_2024-06-17"
	# 	} > /dev/null 2> /dev/null
	# fi

}

gd() {
	if [[ $# -eq 0 ]]; then
		git diff
	elif
		# file with no local changes (or hash?)
		[[ $# -eq 1 ]] && git diff --exit-code "$1" > /dev/null
	then
		git diff HEAD^^ "$1" # check against last commit
	else
		git diff "$@"
	fi
}

gdm() {
	: diff against master, like in a PR

	# caveat: due to git internals, it is not trivial to produce a diff
	# that is both 'cumulative' and completely excludes merges.
	#
	# https://stackoverflow.com/q/25403705
	#
	# this gets reasonably close, but if a file was changed in the current
	# branch as well as in a merge, both changes will be shown. for the
	# purpose of fast diffing (i.e. without network), this is usually fine.

	span="$(_gmaster)...HEAD"
	git log --diff-filter=d --no-merges --first-parent --name-only --oneline --pretty= "$span" |
		sort -u |
		# HACK: --diff-filter excludes files deleted by us, but does
		# not exclude files deleted during a merge
		while read -r f; do
			[[ -f $f ]] && echo "$f"
		done |
		xargs git diff "$span"

	# https://gitlab.com/gitlab-org/cli/-/issues/7704

	# if command -v glab > /dev/null; then
	# 	glab mr diff |
	# 		grep -v Subproject | # https://github.com/dandavison/delta/issues/1943
	# 		delta
	# else
	# 	# includes merges (can be noisy)
	# 	git diff "$(gmaster)...HEAD"
	# fi

}

gcon() {
	# https://nitaym.github.io/ourstheirs/

	: resolve conflicts, if any, and merge

	# git diff --name-only --diff-filter=U --relative

	has_conflicts() {
		rg --hidden '^[<=>]{7}'
		return $?
	}

	get_conflicts() {
		git status --porcelain |
			# grep -P '^(UU|AA)'
			# grep -P '^[^ ?]{2} '
			grep -P '^([^ ?])\1 '
	}

	if ! conflicts=$(get_conflicts); then
		echo "No conflicts detected"
		return
	fi

	# all conflicts are due to lock files
	if ! <<< "$conflicts" grep -v yarn.lock; then
		<<< "$conflicts" cut -c3- |
			xargs dirname |
			while read -r d; do
				pushd "$d" || return
				yarn install || return
				git add yarn.lock
				popd || return
			done
		has_conflicts && return
		git commit -v
		return
	fi

	while has_conflicts; do
		if [[ -f .abort ]]; then
			git merge --abort
			return
		fi
		echo "Unresolved conflicts remaining!"
		get_conflicts | cut -c3- | xargs nvim -p
	done

	get_conflicts | cut -c3- | xargs git add
	git commit -v
}

gapat() {
	: stage hunks matching some pattern

	# # https://choly.ca/post/git-programmatic-staging/
	# git diff |
	# 	# TODO: grepdiff seems to match entire context surrounding the
	# 	# matches, instead of just the surrounding lines
	# 	# might be useful: --only-match=rem|removals|add|additions|mod|modifications|all
	# 	grepdiff --output-matching=hunk "$1" |
	# 	git apply --cached

	# # https://old.reddit.com/r/git/comments/p1vltk
	# git diff -U0 |
	# 	grepdiff --output-matching=hunk "$1" |
	# 	# "By default, git apply expects that the patch being applied
	# 	# is a unified diff with at least one line of context."
	# 	git apply --cached --unidiff-zero

	# https://stackoverflow.com/a/52394658
	git diff --unified=1 --pickaxe-regex -S "$1" |
		grepdiff --output-matching=hunk --extended-regexp "$1" |
		git apply --cached

	# see also:
	# http://www.philandstuff.com/2014/02/09/git-pickaxe.html
	# https://git-scm.com/docs/gitdiffcore#_diffcore_pickaxe_for_detecting_additiondeletion_of_specified_string

	git commit -v

	# # unstage hunks that were unnecessarily added
	# git reset -p
}

guns() {
	: revert file to its state in a previous commit
	f=$1
	sha=$(_git_log_fzf "$1" | awk '{print $1}')
	git checkout "$sha" -- "$f"
}

# gclone() {
# 	ggiturl() { <<< "$1" sed 's|http://|git@|; s|/|:|; s/$/.git/'; }
# 	ggiturl "$1" | xargs git clone
# }

gau() {
	: show authorship of file
	git blame --line-porcelain "$1" |
		sed -rn 's/^author (.+)/\1/p' |
		sort |
		uniq -c |
		sort -n
}

# }}}
# gitlab {{{

# apt 1.36
# snap 1.43/1.54, but cannot read config file (lol)

gmr() {
	: create or open mr in browser
	branch=$(git branch --show-current)
	url=$(git config --get remote.origin.url)
	url=$(_git_http "$url")

	if
		n=$(glab mr list --source-branch "$branch" |
			grep '^!' |
			awk '{print $1}' |
			tr -d '!')
	then
		echo "Opening MR $n"
		url="$url/-/merge_requests/$n"
	else
		echo "Creating new MR"
		url="$url/-/merge_requests/new?merge_request%5Bsource_branch%5D=$branch"
	fi

	xdg-open "$url" 2> /dev/null
}

gldiff() {

	# note: for current branch, just use gdm
	if [[ $# -eq 0 ]]; then
		# n=$(glab mr list |     #--reviewer=@me |
		# 	sed -r 's/  +/\t/g' | # force tab delimiter
		# 	cut -d$'\t' -f1,3- |  # remove useless column
		# 	grep '^!' |           # remove useless lines
		# 	colt |
		# 	fzh |
		# 	awk '{print $1}' |
		# 	tr -d '!')

		# json output requires v1.37 (apt is 1.36 smh)
		# https://gitlab.com/gitlab-org/cli/-/commit/893f5c945a50cb8a6d674eb05923f87e46fa6150

		prv_cmd="echo {} | awk '{print \$NF}' | xargs -I{} git log --oneline origin/{}"

		n=$(glab mr list -F json --not-draft |
			jq '.[:10][]' |
			jqt updated_at iid title assignee.username source_branch |
			sort -r |
			fzh --preview="$prv_cmd" |
			# fzf --preview="$prv_cmd" |
			awk '{print $2}')

		[[ -z $n ]] && return
	else
		n=$1
	fi

	url=$(git config --get remote.origin.url)
	url=$(_git_http "$url")
	url="$url/-/merge_requests/$n.diff"

	# cannot use glab mr diff because diff is malformed
	src=$(curl -sL -H "Cookie:_gitlab_session=$GL_SESSION" "$url")
	if <<< "$src" grep -q "Sign in"; then
		echo "GL_SESSION expired"
		return
	fi
	echo "$src" | delta
}

gci() { watch -n 30 'glab ci list -P 10 | grep -P "^\(" | column -t'; }

gcoup() {
	: for a given file, show which files changed together
	# https://adamtornhill.com/articles/crimescene/codeascrimescene.htm
	git log --pretty=%h "$1" |
		xargs git show --name-only --pretty= |
		sort |
		uniq -c |
		sort -n
}

# }}}

# git diff blame
# https://gist.github.com/maxrothman/d27bbc36f7c150924de6c6e54965de4d py
# https://github.com/eantoranz/difflame py
# https://github.com/dmnd/git-diff-blame pl

# GitBlameOpenFileURL
# $url/-/blob/$branch/$path

# jj
# jj git init --colocate
# jj describe
# non-starter until jj describe has a verbose option
# https://github.com/jj-vcs/jj/issues/1946#issuecomment-2561045057

# python {{{

# i haven't worked in python in a while, so this may be cleaned up

pydeps() {
	# https://stackoverflow.com/a/75344709
	mapfile -t args < /dev/stdin
	python -c 'import sys
for i in sys.argv[1:]:
    if i.split(".")[0] not in sys.stdlib_module_names:
        print(i)' "${args[@]}"
}

genuv() {
	: generate dependencies of a uv script
	# assumes there are no 1st party imports; when generating dependencies
	# of a uv script, this is probably true
	deps=$(< "$1" grep -P '^(from|import)' | cut -d' ' -f2 | sort -u | pydeps)
	[[ -z $deps ]] && return

	cat << EOF
# /// script
# dependencies = [
$(echo "$deps" | while read -r dep; do echo "#   \"$dep\","; done)
# ]
# ///
EOF

}

alias pt='gls | grep test_.*py | xargs pytest -x -vv --disable-warnings'

pget() {
	pyp=$(_get_repo_root)/pyproject.toml

	if [[ -f $pyp ]]; then
		echo "not in python project"

	elif < "$pyp" grep -Fq tool.poetry; then
		poetry add "$@"

	elif command -v uv > /dev/null; then
		uv add "$@"
	fi
}

pup() {
	pyp=$(_get_repo_root)/pyproject.toml

	if [[ ! -f $pyp ]]; then
		echo "not in python project"

	elif < "$pyp" grep -Fq tool.poetry; then
		poetry update "$@"

	elif command -v uv > /dev/null; then
		# https://www.loopwerk.io/articles/2024/python-poetry-vs-uv/
		# https://www.loopwerk.io/articles/2024/python-uv-revisited/
		uv lock --upgrade-package "$@"
	fi
}

pentmd() {
	: render entry points as markdown
	# - [`poetry run XXX`](./path/to/script.py)
	# shellcheck disable=SC2016
	grep < pyproject.toml :main |
		sed -r 's|^([^ ]+) = "([^:]+):main"|- [`poetry run \1`](./\2.py)|g' |
		tr . / |
		sed -r 's#/(/|py)#.\1#g'
}

# }}}
# rust {{{

# cargo +nightly udeps
alias cb="cargo build"
alias cbr="cargo build --release && cp target/release/\$(basename \$PWD) ."
alias cn="cargo new"
alias ct="cargo test"
alias cwr="cargo watch -x run"                           # web servers only
alias sqp='cargo sqlx prepare --workspace; ga .sqlx; gc' # postgres only

sqre() {
	# regen sqlite db
	# often required for sqlite, possibly when .sql files are modified are migration
	# https://github.com/launchbadge/sqlx/discussions/1292#discussioncomment-3015486
	sqlx database drop
	sqlx database create
	sqlx migrate run
}

cw() {
	cargo watch -x check -x "test $1"
}

rsmod() {

	if [[ -f $1 ]]; then

		# convert foo/bar.rs -> foo/bar/mod.rs
		rs=$1
		base=${rs/.rs/}
		mkdir -p "$base"
		mv "$rs" "$base/mod.rs"
		# TODO: update lib, pub use, etc

	elif [[ -n $1 ]]; then

		echo "Creating module $1"

		echo "pub mod $1;" >> src/lib.rs # doesn't work?
		mkdir -p "src/$1"
		mod="src/$1/mod.rs"
		# touch "$mod"
		echo "mod foo;" >> "$mod"
		echo "pub use foo::*;" >> "$mod"

	fi

}

# }}}
# go {{{

# https://gist.githubusercontent.com/alexedwards/3b40775846535d0014ab1ff477e4a568/raw/15f15b499f626a6e3949c237d52a3e8aace1b05b/Makefile

# alias gonew=gon
alias gobe="go test -bench=. -run=^$ ./..."         # run benchmarks only -- https://stackoverflow.com/a/16161605
alias gor="\ls *.go | grep -v _test | xargs go run" # won't work with args

gop() {
	# https://go.dev/blog/pprof

	# https://github.com/google/pprof/blob/a8630aee4ab9e36dfc54c2e0a4df49abb8345dbd/internal/driver/commands.go#L125
	go tool pprof -web -nodefraction=0.1 ./*.prof 2> /dev/null
}

gopk() {
	: move foo.go to foo/foo.go
	# parent must then import from foo; goimports should fix this?
	f=$1
	pkg=${f/.go/}
	[[ -d $pkg ]] && return
	mkdir "$pkg"
	sed -i -r "s/^package main/package $pkg/" "$f"
	mv "$f" "$pkg"
}

gon() {
	[[ $# -ne 1 ]] && return
	[[ -d $1 ]] && return
	if [[ -f ./go.mod ]]; then
		mkdir "$1"
		echo -e "package $1\nfunc foo(){\n}" > "$1/$1.go"
		vim + "$1/$1.go"
	else
		mcd "$1"
		go mod init "$1"
		echo "$1" > .gitignore
		echo -e "func main(){\n}" > main.go
		go build # generate go.mod
		vim + main.go
	fi
}

gob() { # build and run (gor won't work with args)
	name=$(< go.mod head -n1 | cut -d' ' -f2)
	go build && ./"$name" "$@"
}

gorep() {
	patt=$1
	repl=$2

	# # see matches
	# rg -IN "$patt" ./*.go
	# read -r -p 'press enter to preview changes'

	# preview changes
	# note: gofmt can only modify expressions, not func declarations!
	gofmt -r "$patt -> $repl" ./*.go | less
	read -r -p 'press enter to accept changes'

	# execute
	gofmt -r "$patt -> $repl" -w ./*.go
}

# https://leg100.github.io/en/posts/building-bubbletea-programs/

# ideally i would like gow to be spawned in a background tab (not window!),
# then gowr in the main tab, BUT wezterm tabs mess with bubbletea dims
gow() {
	: watch code changes, trigger re-build, and kill process

	# cr
	find . -name '*.go' | entr -cr go test ./...

	# [[ ! -f go.mod ]] && return
	# name=$(< go.mod head -n1 | cut -d' ' -f2)
	# while :; do
	# 	go build && pkill "$name"
	# 	# inotifywait --event attrib $(find . -name '*.go') > /dev/null || return
	# 	find . -name '*.go' -print0 | xargs -0 inotifywait --event attrib > /dev/null || return
	# done

}
gowr() { while :; do gob "$@" || break; done; } # in foreground, continously run app

# }}}
# js {{{

tsc() {
	if [[ -f node_modules/.bin/tsc ]]; then
		cmd=node_modules/.bin/tsc
	elif cmd=$(which tsc); then
		:
	else
		return
	fi
	"$cmd" --version
	"$cmd" "$@"
}

# https://stackoverflow.com/a/47948461
_js_pkg_ver() { < package.json jq -r "[.dependencies, .devDependencies] | add | .$1" | tr -d '^~'; }
_js_pkgs() { < package.json jq -r '[.dependencies, .devDependencies] | add | keys[]'; }

jx() {
	pkgmgr() {
		if [[ -f yarn.lock ]]; then
			echo yarn
		elif [[ -f pnpm-lock.yaml ]]; then
			echo pnpm
		else
			echo npm
		fi

	}

	cmd=$(< package.json jq -r .scripts | grep : | fzh | cut -d'"' -f2)
	[[ -n $cmd ]] && "$(pkgmgr)" "$cmd"
}

jmake() {
	: convert scripts to Makefile

	keys=$(< package.json jq -r '.scripts | keys[]')

	cmds=$(echo "$keys" |
		while read -r cmd; do
			echo "${cmd//:/-}:" # make targets cannot contain :
			< package.json jq -r ".scripts.\"$cmd\"" |
				sed 's/&& /\n/g; s/\"/"/g' |
				prepend '\t'
		done)

	cat << EOF | tee Makefile
.PHONY: $(<<< "$keys" tr : - | xargs)
$cmds
EOF
}

jup() {
	: upgrade npm package
	pkg=$(_js_pkgs | fzf)
	curr_ver=$(_js_pkg_ver "$pkg")
	target_ver=$(c "https://www.npmjs.com/package/$pkg?activeTab=versions" |
		grep -Po '\d+?\.\d+?\.\d+?</a></td><td class="downloads">[0-9,]+' |
		sed -r 's|</a></td><td class="downloads">|\t|' |
		sort -rV |
		sed "/^$curr_ver/,\$d; /\t0$/d" | # filter to versions newer than current
		sort -k2n |                       # sort by downloads
		fzf --tac --prompt="$pkg (current: $curr_ver)" |
		cut -f1)
	# npm install (update?) / yarn upgrade
	echo yarn upgrade "$pkg@^$target_ver"
}

jupall() {
	: this is almost certainly a bad idea!
	_js_pkgs | xargs -n1 -I{} yarn upgrade {}@latest
}

perfnode() {
	if [[ $# -gt 0 ]]; then
		# creates perf.data
		perf record -e cycles:u -g -- node --perf-basic-prof "$@"
	elif [[ -f perf.data ]]; then
		# https://nodejs.org/en/learn/diagnostics/flame-graphs#create-a-flame-graph-with-system-perf-tools
		# https://speakerdeck.com/mrfoto/what-are-flame-graphs-and-how-to-read-them
		perf script | # reads perf.data
			# remove internal
			sed -r -e "/( __libc_start| LazyCompile | v8::internal::| Builtin:| Stub:| LoadIC:|\[unknown\]| LoadPolymorphicIC:)/d" \
				-e 's/ LazyCompile:[*~]?/ /' |
			# show only user defined functions
			grep -e "$USER" -e '^\S' -e '^$' |
			stackvis perf > flamegraph.htm
		chromium flamegraph.htm 2> /dev/null &
	fi
}

# }}}
# c {{{

x() {
	n=$(basename "$(realpath .)")
	gcc -o "$n" ./*.c && "./$n"
}

mch() {
	# f=$1

	: [re]generate header files
	for f in *.c; do
		[[ $f == main.c ]] && continue

		h="${f/.c/.h}"
		if [[ -f $h ]]; then
			# for merge to work, fn decls must all be placed at the
			# bottom of the .h file. includes, macros, structs
			# should be placed at the top. (is there a recommended
			# order?)
			{
				< "$h" grep -Pv '\);$' # discard existing fn decls
				cproto "$f" | sed 1d   # cproto only generates fn decls
			} | sponge "$h"
		else
			cproto "$f" > "$h"
		fi
	done
}

# }}}
# sql {{{

if [[ -n $POSTGRES_URL ]]; then
	alias psql="psql \$POSTGRES_URL"
fi

sq() {

	# TODO: sqlite in prod
	# https://fractaledmind.github.io/2023/09/07/enhancing-rails-sqlite-fine-tuning/#pragmas-summary

	# PRAGMA busy_timeout = 5000;
	# PRAGMA cache_size = 2000;
	# PRAGMA journal_mode = WAL;
	# PRAGMA journal_size_limit = 67108864; -- 64 megabytes
	# PRAGMA mmap_size = 134217728; -- 128 megabytes
	# PRAGMA synchronous = NORMAL;

	if [[ -f $1 ]]; then
		< "$2" sqlite3 "$1"
	else
		echo "$2" | sqlite3 "$1"
	fi
	# echo "Not a file: $1"
}

sqbrk() {
	# sqruff fix -f=json --force gripts/disq/queries/*.sql |
	sqruff fix -f=json --force "$@" |
		jq -r 'to_entries[] | .value=.value[].range.start.line | [.key, .value|tostring] | join("\t")' |
		while read -r f lnum; do
			# TODO: nothing can be done about url comments that are
			# too long (other than removing them)
			line=$(sed "${lnum}q;d" "$f")
		done
}

psqlj() {
	: convert psql output to jq
	# useful for times when it is easier to write jq than sql
	# https://www.pgcasts.com/episodes/generating-json-from-sql
	psql "$POSTGRES_URL" -c "select row_to_json(t) from ($1) t" |
		grep -Po '\{.+' |
		jq
}

# }}}
# jq {{{

alias jqc="jq -c" # basically just colors output

jqk() {

	: https://gist.github.com/pedroxs/f0ee8c515eea0dbce2e23eea7c048e10#file-jq-filters-sh-L2
	jq < /dev/stdin -r '.. | objects | with_entries(select(.key | contains("'"$1"'"))) | select(. != {}) | .'"$1"
}

jqt() {

	: select jq fields from a flat sequence of objects and format as tsv with alignment
	fields=()
	for x in "$@"; do
		fields+=(".$x")
	done
	query="$(ajoin "${fields[@]}")" # .foo,.bar,.baz

	# query="[$(echo "$@" | sjoin ,)]"

	# note: jq knows how to if read from stdin if no file passed
	< /dev/stdin jq -r "[$query] | @tsv" | colt

}

# }}}

# docker {{{

alias dolf='docker logs --tail=1 -f'

dolc() {
	: clear logs of docker image without restart
	# https://stackoverflow.com/a/42510314
	[[ $# -eq 0 ]] && return
	name=$1
	json="$(docker inspect --format='{{.LogPath}}' "$name")"
	# [[ ! -f $json ]] && return
	sudo ls "$json" > /dev/null || return
	# doesn't work for go binary? file -is- cleared, but `docker logs` still produces old output
	: | sudo tee "$json"
	sudo du "$json"
	echo "cleared $name $json"

	# remove lines with null bytes
	# https://stackoverflow.com/a/77907885
	sudo grep -r -l -a -P '\x00' /var/lib/docker/containers/ |
		while read -r f; do
			sudo perl -pi -e 's/\x00//g' "$f"
		done

	# dolf "$name"
}

# alias dps='docker ps -a --format "table {{.Names}}\t{{.State}}\t{{.Status}}\t{{.ID}}\t{{.RunningFor}}" | sort'

dps() {
	# docker ps adds too much padding, and cannot truncate long values
	docker ps -a --format=json |
		# note: ID is usually just visual noise, but placing it any
		# later in the seq will make it hard to extract (with cut/awk)
		jqt 'Names[0:40]' State ID Status RunningFor |
		# jq -r '[.Names[0:40], .State, .ID, .Ports, .Status, .RunningFor] | @tsv' |
		sort |
		column -t -s $'\t' # https://unix.stackexchange.com/a/57235
}

doslow() {
	: list slowest steps in a docker log

	# set -eu
	if
		steps=$(< "$1" grep -P '^#\d+ DONE' |
			sort -Vu |
			awk '!a[$1]++') && [[ -n $steps ]]
	then
		paste <(echo "$steps") <(
			<<< "$steps" cut -d' ' -f1 |
				while read -r n; do
					< "$1" grep "$n" |
						tac |
						grep -Pm1 "$n \[" |
						cut -d' ' -f2-
				done
		)
	else
		echo all ok
	fi
}

docl() {
	sudo docker system prune
	sudo docker volume ls -f dangling=true -q | xargs sudo docker volume rm
}

dostop() {
	docker ps --all --quiet | xargs docker stop
}

dorm() {
	mapfile -t containers < "$(docker ps --all --quiet)"
	docker stop "${containers[@]}"
	docker rm "${containers[@]}"
}

# }}}
# ssh {{{

if [[ -n $REMOTE ]]; then

	sget() {
		if [[ -f $1 ]]; then
			rsync --no-relative --files-from="$1" "$REMOTE:/" .
		else
			rsync --exclude=".*/" "$REMOTE:$1" .
		fi
	}

	sput() {
		rsync --exclude=".*/" "$@" "$REMOTE:~/"
	}

fi

# https://gist.github.com/cmbaughman/6a2ae275e0c0f39f42d95a728e07f796
# https://www.redhat.com/sysadmin/ssh-automation-sshpass

# }}}
# files, navigation {{{

zd() { zip -jr "${1%/}" "${1%/}"; }                         # zip directory (flat); stripping trailing slash is important
zin() { < /dev/stdin zip --junk-paths --names-stdin "$1"; } # pipe files from stdin to zip

f() {
	case $1 in

	n | new | mtime) find "${2:-.}" -maxdepth 1 -type f -printf "%T+\t%p\n" |
		sort |
		cut -f2 ;;

	# https://unix.stackexchange.com/a/22448
	s | sz | size) find "${2:-.}" -type f -exec du -a {} + |
		sort -n ;;

	esac
}

mcd() {
	: mkdir any number of paths, cd to last
	# it is uncommon for >1 arg to be passed, so this is more for cd
	# [[ $# -eq 0 ]] && return
	local p
	for p in "$@"; do mkdir -p "$p" || :; done
	# shellcheck disable=SC2164
	[[ -d $p ]] && cd "$p"
}

if [[ -n $MU ]]; then
	: wrap rm in a python check to prevent accidental deletion of some dir
	rm() {
		# parsing arbitrary args with bash is nonsense

		if [[ $* == *"$MU"* ]]; then
			python3 -c "
import sys
if \"$MU\" in {x.rstrip('/') for x in sys.argv}:
    print('FATAL')
    raise Exception
" "$@"
		fi

		command rm -v "$@"
	}
fi

rgo() {
	: useful when you know what to look for but dont want to open vim
	# https://blog.burntsushi.net/ripgrep
	# https://github.com/nvim-telescope/telescope.nvim/blob/7b5c5f56a21e82fdcfe5b250278b8dfc4b1cbab4/lua/telescope/config.lua#L646
	# $1 = fzf query generally more useful than $1 = file
	match=$(rg --color=never --no-heading --with-filename --line-number --column --smart-case '^.+$' . |
		fzf -e -q "${1:-}")
	[[ -z $match ]] && return

	# file:line:col:match
	IFS=':' read -ra array <<< "$match"

	# TODO: --glob '!libs/*' (! must be single quoted)

	{
		# force insert into history
		echo "vim $(realpath "${array[0]}")"
		echo "#$(date +%s)"
	} >> ~/.bash_history

	# note: this won't go into history (only rgo will)
	"$EDITOR" +"${array[1]}" "${array[0]}"

}

j() {
	: jump to frequently used file, should be used in conjunction with rgo
	sel=$(< ~/.bash_history grep -P '^n?vim' |
		awk '!seen[$0]++' |
		while read -r cmd; do
			f=$(<<< "$cmd" cut -d' ' -f2)
			f=$(realpath "$f" 2> /dev/null) || continue
			[[ ! -f $f ]] && continue
			echo "$f"
		done |
		awk '!seen[$0]++' |
		fzf --tac)
	[[ -z $sel ]] && return
	"$EDITOR" "$sel"
}

files() {
	: list files in use by a process
	pidof "$1" |
		xargs -n1 lsof -p |
		grep -Po '/[a-z].+' |
		sort -u |
		grep -P --color=never '^/(home|run)'
}

# }}}
# stdout manipulation {{{

append() { < /dev/stdin awk "{print \$0 \"$1\"}"; }
desec() { < /dev/stdin sed -r 's/:[0-9]{2}\.[0-9]{8,}Z//'; }            # for ease of filtering logs
largs() { < /dev/stdin xargs --no-run-if-empty --delimiter='\n' "$@"; } # split xargs by newline instead of space
ljoin() { < /dev/stdin tr '\n' , | sed 's/,$//'; }                      # lines to comma-delimited str
paren() { < /dev/stdin prepend '(' | append ')'; }
prepend() { < /dev/stdin awk "{print \"$1\" \$0}"; }
sum() { < /dev/stdin paste -sd+ | bc; }
surround() { < /dev/stdin awk "{print \"$1\" \$0 \"$1\"}"; }
tojson() { node --eval "console.log(JSON.stringify($(< /dev/stdin)))" | jq; }
line() { < /dev/stdin sed -n "${1}p"; }

ajoin() {
	: join space-delimited array
	# # https://stackoverflow.com/a/9429887

	# stdin=$(< /dev/stdin)
	# if [[ -n $stdin ]]; then
	# 	# mapfile -t input < /dev/stdin
	# 	mapfile -t input < <(echo "$stdin" | \xargs -n1) # bruh
	# else
	# 	input=("$@")
	# fi

	input=("$@")
	IFS=,
	echo "${input[*]}"
}

dehtml() {
	# https://stackoverflow.com/a/19878198
	< /dev/stdin sed -e 's/<br[^>]*>/\n/g; s/<[^>]*>//g' |
		# recode xml..utf8 |
		# https://stackoverflow.com/a/13161719
		perl -MHTML::Entities -pe 'decode_entities($_);'
}

plot() {
	: plot latency from json logs
	script=$(
		# https://unix.stackexchange.com/a/754698
		# https://superuser.com/a/108380
		cat <<- EOF
			show terminal;
			set ylabel 'ms';
			set xdata time;
			set timefmt '%Y-%m-%dT%H:%M';
			plot '-' using 1:(\$2/1000000)
		EOF
	)
	# echo "$script"
	< "$1" grep latency |
		grep -Fv -e null -e '={' | # remove invalid nested json
		# tail -n10000 |
		jqt time[0:19] latency |
		time gnuplot --persist -e "$script"
}

# }}}
# web {{{

,c() {
	c "$1" | prettier --parser html
	# c "$1" | lynx -stdin -dump
	# tidy injects extra stuff
}

,,c() {
	# uses a different user agent from curl
	# C() {
	: alternative to curl
	python3 -c '
import codecs
import sys

from bs4 import BeautifulSoup
import cloudscraper

byt = cloudscraper.create_scraper().get(sys.argv[1]).content
s = BeautifulSoup(byt, "html.parser").prettify()

# print(s)

# forcefully decode "unicode-strings" e.g. u002F
print(codecs.decode(s, "unicode-escape"))

' "$1"

}

alias C=,,c

upload() { # upload file to catbox.moe, copy link to clipboard

	# https://github.com/Allypost/bash-scripts/blob/fa4b1006a1c022484c3d48a05ec0ff1c94b9a541/catbox#L116
	# https://github.com/mananapr/dotfiles/blob/9dc9196224c2c84e4265e517dc36af1c79637eb7/bin/catbox
	# https://github.com/search?type=code&q=curl+catbox.moe+language%3AShell+fileupload

	link=$(
		curl -s --form "reqtype=fileupload" \
			--form "fileToUpload=@$1" \
			https://catbox.moe/user/api.php #| tee /dev/null
	)

	echo -en "Uploaded to: \e[1m$link\n" # idk what that escape does
	echo -n "$link" | xclip -sel c
}

nmc() {
	ssid=$(nmcli --terse device wifi list |
		fzf --reverse |
		cut -d: -f8 |
		xargs)
	nmcli --ask device wifi connect "$ssid" # password $password
}

nt() {
	: check network status in a loop
	int=5
	SECONDS=0
	while true; do
		# result=$(timeout 1 ping -c 1 google.com 2> /dev/null)
		# if [[ $? -eq 0 ]]; then
		if ! result=$(timeout 1 ping -c 1 google.com 2> /dev/null); then
			echo -en "\r\e[Kalive $SECONDS"
			notify-send alive
			[[ $int -lt 80 ]] && ((int *= 2))
		else
			# grep <<< "$result" -Po '\d+ ms'
			echo -en '\r\e[Kdead'
			int=5
			SECONDS=0
		fi
		sleep "$int"
	done
}

getmail() {
	mail 2>&1 | grep 'No new mail.'
	[[ $(notmuch count tag:inbox and tag:unread and date:today) -eq 0 ]] && return
	TERM=xterm-direct neomutt
}

pacmir() {
	: regenerate pacman mirrors
	# TODO: test current speed; if ok, just return
	country=$(curl -sL ipinfo.io | jq -r .country)
	url="https://archlinux.org/mirrorlist/?country=$country&protocol=https&use_mirror_status=on"
	curl -s "$url" |
		sed -e 's/^#Server/Server/' -e '/^#/d' |
		rankmirrors --max-time 1 -v -n 99 - |
		sudo tee /etc/pacman.d/mirrorlist

}

# mw() {
# 	cd ~/.mail/account.gmail || return
# 	while true; do
# 		# note: deleting empty dirs will almost certainly break sync
# 		gmi pull
# 		new=$(notmuch count tag:inbox and tag:unread and date:today)
# 		if [[ $new -gt 0 ]]; then
# 			notify-send -u critical "$new new mail"
# 			neomutt
# 		fi
# 		sleep 15m
# 	done
# }

# }}}

kp() {
	# urldecode() {
	# 	local i="${*//+/ }"
	# 	echo -e "${i//%/\\x}"
	# }
	url='https://www.discogs.com/search/?style_exact=K-pop&sort=hot%2Cdesc&ev=gs_ms'
	curl -sL "$url" -H 'User-Agent: M' | # lol
		grep -Po '/release/\d+-[^"]+' |
		cut -d'-' -f2- |
		tr '-' ' ' |
		# TODO: percent decode
		sort -u |
		while read -r rel; do
			echo "$rel"
			ya "$rel"
		done
}

rge() {

	: edit files matching pattern
	files=$(rg --files-with-matches "$@" | sort -u)
	if [[ $(<<< "$files" wc -l) -gt 10 ]]; then
		echo "More than 10 files found"
		return
	fi
	echo "$files" | xargs nvim -p
}

# rg -U --multiline-dotall '^import.+?;'
# similar for go; difficult for python if not one-per-line

# uncommon

# echo ${files[@]} | entr -cr $cmd

# {
# 	find "$HDD/movies" -type f
# 	cat ~/to_watch
# } | fzf

_unused() {
	: list unused functions
	< ~/.bash_aliases grep -Po '^[a-z]\w+\(\)' |
		tr -d '()' |
		while read -r cmd; do
			< ~/.bash_history grep -wq "$cmd" || echo "$cmd"
		done
}

# rng() { for _ in "$(seq "${2:-1}")"; do echo $((1 + RANDOM % ${1:-100})); done; }
,pgrep() { \pgrep "$1" | xargs ps; } # ps for runtime
pk() { pgrep "$1" | fzf -m --tac | cut -d' ' -f1 | xargs kill; }
pkill1() { \pgrep "$1" | sed 1d | xargs kill; }                                            # kill all procs except 1st
rng() { while read -r _; do echo $((1 + RANDOM % ${1:-100})); done < "$(seq "${2:-1}")"; } # shellharden
ya() { mpv --video=no "ytdl://ytsearch10:\'$*\'"; }
yi() { yt-dlp --dump-single-json --skip-download "$1" 2> /dev/null | jq -r '.title, .description, .webpage_url, .channel_url'; }
yt() { mpv --force-window "ytdl://ytsearch10:\'$*\'"; }

ys() { # read youtube subs in less
	yt-dlp -j "$1" |
		jq . |
		grep '=vtt' |
		grep -v tlang |
		tail -n1 | # auto subs are listed first
		cut -d'"' -f4 |
		xargs curl -sL |
		dehtml |
		grep -v -- '-->' |
		grep -Pv '^\s*$' |
		tr '\n' ' ' |
		fold --spaces |
		less
}

yti() {
	: get info for currently playing file with youtube id
	# www-watch?v=bMEfWLA-V00.mp3
	pactl list sink-inputs |
		grep media.name |
		cut -d= -f3 |
		cut -d. -f1 |
		prepend 'https://youtube.com/watch?v=' |
		xargs yt-dlp -j 2> /dev/null |
		jq -r .title
}

nico() {
	# set -x
	[[ ! -f $1 ]] && return
	xdotool key super+8
	# ensure window is focused!
	i=0
	while read -r line; do
		[[ -z $line ]] && break

		# slsk blocks all searches after a while
		((i++))
		[[ $i -ge 68 ]] && break

		echo "$i: $line"
		echo "$line" | xclip -sel c
		xdotool key ctrl+2 F6 ctrl+v enter
		sleep 3
	done < "$1"

	notify-send 'done'
}

epk() {
	: fix malformed epubs

	# according to the spec, `mimetype` must be the first listed file. note
	# that malformed epubs are still readable in zathura, so this is mainly
	# to prevent yazi from treatting malformed epubs as zip.

	tmpdir=tmp
	tmpname=foo

	for f in *.epub; do

		# https://github.com/ikrukov/epub/blob/c663821de66d57b3d138dc9125251f40ea755c2c/script/pack_epub#L25
		# https://www.mobileread.com/forums/showthread.php?t=299415

		unzip -l "$f" > /dev/null 2> /dev/null || continue                 # corrupt (unreadable)
		file --mime-type "$f" | grep -q 'application/epub+zip' && continue # ok

		unzip "$f" -d "$tmpdir"
		cd "$tmpdir" || :
		echo 'application/epub+zip' > mimetype
		zip -X -0 --quiet "$tmpname" mimetype
		zip -X -9 --quiet --no-dir-entries --recurse-paths "$tmpname" META-INF OEBPS
		cd ..
		mv "$tmpdir/$tmpname.zip" "$f"
		\rm -rf "$tmpdir"
		echo "fixed $f"

	done
}

watchmem() {
	stdin="$(< /dev/stdin)"

	if [[ $stdin =~ ^[0-9]+$ ]]; then
		pid="$stdin"
		watch -d ps -o %cpu,%mem,cmd -p "$pid"

	# else
	# 	pid=$(ps aux |
	# 		grep "$1" |
	# 		head -n1 |
	# 		awk '{print $2}')
	# 	while true; do
	# 		pmap -x "$pid" | tail -n1
	# 		sleep 2
	# 	done

	fi

}

gev() {
	: get env var
	find . -type f -name '.*env' -print0 |
		# probably better to force upper, but whatever
		\xargs -0 grep -Pi "$1" |
		awk -F: '!a[$2]++' |
		sed -r 's/:/	/' |
		column -s '	' -t
}

scan() {
	cd ~/scores || return
	f=$1
	n=1
	echo 'type x to exit'
	res=600
	while true; do
		echo -n "$n: "
		read -r ans < /dev/tty
		[[ $ans == x ]] && break
		# 600: 30 sec, 4.4 MB
		# 2400: 8 min, 48 MB
		scanimage --format=pdf --progress --resolution="$res" \
			--output-file "$f-$n-$res.pdf"
		((n++))
	done
	pdfunite "$(\ls "$f"-* | sort -V)" "$f.pdf"
	rm -I "$f"-*
}

# force delete plugins where contents were unintentionally changed (typically
# via a stray `black` format)
# note: Lazy (still) doesn't have a log file, so the output must be copied from
# Lazy itself
# https://github.com/folke/lazy.nvim/blob/014d1d6d78df4e58f962158e6e00261d8632612c/TODO.md?plain=1#L47
# < lazy.log grep 'local changes in' |
# 	cut -d'`' -f2 |
# 	sort -u |
# 	xargs rm -rf

# note: sendmail unresponsive
# note: it is not known what set up is needed
# echo "$body" | mail --subject="$subject" $email

mdr() {
	c 'https://www.mdr.de/nachrichten/index.html' |
		grep 'class="headline" ' |
		prepend '<li>' |
		html2markdown --domain https://www.mdr.de |
		sort -u
}
