# shellcheck shell=bash
# vim:ft=bash
# if possible, this file should remain under 1000 LOC. interactive shell
# startup time should remain under 0.02 s

# startup {{{

# https://wiki.archlinux.org/title/Systemd#Boot_time_increasing_over_time
# systemd-analyze blame | grep -P '\ds'
# systemd-analyze critical-chain
#
# sudo systemctl disable NetworkManager-wait-online.service # https://askubuntu.com/a/1018731
#
# journalctl --disk-usage                                                          # current usage
# journalctl -b -u systemd-journald | grep max                                     # current max
# sudo journalctl --vacuum-time=3d                                                 # truncate
# sudo sed -i -r 's/#SystemMaxUse.+/SystemMaxUse=100M/' /etc/systemd/journald.conf # set max (should be done on arch install)

# docker is disabled for now, because i literally never use it
# sudo systemctl disable docker.service

if [[ -f /tmp/updates ]] && ! pgrep pacman > /dev/null; then

	cat /tmp/updates

	if
		< /tmp/updates grep -q '^python ' &&
			! < /tmp/updates grep -P 'python (3\.\d+)\S+ -> \1'
	then
		echo -e "WARNING: major Python update\n"
		# TODO: update globally installed pips (scrobblerh)
	fi

	if
		< /tmp/updates grep -q '^postgresql ' &&
			! < /tmp/updates grep -P 'postgresql (\d+)\S+ -> \1'
	then
		echo -e "WARNING: major postgresql update\n"
	fi

	if sudo pacman -Syu; then
		rm /tmp/updates

		# may get unset after update? not sure what causes it
		setxkbmap -layout us -option -option compose:rctrl,caps:menu

	elif
		# if pacman hasn't been run in a long time, keys in keyring
		# will expire. updating archlinux-keyring should fix this
		command -v expac > /dev/null &&
			last_update=$(expac --timefmt '%s' "%l" | sort -n | tail -n1) &&
			# https://stackoverflow.com/a/6948865
			[[ $(((last_update - $(date +%s)) / (60 * 60 * 24))) -gt 14 ]]
	then
		sudo pacman -Sy archlinux-keyring

	fi
fi

if ps --pid "$PPID" | grep -Fq wezterm; then

	[[ -f /tmp/verse ]] && [[ -s /tmp/verse ]] && cat /tmp/verse

	if [[ -d $SLSK ]]; then
		if
			x=$(du -csh "$SLSK" | head -n1 | grep G) &&
				<<< "$x" grep -Po '^\d+' | \xargs -I{} test {} -ge 3
		then
			echo -e "\n$x"
		fi
		unset x
	fi

fi

[[ -f ~/jira.txt ]] && < ~/jira.txt cut -f1,3

# }}}
# aliases {{{

alias dr=discogs_rate
alias ex=extract
alias gm=getmail
alias lc=leetcode.py # shadows lc binary (who?)
alias mb=musicbrainz
alias met=metronome
alias ns=notify-send
alias trk=trackratings.py
alias tt=taptempo
alias wd=waitdie
alias xo=xdg-open

alias rab='exec yazi "$HDD/books"'
alias rad='exec yazi "$SLSK/complete"' # TODO: investigate `ya pub`
alias rag='exec yazi "$HDD/guitar"'
alias ram='exec yazi "$MU"'
alias rat='exec yazi "$HDD/torrent" "$HDD/movies"'

# alias lock="[[ -d /sys/class/power_supply/BAT0 ]] && systemctl suspend && slock"
# alias n="NO_COLOR=1 node --import=tsx"
alias au="audacious -H"
alias bh="vb -b"
alias cam="ls /dev/video* && exec mpv --fs av://v4l2:/dev/video0 --profile=low-latency --untimed" # TODO: handle >1 video device (just increment n until file not exist)
alias cdnp='cd "$(files mpv | grep mp3 | largs dirname)"'
alias ci="chromium --incognito"
alias colt="column -t -s$'\t'" # align tab-containing output
alias cpu='top -b -n1 -o %CPU | grep -m10 $USER'
alias ctz='sudo timedatectl set-timezone $(timedatectl list-timezones | grep / | fzf)' # TODO: geolocate
alias cv='exec $EDITOR ~/cv/src/index.tex'
alias dA="dc artist:"
alias datez='date -u +%FT%TZ' # utc (i.e. ignore current timezone)
alias dc="discogs_collection filter"
alias dt="discogs_collection top"
alias fzh="fzf --height=~33% --reverse" # height=~X% means min(input rows, window height * X%);
alias inw="inotifywait --monitor --recursive"
alias li="exec chromium --incognito 'https://www.linkedin.com/notifications/?midToken=AQECUGJ6GKhRSg'"
alias mem='top -b -n1 -o %MEM | grep -m10 $USER'
alias or="cd ~/gripts/oar && time ./oar && waitdie mpv && vol --auto && mpv --profile=bcx ./out && rm -rI ./out ; kp"
alias pq="~/plaque/plaque"
alias pss="ps -e --format=lstart,pid,cmd --sort=start_time | grep -Fv -e '[' -e '('"
alias synctime="sudo ntpd --quit --panicgate"
alias tf="waitdie con; fix_tags"
alias trizen="trizen --aur-results-sort-by=votes --aur-results-sort-order=ascending"
alias tx="tectonic -X"
alias tz=trizen # if gpg fail, gpg --recv-keys <key>

# alias y="bash ~/gripts/disq/ytm.sh"

y() {
	{
		# force pause before playback (?)
		playerctl play-pause

		# wait for mpv to start
		while
			sink=$(pactl --format=json list sink-inputs | jq -r '.[] | select(.properties."application.name"=="mpv") | .sink')
			[[ -z $sink ]]
		do
			sleep 0.5
		done

		# ensure mpv playing on headphones
		# alsa.id=="Au" means connected via headphone jack (speakers are connected via "USB")
		if
			! pactl --format=json list sinks |
				jq -e ".[] | select(.state==\"RUNNING\" and .index==$sink and .properties.\"alsa.id\"==\"Au\")" > /dev/null
		then
			notify-send -u critical 'playing on speakers'
			# pgrep bash | grep ytm.sh | cut -d' ' -f1 | xargs kill
			pavucontrol
		else
			playerctl play-pause
		fi
	} &
	bash ~/gripts/disq/ytm.sh
}

EXA_ARGS=(

	# https://github.com/search?type=code&q=path:dot_config/eza
	# xdg dir is only for theme...?

	# --dereference # this actually undoes symlink `-> ...`
	--all # show dot files
	--color=always
	--git                     # status porcelain
	--group-directories-first # debatable
	--links                   # inode count
	--long                    # note: long names will not be wrapped
	--no-permissions
	--no-user
	--octal-permissions
	--time-style=iso

	--level=2
	--tree # will be slow in large (wide) dirs

	# --sort=modified
)

alias ls='exa ${EXA_ARGS[*]}'
alias lsl="ls --sort=modified"

# }}}
# frequent {{{

# # show contents of most recent self-sent msg
# notmuch show --limit=1 from:hejops1 |
# 	grep -Po 'id:\S+' |
# 	xargs notmuch show --part=2

# < ~/.config/mpv/library fzf |
# 	prepend "$MU"/ |
# 	largs mpv

m() {
	{
		find "$HDD/movies" -type f
		cat ~/to_watch
	} | fzf
}

da() {
	if [[ $# -eq 1 ]]; then
		~/disq/disq -artist "$1"
	else
		~/disq/disq
	fi
}

cm() {

	if [[ $# -eq 0 ]]; then
		# note: files added to cm via `add -f <symlink>` are not
		# automatically updated when the src file (target of the
		# symlink) is modified. the symlink targets must always be
		# re-added. this will no longer be necessary when the scripts
		# repo is deprecated.
		chezmoi status | grep -Po '\.local/bin/.+' | largs chezmoi add -f 2> /dev/null

		chezmoi cd
	else
		chezmoi "$@"
	fi
}

bx() { [[ $# -gt 0 ]] && bash -x "$@"; }

replace() {
	_in_git_repo || return

	# check correct rep binary (not the lisp thing)
	if ! command -v rep | grep -Fq .cargo; then
		cargo install rep-grep
		return
	fi

	search=$1
	replace=$2
	_rg() {
		# --hidden will cause .git to be included!
		rg --hidden --glob='!.git/**' "$@"
	}

	if ! _rg -q -- "$search"; then
		echo "Pattern not found"
		return
	fi

	# note: backreferences use $1, not \1
	_rg --line-number -- "$search" | rep -- "$search" "$replace"
	read -r -p 'OK?' || return
	_rg --line-number -- "$search" | rep --write -- "$search" "$replace"

	# git diff
	gapat "$replace"
}

sd() {
	: shutdown
	# uptime | grep hour || return/reboot

	waitdie mpv pacman curl yt-dlp

	if [[ -n $HDD ]]; then

		if
			files firefox | grep "$HDD"
		then
			inotifywait -e moved_to "$HDD"/movies
		fi
		killall firefox

		while
			f=$(files python | grep "$SLSK")
		do
			echo "$f" | xargs -n1 inotifywait -e move_self
		done
		killall nicotine

	fi

	echo "Shutting down..."
	sleep 3
	shutdown now
}

rt() {
	: pass an array of relative paths to tagfix
	# note: dead symlinks are still displayed as if they exist

	< ~/.config/mpv/library fzf --multi --reverse --preview="ls \"$MU\"/{}" |
		prepend "$MU/" |
		while read -r d; do
			files mpv | grep -Fq "$d" && waitdie mpv >&2
			echo "$d"
		done |
		# to preserve the old behaviour (>1 args), remove -n1
		largs -o fix_tags

}

ytm() {

	f=$(mktemp)
	"$EDITOR" +startinsert "$f"

	waitdie mpv

	all_ids=
	while read -r query; do
		echo "$query"
		curl -sL 'https://music.youtube.com/youtubei/v1/search' -H 'Content-Type: application/json' \
			--data-raw '{"context":{"client":{"clientName":"WEB_REMIX","clientVersion":"1.20240904.01.01"}},"query":"'"$query"'","params":"EgWKAQIIAWoSEAMQBBAJEA4QChAFEBEQEBAV"}' |
			jq '
		.contents |
		.tabbedSearchResultsRenderer |
		.tabs[] |
		.tabRenderer |
		.content |
		.sectionListRenderer |
		# .contents[] | # TODO: filter null
		.contents[1] |
		.musicShelfRenderer |
		.contents[] |
		.musicResponsiveListItemRenderer |
		.flexColumns[] |
		.musicResponsiveListItemFlexColumnRenderer |
		.text |
		.runs[]
	' |
			grep -- videoId |
			cut -d'"' -f4 |
			while read -r id; do
				<<< "$all_ids" grep -Fxq -- "$id" && continue
				all_ids+=$'\n'$id
				echo "$id"
			done |
			prepend 'https://youtube.com/watch?v=' |
			xargs mpv --video=no
	done < "$f"

	exit
}

# }}}

# git

alias S=gS
alias b=git_branch # i could <leader>gB, but changing branch means context switching and probably closing vim anyway
alias bb=gb
alias cr=git_root
alias e=v
alias s=git_status # could be ported to vim maybe

# discouraged due to double index keypresses: gt gf gb

# alias gr=git_root
alias gl=git_log
alias gs=git_status

# alias gdnw="git diff --color-words --no-index"
alias g.="git push"
alias gC="git show HEAD | cat; git reset --soft HEAD~1"                                         # un-commit, but keep changes staged
alias gCH="git show --oneline HEAD | cat; echo; read -r -p 'confirm?'; git reset --hard HEAD~1" # un-commit, and discard changes
alias ga="git add"
alias gdn="git diff --no-index"                  # https://stackoverflow.com/a/17433969 -- TODO: handle symlinks
alias gdnc="git diff --color-words=. --no-index" # diff by char; may be replaced with delta
alias gig='$EDITOR $(_get_repo_root)/.gitignore'
alias gu=gun
alias gx='git log --author=$(git config --get user.email) --branches --format="%h%x09%S%x09%s" --pickaxe-regex -S' # TODO: colt would be nice, but then it can't be an alias anymore

# git info {{{
# functions that only report info

# shellcheck disable=SC2120
gls() { git ls-files "${1:-.}"; }

_get_remote() { git config --get remote.origin.url; }
_git_current_branch() { git branch --show-current; }
_in_git_repo() { git rev-parse --is-inside-work-tree > /dev/null 2> /dev/null; }

_get_repo_root() {
	if [[ $(basename "$PWD") == .git ]]; then
		realpath ..
	else
		git rev-parse --show-toplevel 2> /dev/null
	fi
}

_gmaster() {
	: get default branch, e.g. master
	# https://stackoverflow.com/a/44750379
	# default_branch=$(git symbolic-ref refs/remotes/origin/HEAD | sed 's|^refs/remotes/origin/||')
	git symbolic-ref refs/remotes/origin/HEAD 2> /dev/null | cut -d/ -f4
}

git_root() {
	if _in_git_repo; then
		cd "$(_get_repo_root)" || :
	elif [[ -n $REPO ]]; then
		cd "$REPO" || :
	fi
}

_git_http() {
	url=$1
	if [[ $url == http* ]]; then
		echo "$url"
	else
		tr <<< "$url" : / | sed -r 's|git@|https://|; s|.git$||'
	fi

}

_git_has_conflicts() {
	rg --hidden '^[<=>]{7}'
	return $?
}

_git_get_conflicts() {
	# submodule conflicts don't really need to be resolved?
	git status --porcelain --ignore-submodules=all |
		grep -P '^([^ ?])\1 ' |
		sort -u |
		cut -c3-
}

gauthors() {
	: show authorship of file
	git blame --line-porcelain "$1" |
		sed -rn 's/^author (.+)/\1/p' |
		sort |
		uniq -c |
		sort -n
}

gL() {
	: show full history of a file/dir
	prv_cmd="echo {} | cut -d' ' -f1 | xargs -I{} git show --color=always {} $1"
	git log --oneline "$1" |
		tac |
		fzf --reverse --preview="$prv_cmd" --preview-window='right,60%,border' --ansi
}

git_status() { # {{{
	# 1. changed files (twice: porcelain, then diff stat)
	# 2. untracked files
	# 3. current number of staged commits

	# Nothing staged. Current stat:
	#
	#  sqlc/artists.sql.go | 1 +
	#  schema.sql          | 2 +-
	#  queries/artists.sql | 4 ++--
	#  main.go             | 5 +++++
	#
	# Your branch is ahead of 'origin/master' by 2 commits.

	_in_git_repo || return

	if
		# new repo
		git status | grep 'No commits yet'
	then
		echo "Files:"
		echo
		git ls-files --others --exclude-standard
		return
	fi

	# shellcheck disable=SC2164
	[[ $# -eq 1 ]] && [[ -d $1 ]] && pushd "$1" > /dev/null

	# 1

	if
		staged=$(git status --porcelain . |
			# grep '^A' | # only added files!
			# grep -Fv '??' |
			grep -P '^[A-Z]' |
			awk '{print $NF}' |
			# make paths absolute (default: relative to root)
			prepend "$(_get_repo_root)/" |
			# then relativise to cwd
			largs realpath --relative-to=. 2> /dev/null) #&&
		[[ -n $staged ]]
	then
		: diffing staged files

		cat <<- EOF
			Staged:

		EOF

		# TODO: can we not rely on pipefail?
		set -o pipefail
		<<< "$staged" \xargs git diff --stat --staged 2> /dev/null |
			grep -F '|' | # ignore summary line
			sort -n -k3 ||
			# TODO: deleted files raise error
			git status --porcelain | grep '^[A-Z]'
		set +o pipefail

	else
		echo "Nothing staged."

	fi

	# note: colors are lost when piping, but sort is more useful than color
	if
		# git diff only diffs unstaged files
		diffs=$(git diff --stat . | # generally, i only want to see the diff stat for current dir
			grep -F '|' |              # ignore summary line
			sort -n -k3)               # most changes last (more useful in short terminals)
		[[ -n $diffs ]]
	then
		# [[ -n $staged ]] && echo
		cat <<- EOF

			Unstaged:

			$diffs
		EOF

	# else
	# 	: no files staged

	fi

	echo

	# 2

	if
		untracked=$(git ls-files --others --exclude-standard) &&
			num_untracked=$(<<< "$untracked" wc -l) &&
			[[ $num_untracked -ge $LINES ]]
	then
		echo "[$num_untracked untracked files]"
		echo
	elif [[ -n $untracked ]]; then
		echo "$untracked"
		echo
	fi

	# 3

	if ! git status | grep -q 'Your branch'; then
		# TODO: could also mean no branch on remote yet
		echo "No remote yet."
	elif ! git status | grep -P '\d+ commits?'; then
		echo 'No commits staged.'
	fi

	popd > /dev/null 2> /dev/null || :
} # }}}

gh() {
	: open remote url

	if ! repo=$(_get_remote); then
		echo "Current repo has no remote"
		return
	fi

	# better handled in vim

	# if [[ -f $1 ]] && git ls-files --error-unmatch "$1" &> /dev/null; then
	# 	# view file at its most recent commit
	# 	hash=$(git log --max-count=1 --pretty=format:%h -- "$1")
	# 	url="$repo/blob/$hash/$1"
	#
	# elif [[ -n $1 ]]; then # view repo at specific commit
	# 	h=$(git rev-parse --short --verify HEAD)
	# 	url="$repo/commit/$h"
	# fi

	url=${repo%*.git}
	url=$(_git_http "$url")
	echo "$url"
	# ubuntu is a pita:
	# gio: ...: Failed to find default application for content type ‘text/html’
	xdg-open "$url" ||
		firefox "$url"
}

gd() {
	if [[ $# -eq 0 ]]; then
		git diff
	elif
		# file with no local changes (or hash?)
		[[ $# -eq 1 ]] && git diff --exit-code "$1" > /dev/null
	then
		git diff HEAD^^ "$1" # check against last commit
	else
		git diff "$@"
	fi
}

# }}}
# git history {{{

_git_log_fzf() { # {{{
	_in_git_repo || return
	# rather, if the heads dir is empty; but i don't want to ls/glob
	if [[ ! -f $(_get_repo_root)/.git/refs/heads/master ]]; then
		echo "no commits yet" >&2
		return 1
	fi

	prv_cmd="echo {} | cut -d' ' -f1 | xargs git show --color=always"

	args=()

	if [[ -f $1 ]] || [[ -d $1 ]]; then
		args+=("$@")
		prv_cmd="echo {} | cut -d' ' -f1 | xargs -I{} git show --color=always {} $1" # restrict diff to selected file/dir
	elif
		[[ $# -gt 1 ]] # probably arbitrary options to git log
	then
		# TODO: allow arbitrary options to fzf (this is a can of worms)
		args+=("$@")
	elif
		# other dev branch
		[[ $# -eq 1 ]] &&
			git branch --remote | grep -Pqx "  origin/$1"
	then
		git pull > /dev/null 2> /dev/null
		args+=("origin/$1")
	elif
		m=$(_gmaster) &&
			[[ $(_git_current_branch) == "$m" ]]
	then
		: on master
	elif [[ -n $m ]]; then # dev branch
		args+=(--first-parent "$m...HEAD")
	else
		: no remote yet
	fi

	# there is literally nothing to see in merge commits (Merge branch 'x'
	# into 'master'), so --no-merges is generally a good idea.
	#
	# however, commits that are the -result- of a merge are still included.
	# these merges can be further ignored with --first-parent, although
	# ignoring them may not always be desirable.
	#
	# alternatively, it may be good to indicate whether the commit was
	# committed in this branch, or simply pulled from remote.

	git log --decorate --oneline --no-merges "${args[@]}" |
		fzf -m --preview="$prv_cmd" --preview-window='right,60%,border' --ansi
}     # }}}
v() { # {{{
	: open recently modified files

	_in_git_repo || return

	# bat can keep up with rapid renders; pygmentize can't
	#
	# chezmoi/ > time cat dot_config/nvim/init.lua >/dev/null
	# real    0m0.001s
	#
	# chezmoi/ > time bat --color=always --style=auto --paging=never dot_config/nvim/init.lua >/dev/null
	# real    0m0.028s
	#
	# chezmoi/ > time pygmentize dot_config/nvim/init.lua >/dev/null
	# real    0m0.118s

	# on ubuntu:
	# ln -s /usr/bin/batcat ~/.local/bin/bat
	prv_cmd="bat --color always --style=auto {} 2>/dev/null || cat {}"

	{
		# git diff --name-only --ignore-submodules "$(_gmaster)...HEAD" | grep . #||
		git log --no-merges --first-parent --name-only --pretty= "$(_gmaster)...HEAD" | grep .
		git ls-files --full-name # . is implicit
	} |
		prepend "$(_get_repo_root)"/ |
		largs realpath --relative-to=. 2> /dev/null |
		sort -u |
		largs ls -1t 2> /dev/null |
		head -n50 |
		# height=~X% is not suitable because preview is usually longer
		# than input rows, and preview must always be shown to a reasonable
		# extent
		fzf -m --prompt="$(_git_current_branch): " \
			--height=50% --reverse --preview-window='right,50%,border' \
			--preview="$prv_cmd" |
		xargs nvim -p
}       # }}}
gdm() { # {{{
	: diff against master, like in a PR

	# caveat: due to git internals, it is not trivial to produce a diff
	# that is both 'cumulative' and completely excludes merges.
	#
	# https://stackoverflow.com/q/25403705
	#
	# this gets reasonably close, but if a file was changed in the current
	# branch as well as in a merge, both changes will be shown. for the
	# purpose of fast diffing (i.e. without network), this is usually fine.

	span="$(_gmaster)...HEAD"
	root=$(_get_repo_root)
	git log --diff-filter=d --no-merges --first-parent --name-only --oneline --pretty= "$span" |
		sort -u |
		# HACK: --diff-filter excludes files deleted by us, but does
		# not exclude files deleted during a merge
		while read -r f; do
			[[ -f "$root/$f" ]] && echo "$root/$f"
		done |
		# TODO: xargs: git: terminated by signal 13
		xargs git diff "$span" 2> /dev/null

	# https://gitlab.com/gitlab-org/cli/-/issues/7704

	# if command -v glab > /dev/null; then
	# 	glab mr diff |
	# 		grep -v Subproject | # https://github.com/dandavison/delta/issues/1943
	# 		delta
	# else
	# 	# includes merges (can be noisy)
	# 	git diff "$(gmaster)...HEAD"
	# fi

} # }}}

git_log() {
	: browse git log, showing each commit\'s diff in fzf preview
	_git_log_fzf "$@" | awk '{print $1}' | xargs git show
}

gxx() {
	: show commits whose changes contain a pattern
	prv_cmd="echo {} | cut -f1 | xargs git show --color=always"
	git log --branches --format="%h%x09%S%x09%s" --pickaxe-regex -S "$1" | # WARN: slow with large histories
		fzf -m --preview="$prv_cmd" --preview-window='right,60%,border' |     # --ansi
		cut -f1 |
		xargs git show
}

gcoup() {
	: for a given file, show which files changed together
	# https://adamtornhill.com/articles/crimescene/codeascrimescene.htm
	git log --pretty=%h "$1" |
		xargs git show --name-only --pretty= |
		sort |
		uniq -c |
		sort -n
}

# gsdel() {
# 	: show last state of a deleted file
# 	# https://stackoverflow.com/a/19727752
# 	f=$1
# 	git show "$(git rev-list --max-count=1 --all -- "$f")^:$f"
# }

# git diff blame
# inherently, this means git diff must operate on a time range that spans more
# than commits, typically a (big) diff of a PR. by extension, this means that
# git diff blame is only useful when multiple authors have worked on the same
# PR, which tends to not happen very often IME.
# https://gist.github.com/maxrothman/d27bbc36f7c150924de6c6e54965de4d py
# https://github.com/eantoranz/difflame py
# https://github.com/dmnd/git-diff-blame pl

# GitBlameOpenFileURL
# $url/-/blob/$branch/$path

# }}}
# git staging {{{
# functions that modify files or the index

gA() {
	: un-add, unstage
	# i usually want restore more often (?)
	set -x
	git restore --staged "$@" \
		2> /dev/null || # committed; without --staged, changes are discarded!
		git reset "$@"  # not committed yet
	set +x
}

gc() {
	: commit

	local cmd=(git commit -v --untracked-files=no)

	if [[ $# -gt 0 ]]; then

		# 1. specified files, but excluding untracked files
		# note: this loop commits renamed files, but does not commit
		# their old names

		# arr=()
		# for f in "$@"; do
		# 	[[ ! -f $f ]] && continue
		# 	realpath "$f" | xargs git ls-files | grep -q . && arr+=("$f")
		# done
		# git commit -v "${arr[@]}"

		for f in "$@"; do
			[[ ! -f $f ]] && continue
			realpath "$f" |
				xargs git ls-files |
				grep -q . && echo "$f"
		done |
			largs "${cmd[@]}"

	# note: git commit -av stages -all- changes in the entire repo. this is
	# almost never what i want

	elif
		rd=$(git diff --diff-filter=RD --name-only --staged | grep .)
	then
		"${cmd[@]}"

	elif
		# 2. file(s) that have been renamed/deleted
		# this behaviour may not be desirable when modified files
		# should also be included in the commit
		# TODO: also check --staged
		rd=$(git diff --diff-filter=RD --name-only | grep .)
	then
		echo "$rd" |
			prepend "$(_get_repo_root)/" |
			xargs "${cmd[@]}"

	elif
		# 3. all staged changes
		# [git diff] "exits with 1 if there were differences"
		! git diff --staged --diff-filter=AMD --quiet
	then
		: committing staged changes
		"${cmd[@]}"

	else
		# 4. all files that have changed in the current dir
		git diff --name-only . |
			prepend "$(_get_repo_root)/" |
			grep -v .gitignore |
			xargs "${cmd[@]}"

	fi

}

gS() {
	: like gs+gl, for files to stage/commit

	# # porcelain v1 is -always- relative to repo root, which makes
	# # relativising to cwd needlessly tedious (this would probably involve
	# # splitting each line, prepending repo root to the latter part,
	# # relativising, and then rejoining!)
	# files=$(git status --porcelain)

	prv_cmd=$(
		cat <<- EOF
			echo {} | awk '{print \$NF}' | xargs git diff --color=always | grep . ||
			echo {} | awk '{print \$NF}' | xargs bat --color always --style=auto 2>/dev/null
		EOF
	)

	# by default, git status does not enter dirs containing only 1
	# (untracked) file
	sel=$(git status --porcelain=2 --untracked-files=all |
		# 1 .M N... 100644 100644 100644 <hash> <hash> package.json
		#   $2					       $NF
		# ? README.md
		#
		# $2 is more useful for tracked files (since it more closely maps to v1
		# labels), but for untracked files this duplicates the file path, so we
		# stick to $1
		#
		# https://git-scm.com/docs/git-status#_changed_tracked_entries
		#
		# HACK: i have no idea how to 'return' multiple columns inside
		# a ternary, so concat with a space as an ugly workaround
		awk '{print ($1=="?") ? $0 : $2" "$NF}' |
		fzf --multi --reverse --preview="$prv_cmd" --preview-window='right,60%,border' --ansi)
	# fzh --multi --preview="$prv_cmd" --preview-window='right,60%,border' --ansi)

	# add untracked files first
	echo "$sel" | grep -P '^\?' | awk '{print $NF}' | xargs git add
	echo "$sel" | awk '{print $NF}' | xargs git commit -v
}

gsq() {
	: squash last n commits -- rewrites history!
	# https://stackoverflow.com/a/5201642
	sha=$(_git_log_fzf | cut -d' ' -f1)
	# `git reset <sha>` brings us back to the commit -after- <sha>. this
	# means we need to select the commit before the 'target', which is
	# unintuitive. so we just go back 1 more commit with ~
	git reset --soft "$sha~"
	git commit --edit -m"$(git log --format=%B --reverse "HEAD..HEAD@{1}")"
	git push --force-with-lease origin "$(_git_current_branch)"
}

gcf() {
	: like gc, but squash the new commit with an earlier one

	# https://jordanelver.co.uk/blog/2020/06/04/fixing-commits-with-git-commit-fixup-and-git-rebase-autosquash/
	old_sha=$(_git_log_fzf . | cut -d' ' -f1)
	[[ -z $old_sha ]] && return

	# --fixup associates a new commit with an existing commit so that when
	# you do an interactive rebase, you don't have to re-order any commits
	# in order to squash them. And you don't have to change any commit
	# messages
	git commit -v --fixup "$old_sha" # "$new_sha"

	# with no arg, defaults to curr branch (NEVER use gmaster; to avoid
	# losing work, git rebase --abort immediately)
	# --autostash required to avoid 'unstaged changes present'
	git rebase --autosquash --autostash || gC
}

gapat() { # {{{
	: stage hunks matching some pattern

	# grepdiff is more reliable than git diff -S/-G
	# https://choly.ca/post/git-programmatic-staging/
	# https://blog.paddlefish.net/git-tip-stage-lines-matching-a-regular-expression/
	# https://old.reddit.com/r/git/comments/p1vltk
	git diff -U0 |
		grepdiff --output-matching=hunk -E "$1" |
		# "By default, git apply expects that the patch being applied
		# is a unified diff with at least one line of context."
		git apply --cached --unidiff-zero

	# # https://stackoverflow.com/a/52394658
	# git diff --unified=1 --pickaxe-regex -S "$1" |
	# 	grepdiff --output-matching=hunk --extended-regexp "$1" |
	# 	git apply --cached

	# see also:
	# http://www.philandstuff.com/2014/02/09/git-pickaxe.html
	# https://git-scm.com/docs/gitdiffcore#_diffcore_pickaxe_for_detecting_additiondeletion_of_specified_string

	git commit -v

	# # unstage hunks that were unnecessarily added
	# git reset -p
} # }}}

grev() {
	: revert single commit in isolation
	_git_log_fzf "$@" | awk '{print $1}' | xargs git revert
}

gRev() {
	: rollback entire index to a known good commit -- check ci first
	sha=$(_git_log_fzf "$@" | awk '{print $1}')
	git checkout -f "$sha" -- .
	git commit -av
}

gun() {
	if
		[[ $# -eq 0 ]] ||
			[[ $(_git_current_branch) == $(_gmaster) ]] && [[ $1 == . ]]
	then
		echo "cannot reset on master"
		return
	fi

	git diff "$@" | cat
	git checkout -- "$@"
	echo "undid ${#@} files"
}

guns() {
	: revert file to its state in a previous commit
	[[ $# -ne 1 ]] && return

	f=$1
	prv_cmd="echo {} | cut -d' ' -f1 | xargs -I{} git show --color=always {} $1"

	# _git_log_fzf "$1" |
	git log --oneline "$1" |
		fzf -m --preview="$prv_cmd" --preview-window='right,60%,border' --ansi |
		awk '{print $1}' |
		xargs -I{}git checkout {} -- "$f"

}

# gpick() {
# 	: cherry pick commit from other branch
# 	prv_cmd="echo {} | cut -d' ' -f1 | xargs git show --color=always"
# 	sha=$(git log --branches --remotes --tags --oneline --decorate |
# 		fzf --preview="$prv_cmd" --preview-window='right,60%,border' --ansi |
# 		awk '{print $1}')
# 	# https://stackoverflow.com/a/29788254
# 	[[ -n $sha ]] && git show "$sha" | git apply -
# }

# gac() {
# 	: append ALL changes to most recent unpushed commit
# 	git add "$@"
# 	git commit --amend --no-edit
# }

# gapc() {
# 	git add --patch "$@"
# 	git commit --amend --no-edit
# }

# }}}
# git branch # {{{
gb() { # {{{
	: switch to new branch, or existing branch

	handle_conflicts() {
		_git_has_conflicts || return
		# similar to gcon
		while _git_has_conflicts; do
			echo "Conflicts found!"
			_git_get_conflicts | xargs nvim -p
		done
		_git_get_conflicts | xargs git add
		git commit -v
	}

	default_local_branch=$(_gmaster)
	current_local_branch=$(_git_current_branch)

	if [[ $# -eq 0 ]]; then
		if [[ $default_local_branch == "$current_local_branch" ]]; then
			echo "Already on $default_local_branch"
		else
			# func retval is not propagated to parent
			git checkout "$default_local_branch" || return 1
			timeout 30 git pull
		fi
	else

		# generally, new branches should target master. however, this
		# may not always be the case, so accept an optional 2nd arg to
		# specify target branch (should be current)
		#
		# TODO: --conflict will fail if changes have been staged

		# TODO: --conflict will cause conflict markers to appear in
		# master. this is never desired, so conflicts should be
		# resolved in the current branch (i.e. -before- the checkout)

		# post checkout hook outputs to stderr
		# but real errors are probably also written to stderr?
		# git checkout "${2:-$default_local_branch}" #> /dev/null 2> /dev/null

		# git checkout --conflict=zdiff3 "${2:-$default_local_branch}"
		# handle_conflicts

		# existing remote branch > create local branch > existing local branch
		if
			! git branch | grep -qPx "[ *] $1" &&
				timeout 30 git pull &&
				git branch -r | grep -q "origin/$1"
		then
			# note: git hook stdout cannot be suppressed
			echo "Switching to remote branch $1"

			# TODO: --guess?
			git switch "$1" > /dev/null || return 1

		elif
			git switch --create "$1" "$default_local_branch" > /dev/null 2> /dev/null
		then
			# for some reason, newly created branches don't know
			# which repo to pull from
			git pull "$(_get_remote)" "$default_local_branch"

		else

			# TODO: keeping unstaged changes in the new branch is
			# just annoying, because these changes are usually
			# never meant to be committed. but --discard-changes is
			# also unsafe

			# note: .. and ... are NOT synonymous! ... is usually
			# what we want

			# presumably, ' M	' can be safely ignored?
			# git diff-tree HEAD "$1"
			# git diff-index "$1"
			# git diff --numstat "$1"...HEAD

			git diff-index "$1" |
				grep -F '00000 M	' |
				cut -f2 |
				while read -r f; do
					[[ -f $f ]] || continue
					git commit -v --untracked-files=no "$f" || git checkout -- "$f"
				done

			# plain git switch can fail, if 'files would be
			# overwritten by checkout'. with --conflict, switch
			# always succeeds, but may result in conflicts which
			# must be resolved in the new branch
			git switch "$1"
			# --conflict=zdiff3 "$1" > /dev/null
			#
			# handle_conflicts

			# # alternatively, revert all unstaged changes, then
			# # switch. this is probably more fragile
			# git switch "$branch" 2>&1 |
			# 	grep '^\s' |
			# 	xargs git checkout --

		fi
	fi

	# check if (dev) branch is behind remote
	# rev-list probably wouldn't be useful if we don't fetch though
	# note: rev-list errors if branch has no remote yet
	if [[ "$(git rev-list --left-right --count \
		"origin/$1...HEAD" 2> /dev/null | cut -f1)" -gt 0 ]]; then
		git pull
	fi

} # }}}

git_branch() {
	: switch to branch
	# https://stackoverflow.com/a/1441062
	# --pretty=format:'%h%x09%an%x09%ad%x09%s' # no color
	# TODO: include date/author, but preserve color

	_in_git_repo || return
	if [[ $(git branch | wc -l) -eq 1 ]]; then
		echo "No other branches; create one with gb <branch>"
		return
	fi

	prv_cmd=$(
		cat <<- EOF
			echo {} | sed -r 's/^[ *]+/$(_gmaster)../' | xargs git log --oneline --color=always | grep . ||
				git log --oneline  --color=always {}
		EOF
	)
	branch=$(git branch --sort=-committerdate |
		fzf --preview="$prv_cmd" --preview-window='right,80%,border' --ansi |
		sed -r 's/^[ *]+//')
	[[ -z $branch ]] && return
	gb "$branch"

}

gbd() {
	: prune local branches that no longer exist on remote -- unstaged changes will be lost!
	# https://stackoverflow.com/a/46192689
	git branch -vv |
		grep ': gone]' |
		grep -v "\*" |
		awk '{ print $1; }' |
		xargs -r git branch -D
}

# }}}
# git remote {{{
# functions that involve remote repository

_gssh() { # {{{
	: init github ssh key
	# https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent#generating-a-new-ssh-key
	#
	# note: this key must still be added to github!
	# https://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account#adding-a-new-ssh-key-to-your-account

	# password not strictly necessary
	ssh-keygen -t ed25519 -C hejops1@gmail.com -f "$HOME/.ssh/github_$(date -I)"
	ssh -T git@github.com 2>&1 | grep -q success && echo ok

	# to actually use the key on startup, add to .xinitrc (or similar);

	# if [[ -z $SSH_AUTH_SOCK ]]; then
	# 	{
	# 		pkill ssh-agent
	# 		eval "$(ssh-agent -s)"
	# 		ssh-add "$HOME/.ssh/github_2024-06-17"
	# 	} > /dev/null 2> /dev/null
	# fi

} # }}}

gmm() {
	: merge master into dev branch
	[[ $(_git_current_branch) == $(_gmaster) ]] && return
	# https://stackoverflow.com/a/20103414
	git fetch origin
	# TODO: for forks, need to sync fork (in gh), then git pull
	git merge "origin/$(_gmaster)"
}

g,() {
	git pull && return
	git diff --name-only "$(_gmaster)..origin/$(_gmaster)" |
		xargs -n1 git commit -v
	git pull && git push
}

gcon() { # {{{
	# https://nitaym.github.io/ourstheirs/

	: resolve conflicts, if any, and merge

	# git diff --name-only --diff-filter=U --relative

	if ! conflicts=$(_git_get_conflicts); then
		echo "No conflicts detected"
		return
	fi

	# all conflicts are due to lock files
	if ! <<< "$conflicts" grep -v yarn.lock; then
		<<< "$conflicts" cut -c3- |
			xargs dirname |
			while read -r d; do
				pushd "$d" || return
				yarn install || return
				git add yarn.lock
				popd || return
			done
		_git_has_conflicts && return
		git commit -v
		return
	fi

	# in case of submodule conflict:
	# cd $submodule
	# gun .
	# git merge $hash (git should tell you which hash -- how to script?)
	# git add $submodule
	# git commit

	while _git_has_conflicts; do
		if [[ -f .abort ]]; then
			git merge --abort
			return
		fi
		echo "Unresolved conflicts remaining!"
		_git_get_conflicts | xargs nvim -p
	done

	_git_get_conflicts | xargs git add
	git commit -v
}        # }}}
gnew() { # {{{
	: push to newly created remote

	# if [[ -f files_to_add ]]; then
	# 	if [[ -d .git ]] && [[ -d .git_old ]]; then
	# 		echo 'new and old git histories found, remove new one first: rm -rf ./.git'
	# 		return
	# 	fi
	# 	mv .git .git_old
	# fi

	if _get_remote; then
		return

	elif [[ ! -d .git ]]; then
		git init
		return

	elif
		! git log > /dev/null 2> /dev/null &&
			! git status --porcelain | grep -Fv '??'
	then
		echo 'no commits made yet'
		return

	else
		# WARN: this may not be desired
		git commit -m "initial commit"
	fi

	git branch -M master # don't call _gmaster!
	xdg-open https://github.com/new &
	read -rp 'Repo name (not URL!): ' repo

	# https://kbroman.org/github_tutorial/pages/init.html
	git remote add origin "https://github.com/hejops/$repo"
	git push -u origin master
	git status
	git remote set-head origin --auto

} # }}}

# gclone() {
# 	ggiturl() { <<< "$1" sed 's|http://|git@|; s|/|:|; s/$/.git/'; }
# 	ggiturl "$1" | xargs git clone
# }

# grbr() {
# 	: rebase to remote, discarding all local changes that conflict with remote
# 	# use case:
# 	# - our branch was started at the same time as another branch
# 	# - rewriting is simpler than resolving conflicts
# 	# - the other branch is much larger
# 	# - the other branch has been merged to master
# 	cr
# 	# first preserve files that were only added to in our branch
# 	# (this is a looser definition than just 'new files')
# 	git diff --numstat master...HEAD |
# 		grep -P '^\d+\t0\t' |
# 		cut -f3 |
# 		xargs git diff master...HEAD > tmp.diff
# 	# equivalent to `git rebase origin/master; git rebase --skip (repeatedly)`
# 	git rebase --strategy-option=theirs "origin/$(_gmaster)"
# 	git apply tmp.diff
# 	# git push -f
# }

# }}}

# gitlab {{{

alias gld=gldiff

# apt 1.36
# snap 1.43/1.54, but cannot read config file (lol)

# gmr() {
# 	: create or open mr in browser
# 	branch=$(_git_current_branch)
# 	url=$(_get_remote)
# 	url=$(_git_http "$url")
# 	if
# 		n=$(glab mr list --source-branch "$branch" |
# 			grep '^!' |
# 			awk '{print $1}' |
# 			tr -d '!')
# 	then
# 		echo "Opening MR $n"
# 		url="$url/-/merge_requests/$n"
# 	else
# 		echo "Creating new MR"
# 		url="$url/-/merge_requests/new?merge_request%5Bsource_branch%5D=$branch"
# 	fi
# 	xdg-open "$url" 2> /dev/null
# }

gldiff() {

	# note: for current branch, just use gdm
	if [[ $# -eq 0 ]]; then
		# n=$(glab mr list |     #--reviewer=@me |
		# 	sed -r 's/  +/\t/g' | # force tab delimiter
		# 	cut -d$'\t' -f1,3- |  # remove useless column
		# 	grep '^!' |           # remove useless lines
		# 	colt |
		# 	fzh |
		# 	awk '{print $1}' |
		# 	tr -d '!')

		# json output requires v1.37 (apt is 1.36 smh)
		# https://gitlab.com/gitlab-org/cli/-/commit/893f5c945a50cb8a6d674eb05923f87e46fa6150

		prv_cmd="echo {} | awk '{print \$NF}' | xargs -I{} git log --oneline origin/{}"

		n=$(glab mr list --output=json --reviewer=@me | #--not-draft |
			jq '.[:25][]' |
			jqt updated_at iid title assignee.username source_branch |
			sort -r |
			fzh -1 --preview="$prv_cmd" |
			# fzf --preview="$prv_cmd" |
			awk '{print $2}')

		[[ -z $n ]] && return
	else
		n=$1
	fi

	glab mr diff "$n" | sed '/Subproject commit/d' | delta

}

gci() { watch -n 30 'glab ci list -P 10 | grep -P "^\(" | column -t'; }

# }}}

# python {{{

genuv() {
	: generate dependencies of a uv script
	# would be better in vim, but i don't like writing python scripts these
	# days anyway

	pydeps() {
		: for a given file, list imports that are not in stdlib

		# note: this still includes first-party imports
		< "$1" grep -P '^(from|import)' |
			cut -d' ' -f2 |
			sort -u |
			# https://stackoverflow.com/a/75344709
			xargs python -c 'import sys
for i in sys.argv[1:]:
    if i.split(".")[0] not in sys.stdlib_module_names:
        print(i)' 2> /dev/null
	}

	# assumes there are no 1st party imports; when generating dependencies
	# of a uv script, this is probably true
	deps=$(pydeps "$1")
	[[ -z $deps ]] && return

	cat << EOF
# /// script
# dependencies = [
$(echo "$deps" | while read -r dep; do echo "#   \"$dep\","; done)
# ]
# ///
EOF

}

pget() {
	pyp=$(_get_repo_root)/pyproject.toml

	if [[ -f $pyp ]]; then
		echo "not in python project"

	elif < "$pyp" grep -Fq tool.poetry; then
		poetry add "$@"

	elif command -v uv > /dev/null; then
		uv add "$@"
	fi
}

# why can't they output json like sane people
# what does ! even mean??
# presumably, yellow is major, red is minor/patch?
# poetry show --outdated | grep -F '!' | awk '{print $1}'

pup() {
	pyp=$(_get_repo_root)/pyproject.toml

	if [[ ! -f $pyp ]]; then
		echo "not in python project"

	elif < "$pyp" grep -Fq tool.poetry; then
		poetry update "$@"

	elif command -v uv > /dev/null; then
		# https://www.loopwerk.io/articles/2024/python-poetry-vs-uv/
		# https://www.loopwerk.io/articles/2024/python-uv-revisited/
		uv lock --upgrade-package "$@"
	fi
}

# pentmd() {
# 	: render entry points as markdown
# 	# - [`poetry run XXX`](./path/to/script.py)
# 	# shellcheck disable=SC2016
# 	< pyproject.toml grep :main |
# 		sed -r 's|^([^ ]+) = "([^:]+):main"|- [`poetry run \1`](./\2.py)|g' |
# 		tr . / |
# 		sed -r 's#/(/|py)#.\1#g'
# }

# }}}
# rust {{{

# alias sqp='cargo sqlx prepare --workspace; ga .sqlx; gc' # postgres only
# cargo +nightly udeps
alias cb="cargo build"
alias cbr='cargo build --release && cp target/release/$(basename $PWD) .'
alias cn="cargo new"
alias ct="cargo test"
alias cwr="cargo watch -x run" # web servers only

# sqre() {
# 	# regen sqlite db
# 	# often required for sqlite, possibly when .sql files are modified are migration
# 	# https://github.com/launchbadge/sqlx/discussions/1292#discussioncomment-3015486
# 	sqlx database drop
# 	sqlx database create
# 	sqlx migrate run
# }

cw() {
	cargo watch -x check -x "test $1"
}

# rsmod() {
# 	if [[ -f $1 ]]; then
# 		# convert foo/bar.rs -> foo/bar/mod.rs
# 		rs=$1
# 		base=${rs/.rs/}
# 		mkdir -p "$base"
# 		mv "$rs" "$base/mod.rs"
# 		# TODO: update lib, pub use, etc
# 	elif [[ -n $1 ]]; then
# 		echo "Creating module $1"
# 		echo "pub mod $1;" >> src/lib.rs # doesn't work?
# 		mkdir -p "src/$1"
# 		mod="src/$1/mod.rs"
# 		# touch "$mod"
# 		echo "mod foo;" >> "$mod"
# 		echo "pub use foo::*;" >> "$mod"
# 	fi
# }

# }}}
# go {{{

# https://gist.githubusercontent.com/alexedwards/3b40775846535d0014ab1ff477e4a568/raw/15f15b499f626a6e3949c237d52a3e8aace1b05b/Makefile

# alias gor="\ls *.go | grep -v _test | xargs go run" # won't work with args; gob is probably better
alias gobe="go test -bench=. -run=^$ ./..." # run benchmarks only -- https://stackoverflow.com/a/16161605

gop() {
	# https://go.dev/blog/pprof
	# https://github.com/google/pprof/blob/a8630aee4ab/internal/driver/commands.go#L125
	go tool pprof -web -nodefraction=0.1 ./*.prof 2> /dev/null
}

gopk() {
	: move foo.go to foo/foo.go
	# parent must then import from foo; goimports should fix this?
	f=$1
	pkg=${f/.go/}
	[[ -d $pkg ]] && return
	mkdir "$pkg"
	sed -i -r "s/^package main/package $pkg/" "$f"
	mv "$f" "$pkg"
}

gon() {
	[[ $# -ne 1 ]] && return
	[[ -d $1 ]] && return
	if [[ -f ./go.mod ]]; then
		mkdir "$1"
		echo -e "package $1\nfunc foo(){\n}" > "$1/$1.go"
		vim + "$1/$1.go"
	else
		mcd "$1"
		go mod init "$1"
		echo "$1" > .gitignore
		echo -e "func main(){\n}" > main.go
		go build # generate go.mod
		vim + main.go
	fi
}

gob() { # build and run (gor won't work with args)
	name=$(< go.mod head -n1 | cut -d' ' -f2)
	go build && ./"$name" "$@"
}

gorep() {
	patt=$1
	repl=$2

	# # see matches
	# rg -IN "$patt" ./*.go
	# read -r -p 'press enter to preview changes'

	# preview changes
	# note: gofmt can only modify expressions, not func declarations!
	gofmt -r "$patt -> $repl" ./*.go | less
	read -r -p 'press enter to accept changes'

	# execute
	gofmt -r "$patt -> $repl" -w ./*.go
	# TODO: gapat
}

# https://leg100.github.io/en/posts/building-bubbletea-programs/

# ideally i would like gow to be spawned in a background tab (not window!),
# then gowr in the main tab, BUT wezterm tabs mess with bubbletea dims
gow() {
	: watch code changes, trigger re-build, and kill process

	# cr
	find . -name '*.go' | entr -cr go test ./...

	# [[ ! -f go.mod ]] && return
	# name=$(< go.mod head -n1 | cut -d' ' -f2)
	# while :; do
	# 	go build && pkill "$name"
	# 	# inotifywait --event attrib $(find . -name '*.go') > /dev/null || return
	# 	find . -name '*.go' -print0 | xargs -0 inotifywait --event attrib > /dev/null || return
	# done

}
gowr() { while :; do gob "$@" || break; done; } # in foreground, continously run app

god() {
	: generate documentation for file
	# godoc is only for generating stdlib docs?
	# https://pkg.go.dev/golang.org/x/tools/cmd/godoc

	pushd "$(dirname "$1")" || return
	< "$(basename "$1")" grep -P '^(type|func)' |
		grep -Pow '[A-Z]\w+' |
		sort -u |
		xargs -n1 go doc 2> /dev/null |
		grep -Pv '^package'
	popd || :
}

# }}}
# js {{{

tsc() {
	if [[ -f node_modules/.bin/tsc ]]; then
		cmd=node_modules/.bin/tsc
	elif cmd=$(which tsc); then
		:
	else
		return
	fi
	"$cmd" --version
	"$cmd" "$@"
}

# https://stackoverflow.com/a/47948461
_js_pkg_ver() { < package.json jq -r "[.dependencies, .devDependencies] | add | .$1" | tr -d '^~'; }
_js_pkgs() { < package.json jq -r '[.dependencies, .devDependencies] | add | keys[]'; }

jx() {
	pkgmgr() {
		if [[ -f yarn.lock ]]; then
			echo yarn
		elif [[ -f pnpm-lock.yaml ]]; then
			echo pnpm
		else
			echo npm
		fi

	}

	cmd=$(< package.json jq -r .scripts | grep : | fzh | cut -d'"' -f2)
	[[ -n $cmd ]] && "$(pkgmgr)" "$cmd"
}

jmake() {
	: convert scripts to Makefile

	keys=$(< package.json jq -r '.scripts | keys[]')

	cmds=$(echo "$keys" |
		while read -r cmd; do
			echo "${cmd//:/-}:" # make targets cannot contain :
			< package.json jq -r '.scripts."'"$cmd"'"' |
				sed 's/&& /\n/g; s/\"/"/g' |
				prepend '\t'
		done)

	cat << EOF | tee Makefile
.PHONY: $(<<< "$keys" tr : - | xargs)
$cmds
EOF
}

jup() {
	: upgrade npm package
	pkg=$(_js_pkgs | fzf)
	curr_ver=$(_js_pkg_ver "$pkg")
	target_ver=$(c "https://www.npmjs.com/package/$pkg?activeTab=versions" |
		grep -Po '\d+?\.\d+?\.\d+?</a></td><td class="downloads">[0-9,]+' |
		sed -r 's|</a></td><td class="downloads">|\t|' |
		sort -rV |
		sed "/^$curr_ver/,\$d; /\t0$/d" | # filter to versions newer than current
		sort -k2n |                       # sort by downloads
		fzf --tac --prompt="$pkg (current: $curr_ver)" |
		cut -f1)
	# npm install (update?) / yarn upgrade
	echo yarn upgrade "$pkg@^$target_ver"
}

jupall() {
	: this is almost certainly a bad idea!
	_js_pkgs | xargs -n1 -I{} yarn upgrade {}@latest
}

# perfnode() {
# 	if [[ $# -gt 0 ]]; then
# 		# creates perf.data
# 		perf record -e cycles:u -g -- node --perf-basic-prof "$@"
# 	elif [[ -f perf.data ]]; then
# 		# https://nodejs.org/en/learn/diagnostics/flame-graphs#create-a-flame-graph-with-system-perf-tools
# 		# https://speakerdeck.com/mrfoto/what-are-flame-graphs-and-how-to-read-them
# 		perf script | # reads perf.data
# 			# remove internal
# 			sed -r -e "/( __libc_start| LazyCompile | v8::internal::| Builtin:| Stub:| LoadIC:|\[unknown\]| LoadPolymorphicIC:)/d" \
# 				-e 's/ LazyCompile:[*~]?/ /' |
# 			# show only user defined functions
# 			grep -e "$USER" -e '^\S' -e '^$' |
# 			stackvis perf > flamegraph.htm
# 		chromium flamegraph.htm 2> /dev/null &
# 	fi
# }

# }}}
# c {{{

x() {
	\ls ./*.c 2> /dev/null || return
	n=$(basename "$(realpath .)")
	gcc -o "$n" ./*.c && "./$n"
}

mch() {
	# f=$1

	: [re]generate header files
	for f in *.c; do
		[[ $f == main.c ]] && continue

		h="${f/.c/.h}"
		if [[ -f $h ]]; then
			# for merge to work, fn decls must all be placed at the
			# bottom of the .h file. includes, macros, structs
			# should be placed at the top. (is there a recommended
			# order?)
			{
				< "$h" grep -Pv '\);$' # discard existing fn decls
				cproto "$f" | sed 1d   # cproto only generates fn decls
			} | sponge "$h"
		else
			cproto "$f" > "$h"
		fi
	done
}

# }}}
# sql {{{

if [[ -n $POSTGRES_URL ]]; then
	alias psql='psql $POSTGRES_URL'
fi

sq() {

	{
		if [[ -f $1-wal ]]; then
			cp "$1" tmp.db > /dev/null
			echo "$2" | sqlite3 tmp.db
		elif [[ -f $1 ]]; then
			echo "$2" | sqlite3 "$1"
		fi
	} | jq '.[]'

	# if [[ -f $1 ]]; then
	# 	< "$2" sqlite3 "$1"
	# else
	# 	echo "$2" | sqlite3 "$1"
	# fi
	# # echo "Not a file: $1"

}

# sqbrk() {
# 	: i have no idea what this was supposed to do
# 	sqruff fix -f=json --force "$@" |
# 		jq -r 'to_entries[] | .value=.value[].range.start.line | [.key, .value|tostring] | join("\t")' |
# 		while read -r f lnum; do
# 			# TODO: nothing can be done about url comments that are
# 			# too long (other than removing them)
# 			line=$(sed "${lnum}q;d" "$f")
# 		done
# }

psqlj() {
	: convert psql output to jq
	# useful for times when it is easier to write jq than sql
	# https://www.pgcasts.com/episodes/generating-json-from-sql
	psql "$POSTGRES_URL" -c "select row_to_json(t) from ($1) t" |
		grep -Po '\{.+' |
		jq
}

# }}}
# jq {{{

alias jqc="jq -c" # basically just colors output

jqk() {

	: https://gist.github.com/pedroxs/f0ee8c515eea0dbce2e23eea7c048e10#file-jq-filters-sh-L2
	jq < /dev/stdin -r '.. | objects | with_entries(select(.key | contains("'"$1"'"))) | select(. != {}) | .'"$1"
}

jqt() {

	: select jq fields from a flat sequence of objects and format as tsv with alignment
	fields=()
	for x in "$@"; do
		fields+=(".$x")
	done
	query="$(ajoin "${fields[@]}")" # .foo,.bar,.baz

	# query="[$(echo "$@" | sjoin ,)]"

	# note: jq knows how to if read from stdin if no file passed
	< /dev/stdin jq -r "[$query] | @tsv" | colt

}

# }}}

# docker {{{

alias dolf='docker logs --tail=1 -f'

dolc() {
	: clear logs of docker image without restart
	# https://stackoverflow.com/a/42510314
	[[ $# -eq 0 ]] && return
	name=$1
	json="$(docker inspect --format='{{.LogPath}}' "$name")"
	# [[ ! -f $json ]] && return
	sudo "$(command ls)" "$json" > /dev/null || return
	# doesn't work for go binary? file -is- cleared, but `docker logs` still produces old output
	: | sudo tee "$json"
	sudo du "$json"
	echo "cleared $name $json"

	# remove lines with null bytes
	# https://stackoverflow.com/a/77907885
	sudo grep -r -l -a -P '\x00' /var/lib/docker/containers/ |
		while read -r f; do
			sudo perl -pi -e 's/\x00//g' "$f"
		done

	# dolf "$name"
}

# alias dps='docker ps -a --format "table {{.Names}}\t{{.State}}\t{{.Status}}\t{{.ID}}\t{{.RunningFor}}" | sort'

dps() {
	# docker ps adds too much padding, and cannot truncate long values
	docker ps -a --format=json |
		# note: ID is usually just visual noise, but placing it any
		# later in the seq will make it hard to extract (with cut/awk)
		jqt 'Names[0:40]' State ID Status RunningFor |
		# jq -r '[.Names[0:40], .State, .ID, .Ports, .Status, .RunningFor] | @tsv' |
		sort |
		column -t -s $'\t' # https://unix.stackexchange.com/a/57235
}

doslow() {
	: list slowest steps in a docker log

	if [[ $# -eq 0 ]]; then
		# devc logs

		# prev=''
		grep -RPh '\d+/\d+\]' .config/Code/logs/*/window1/exthost/ms-vscode-remote.remote-containers |
			grep -P '\d{3,}\.\ds$' |
			cut -d= -f2- |
			sort -nr |
			sort -u |
			# dedup by step
			while read -r line; do
				step=$(<<< "$line" cut -d' ' -f2)
				if ! <<< "$prev" grep -Fq "$step"; then
					echo "$prev"
				fi
				prev=$line
			done |
			awk '{print $NF,$0}' |
			sort -nr |
			cut -f2- -d' '

		return
	fi

	if
		steps=$(< "$1" grep -P '^#\d+ DONE' |
			sort -Vu |
			awk '!a[$1]++') &&
			[[ -n $steps ]]
	then
		paste <(echo "$steps") <(
			<<< "$steps" cut -d' ' -f1 |
				while read -r n; do
					< "$1" grep "$n" |
						tac |
						grep -Pm1 "$n \[" |
						cut -d' ' -f2-
				done
		)
	else
		echo all ok
	fi
}

docl() {
	docker system df
	docker system prune --all
	docker volume ls -f dangling=true -q | xargs docker volume rm # usually not important

}

dostop() {
	docker ps --all --quiet | xargs docker stop
}

donuke() {
	: stop and remove all containers
	mapfile -t containers < "$(docker ps --all --quiet)"
	docker stop "${containers[@]}"
	docker rm "${containers[@]}"
}

# # list docker containers responsible for a given high-memory/cpu process
# top -bn1 |
# 	grep -m5 python |
# 	cut -d' ' -f1 |
# 	xargs -n1 pstree -as |
# 	grep moby |
# 	sort -u |
# 	grep -Po '[0-9a-f]{64}' |
# 	xargs -I{} sudo docker ps -f id={}

# }}}
# ssh {{{

# rsync ~/.config/readline/inputrc "$remote:$HOME/.inputrc"
# ssh "$remote" 'touch ~/.hushlogin' # suppress annoying ubuntu login msg

# sget() {
# 	remote=$1
# 	if [[ -f $1 ]]; then
# 		rsync --no-relative --files-from="$1" "$remote:/" .
# 	else
# 		rsync --exclude=".*/" "$remote:$1" .
# 	fi
# }

# sget() { rsync --exclude=".*/" "$1:$2" .; }
# sput() { rsync --exclude=".*/" "$2" "$1:~/"; }

# https://gist.github.com/cmbaughman/6a2ae275e0c0f39f42d95a728e07f796
# https://www.redhat.com/sysadmin/ssh-automation-sshpass

# }}}
# files, navigation {{{

zd() { zip -jr "${1%/}" "${1%/}"; }                         # zip directory (flat); stripping trailing slash is important
zin() { < /dev/stdin zip --junk-paths --names-stdin "$1"; } # pipe files from stdin to zip

f() {
	case $1 in

	n | new | mtime) find "${2:-.}" -maxdepth 1 -type f -printf "%T+\t%p\n" |
		sort |
		cut -f2 ;;

	# https://unix.stackexchange.com/a/22448
	s | sz | size) find "${2:-.}" -type f -exec du -a {} + |
		sort -n ;;

	esac
}

mcd() {
	: mkdir any number of paths, cd to last
	# it is uncommon for >1 arg to be passed, so this is more for cd
	# [[ $# -eq 0 ]] && return
	local p
	for p in "$@"; do mkdir -p "$p" || :; done
	# shellcheck disable=SC2164
	[[ -d $p ]] && cd "$p"
}

if [[ -n $MU ]]; then
	: wrap rm in a python check to prevent accidental deletion of some dir
	rm() {
		# parsing arbitrary args with bash is nonsense

		if [[ $* == *"$MU"* ]]; then
			python3 -c "
import sys
if \"$MU\" in {x.rstrip('/') for x in sys.argv}:
    print('FATAL')
    raise Exception
" "$@"
		fi

		command rm -v "$@"
	}
fi

rgo() {
	: useful when you know what to look for but dont want to open vim
	# https://blog.burntsushi.net/ripgrep
	# https://github.com/nvim-telescope/telescope.nvim/blob/7b5c5f56a21e82fdcfe5b250278b8dfc4b1cbab4/lua/telescope/config.lua#L646
	# $1 = fzf query generally more useful than $1 = file
	match=$(rg --color=never --no-heading --with-filename --line-number --column --smart-case '^.+$' . |
		fzf -e -q "${1:-}")
	[[ -z $match ]] && return

	# file:line:col:match
	IFS=':' read -ra array <<< "$match"

	# TODO: --glob '!libs/*' (! must be single quoted)

	{
		# force insert into history
		echo "vim $(realpath "${array[0]}")"
		echo "#$(date +%s)"
	} >> ~/.bash_history

	# note: this won't go into history (only rgo will)
	"$EDITOR" +"${array[1]}" "${array[0]}"

}

j() {
	: jump to frequently used file, should be used in conjunction with rgo
	sel=$(< ~/.bash_history grep -P '^n?vim' |
		awk '!seen[$0]++' |
		while read -r cmd; do
			f=$(<<< "$cmd" cut -d' ' -f2)
			f=$(realpath "$f" 2> /dev/null) || continue
			[[ ! -f $f ]] && continue
			echo "$f"
		done |
		awk '!seen[$0]++' |
		fzf --tac)
	[[ -z $sel ]] && return
	"$EDITOR" "$sel"
}

files() {
	: list files in use by a process
	pidof "$1" |
		tr ' ' , |
		xargs lsof -p 2> /dev/null |
		grep -Po '/[a-z].+' |
		sort -u |
		grep -P --color=never '^/(home|run)'
}

# TODO: firefox xcb problem; vscode can be ruled out. possibly chromium?
# pidof firefox | tr ' ' , | \xargs lsof -p | grep --color=auto -Po '/[a-z].+' | sort -u | grep xcb
# ls /snap/firefox/current/gnome-platform/*
# "/snap/firefox/current/gnome-platform/*": No such file or directory (os error 2)

# }}}
# stdout manipulation {{{

append() { < /dev/stdin awk "{print \$0 \"$1\"}"; }
desec() { < /dev/stdin sed -r 's/:[0-9]{2}\.[0-9]{8,}Z//'; } # for ease of filtering logs
largs() { < /dev/stdin xargs --delimiter='\n' "$@"; }        # split xargs by newline instead of space
line() { < /dev/stdin sed -n "${1}p"; }
ljoin() { < /dev/stdin tr '\n' , | sed 's/,$//'; } # lines to comma-delimited str
paren() { < /dev/stdin prepend '(' | append ')'; }
prepend() { < /dev/stdin awk "{print \"$1\" \$0}"; }
sum() { < /dev/stdin paste -sd+ | bc; }
surround() { < /dev/stdin awk "{print \"$1\" \$0 \"$1\"}"; }
tojson() { node --eval "console.log(JSON.stringify($(< /dev/stdin)))" | jq; }

# highlight query, but output the entire file
# grep "$query\|$"

ajoin() {
	: join space-delimited array
	# # https://stackoverflow.com/a/9429887

	# stdin=$(< /dev/stdin)
	# if [[ -n $stdin ]]; then
	# 	# mapfile -t input < /dev/stdin
	# 	mapfile -t input < <(echo "$stdin" | \xargs -n1) # bruh
	# else
	# 	input=("$@")
	# fi

	input=("$@")
	IFS=,
	echo "${input[*]}"
}

dehtml() {
	# https://stackoverflow.com/a/19878198
	< /dev/stdin sed -e 's/<br[^>]*>/\n/g; s/<[^>]*>//g' |
		# recode xml..utf8 |
		# https://stackoverflow.com/a/13161719
		perl -MHTML::Entities -pe 'decode_entities($_);'
}

plot() {
	: plot latency from json logs
	script=$(
		# https://unix.stackexchange.com/a/754698
		# https://superuser.com/a/108380
		cat <<- EOF
			show terminal;
			set ylabel 'ms';
			set xdata time;
			set timefmt '%Y-%m-%dT%H:%M';
			plot '-' using 1:(\$2/1000000)
		EOF
	)
	# echo "$script"
	< "$1" grep latency |
		grep -Fv -e null -e '={' | # remove invalid nested json
		# tail -n10000 |
		jqt time[0:19] latency |
		time gnuplot --persist -e "$script"
}

# }}}
# web {{{

,c() {
	# note: arch's prettier may hold back node versions, so it is usually
	# better to use mason's one and symlink it to .local/bin
	c "$1" | prettier --parser html
	# c "$1" | lynx -stdin -dump
	# tidy injects extra stuff
}

,,c() {
	# uses a different user agent from curl. in most cases, it is probably
	# better to just get ua from firefox
	: alternative to curl
	python3 -c '
import codecs
import sys

from bs4 import BeautifulSoup
import cloudscraper

byt = cloudscraper.create_scraper().get(sys.argv[1]).content
s = BeautifulSoup(byt, "html.parser").prettify()

# print(s)

# forcefully decode "unicode-strings" e.g. u002F
print(codecs.decode(s, "unicode-escape"))

' "$1"

}

alias C=,,c

upload() {
	: upload file to catbox.moe, copy link to clipboard

	# https://github.com/Allypost/bash-scripts/blob/fa4b1006a1c022484c3d48a05ec0ff1c94b9a541/catbox#L116
	# https://github.com/mananapr/dotfiles/blob/9dc9196224c2c84e4265e517dc36af1c79637eb7/bin/catbox
	# https://github.com/search?type=code&q=curl+catbox.moe+language%3AShell+fileupload

	[[ ! -f $1 ]] && return
	link=$(
		curl -s --form "reqtype=fileupload" \
			--form "fileToUpload=@$1" \
			https://catbox.moe/user/api.php #| tee /dev/null
	)

	echo -en "Uploaded to: \e[1m$link\n" # idk what that escape does
	echo -n "$link" | xclip -sel c
}

wifi() {
	: connect to wifi network without nmtui
	ssid=$(nmcli --terse device wifi list |
		fzf --reverse |
		cut -d: -f8 |
		xargs)
	nmcli --ask device wifi connect "$ssid" # password $password
}

getmail() {
	mail 2>&1 | grep 'No new mail.'
	[[ $(notmuch count tag:inbox and tag:unread and date:today) -eq 0 ]] && return
	TERM=xterm-direct exec neomutt
}

get_cookie() {
	\cp ~/.mozilla/firefox/*default/cookies.sqlite tmp.db
	sql="select value from moz_cookies where name = '$1' order by id desc limit 1"
	sqlite3 tmp.db "$sql"
	rm tmp.db > /dev/null
}

# seq 1 10 |
# 	while read -r i; do
# 		curl -sL "https://vimcolorschemes.com/i/new/b.dark/$([[ $i -gt 1 ]] && echo "p.$i")" |
# 			grep -Po 'href="[^"]+' |
# 			tail -n20
# 	done |
# 	cut -d/ -f2- |
# 	sort -u

# }}}

alias imm="notmuch show from:noreply@immobilienscout24.de |
	grep -Po 'Adresse: [^(]+' |
	sed -r 's/([a-z])([A-Z])/\1\t\2/' |
	sort -u |
	colt"

geocode() {

	# https://www.google.com/maps/@?api=1&map_action=pano&viewpoint=45.60343636072756,-73.72799336003183

	: transform placename to coordinates
	# TODO: handle places requiring resolution (e.g. alis peru)
	c -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:138.0) Gecko/20100101 Firefox/138.0' \
		"https://www.google.com/maps?q=$1" | # WARN: prone to 429 (esp if no ua)
		grep -Po '\d+\.\d+,\d+\.\d+\]' |
		sed -r 's/(\.[0-9]{3})[0-9]*/\1/g' | # truncate to 3dp (if too specific, isv bails and renders nothing)
		line 3 |                             # extremely arbitrary, need a better grep
		tr -d ']' |
		# when isv gets low-precision coords, it does best effort
		# match, and can end up indoors
		xargs -I{} firefox "https://www.instantstreetview.com/@{},h,p,z"

}

# < ~/geo/geo.csv shuf -n3 | cut -d, -f-2

# df | grep '/$' | cut -d' ' -f1 | xargs sudo smartctl -a

# clickhouse-local --file "$1" --query "$2 FORMAT PrettyCompact"

# could replace xfer with this
# python3 -m http.server -d .

# # analyse complexity via indentation
# < "$1" grep -Po '^\s+' | sed 's/\t/x/g' | sort | uniq -c

# echo ${files[@]} | entr -cr $cmd

kb() {
	if lsusb | grep -iq ergo; then
		# https://en.akkogear.com/faq/how-do-i-get-hold-tap-keys-by-via/
		# https://github.com/gabrielmscampos/ergodash-fw
		# https://github.com/AndrewKlement/ErgoDash_VIA/blob/main/ErgodashVia/keymap.json

		# pass env vars to dbus via systemd?
		# required for file picker; only once per boot (?)
		# https://bbs.archlinux.org/viewtopic.php?pid=2161602#p2161602
		source /etc/X11/xinit/xinitrc.d/50-systemd-user.sh

		ci https://usevia.app/design

	elif lsusb | grep -q Kinesis; then
		f=/run/media/"$USER"/ADV360/layouts/layout1.txt
		if [[ ! -f $f ]]; then
			echo 'connect first'
			inotifywait -e create "/run/media/$USER"
		fi
		vim "$f"

	# elif lsusb | grep -iq elora; then
	# 	exec /opt/vial-appimage/vial-appimage.AppImage

	fi
}

subs() {
	# https://www.azsubtitles.com/restful-api
	# TODO: fname -> infer title
	c "https://www.azsubtitles.com/api/search?q=${1// /+}" |
		jq -r '.Items[0] | .UID' |
		prepend 'https://www.azsubtitles.com/api/movie' |
		xargs curl -sL |
		# File can contain a list of episodes, but we usually just want the first element
		jq -r '.AllSubs[] | select(.Language.Title == "English") | .File[0].Url' |
		sort |
		# head -n1 |
		fzf --preview="curl -sL --globoff {} | head" |
		sed -r 's/ /%20/g' | # url must be encoded
		xargs curl --globoff # but also need globoff to ignore {}[]

}

tvll() {
	: truncate vim lsp.log -- should be nvim autocmd, or session startup
	i=90
	while
		[[ $i -ge 60 ]] &&
			d=$(date --date="$i days ago" -I) &&
			! < ~/.local/state/nvim/lsp.log grep -q "$d"
	do
		((i--))
	done
	echo "$d"
	sed -i -r "1,/$d/d" ~/.local/state/nvim/lsp.log
}

kp() {
	url='https://www.discogs.com/search/?style_exact=K-pop&sort=hot%2Cdesc&ev=gs_ms'
	curl -sL "$url" -H 'User-Agent: M' -H 'Upgrade-Insecure-Requests: 1' |
		grep -Po '/release/\d+-[^"]+' |
		cut -d'-' -f2- |
		tr '-' ' ' |
		# TODO: percent decode
		sort -u |
		while read -r rel; do
			echo "$rel"
			ya "$rel"
		done
}

rge() {
	: edit files matching pattern
	staged=$(rg --files-with-matches "$@" | sort -u)
	if [[ $(<<< "$staged" wc -l) -gt 10 ]]; then
		echo "More than 10 files found"
		return
	fi
	echo "$staged" | xargs nvim -p
}

_unused() {
	: list unused functions
	< ~/.bash_aliases grep -Po '^[a-z]\w+\(\)' |
		tr -d '()' |
		while read -r cmd; do
			< ~/.bash_history grep -wq "$cmd" && continue
			< ~/.bash_aliases grep -Pq "^$cmd\(\) \{.+; \}" && continue # ignore one-liners
			# len=$(< ~/.bash_aliases sed -rn "/^$cmd\(/,/^\}/p" | wc -l)
			len=$(type "$cmd" | wc -l) # more compact, 'neutralises' linebreaks
			echo "$len:$cmd"
		done |
		sort -n

	# # scripts explicitly called from cli
	# \ls ~/scripts | while read -r f; do
	# 	history | grep -wq "$f" && [ -x ~/scripts/"$f" ] && echo "$f"
	# done

	# # scripts accessed within the last 3 days (don't ask me why 3)
	# find ~/scripts -maxdepth 1 -type f -atime -3 -exec basename {} \; |
	# 	sort -u |
	# 	grep -v gitignore |
	# 	prepend "$HOME"/.local/bin/ #| largs chezmoi add -f

}

# rng() { for _ in "$(seq "${2:-1}")"; do echo $((1 + RANDOM % ${1:-100})); done; }
,pgrep() { \pgrep "$1" | xargs ps; } # ps for runtime
pk() { pgrep "$1" | fzf -m --tac | cut -d' ' -f1 | xargs kill -9; }
pkill1() { \pgrep "$1" | sed 1d | xargs kill; }                                            # kill all procs except 1st
rng() { while read -r _; do echo $((1 + RANDOM % ${1:-100})); done < "$(seq "${2:-1}")"; } # shellharden
ya() { mpv --video=no "ytdl://ytsearch10:\'$*\'"; }
yi() { yt-dlp --dump-single-json --skip-download "$1" 2> /dev/null | jq -r '.title, .description, .webpage_url, .channel_url'; }
yt() { mpv --force-window "ytdl://ytsearch10:\'$*\'"; }

ys() { # read youtube subs in less
	yt-dlp -j "$1" |
		jq . |
		grep '=vtt' |
		grep -v tlang |
		tail -n1 | # auto subs are listed first
		cut -d'"' -f4 |
		xargs curl -sL |
		dehtml |
		grep -v -- '-->' |
		grep -Pvx '\s*' |
		tr '\n' ' ' |
		fold --spaces |
		less
}

yti() {
	: get info for currently playing file with youtube id
	# www-watch?v=bMEfWLA-V00.mp3
	# TODO: pgrep mpv is probably easier innit
	pactl list sink-inputs |
		grep media.name |
		cut -d= -f3 |
		cut -d. -f1 |
		prepend 'https://youtube.com/watch?v=' |
		xargs yt-dlp -j 2> /dev/null |
		jq -r .title
}

nico() {
	# set -x
	# TODO: investigate --headless mode
	: launch searches in nicotine
	[[ ! -f $1 ]] && return
	xdotool key super+8
	# ensure window is focused!
	i=0
	while read -r line; do
		[[ -z $line ]] && break

		# slsk blocks all searches after a while
		# TODO: where are logs written to?
		((i++))
		[[ $i -ge 68 ]] && break

		echo "$i: $line"
		echo "$line" | xclip -sel c
		xdotool key ctrl+2 F6 ctrl+v enter
		sleep 3
	done < "$1"

	notify-send 'done'
}

epk() {
	: fix malformed epubs

	# according to the spec, `mimetype` must be the first listed file. note
	# that malformed epubs are still readable in zathura, so this is mainly
	# to prevent yazi from treatting malformed epubs as zip.

	tmpdir=tmp
	tmpname=foo

	for f in *.epub; do

		# https://github.com/ikrukov/epub/blob/c663821de66d57b3d138dc9125251f40ea755c2c/script/pack_epub#L25
		# https://www.mobileread.com/forums/showthread.php?t=299415

		unzip -l "$f" > /dev/null 2> /dev/null || continue                 # corrupt (unreadable)
		file --mime-type "$f" | grep -q 'application/epub+zip' && continue # ok

		unzip "$f" -d "$tmpdir"
		cd "$tmpdir" || :
		echo 'application/epub+zip' > mimetype
		zip -X -0 --quiet "$tmpname" mimetype
		zip -X -9 --quiet --no-dir-entries --recurse-paths "$tmpname" META-INF OEBPS
		cd ..
		\mv "$tmpdir/$tmpname.zip" "$f"
		\rm -rf "$tmpdir"
		echo "fixed $f"

	done
}

watchmem() {
	: watch memory usage of pid
	pid="$(< /dev/stdin)"

	if [[ $pid =~ ^[0-9]+$ ]]; then
		watch -d ps -o %cpu,%mem,cmd -p "$pid"

	# else
	# 	pid=$(ps aux |
	# 		grep "$1" |
	# 		head -n1 |
	# 		awk '{print $2}')
	# 	while true; do
	# 		pmap -x "$pid" | tail -n1
	# 		sleep 2
	# 	done

	fi

}

gev() {
	: get env var
	find . -type f -name '.*env' -print0 |
		# probably better to force upper, but whatever
		\xargs -0 grep -Pi "$1" |
		awk -F: '!a[$2]++' |
		sed -r 's/:/	/' |
		column -s '	' -t
}

scan() {
	cd ~/scores || return
	f=$1
	n=1
	echo 'type x to exit'
	res=600
	while true; do
		echo -n "$n: "
		read -r ans < /dev/tty
		[[ $ans == x ]] && break
		# 600: 30 sec, 4.4 MB
		# 2400: 8 min, 48 MB
		scanimage --format=pdf --progress --resolution="$res" \
			--output-file "$f-$n-$res.pdf"
		((n++))
	done
	pdfunite "$(find . -name "$f-*" | sort -V)" "$f.pdf"
	rm -I "$f"-*
}

# note: sendmail unresponsive
# note: it is not known what set up is needed
# echo "$body" | mail --subject="$subject" $email

mdr() {
	articles=$(c 'https://www.mdr.de/nachrichten/index.html' |
		grep 'class="headline" ' |
		prepend '<li>' |
		html2markdown --domain https://www.mdr.de |
		sort -u |
		grep -v /podcast/ |
		sed -r '1d; s/\[(.+)\]\((.+)\)/\1	\2/g')

	urls=$(<<< "$articles" cut -f1 | fzf -m --reverse)

	echo "$urls" |
		while read -r t; do
			<<< "$articles" grep -F "$t	"
		done |
		cut -f2 |
		sort -u |
		while read -r url; do
			echo "# $url"
			curl -sL "$url" |
				sed -n '/<p class="text">/,/<\/p>/p' |
				html2markdown
		done |
		lowdown -sTms |
		pdfroff -tik -Kutf8 -mspdf |
		zathura --mode=fullscreen -
}
