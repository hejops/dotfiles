# shellcheck shell=bash
# vim:ft=sh
# if possible, this file should remain under 1000 LOC. interactive shell
# startup time should remain under 0.02 s

_base_completer() {
	# https://mill-build.org/blog/14-bash-zsh-completion.html#_conclusion
	# https://www.gnu.org/software/bash/manual/html_node/A-Programmable-Completion-Example.html

	# fallback to default file completion after 1st completion
	# https://stackoverflow.com/a/22827323
	if ((COMP_CWORD > 1)); then
		COMPREPLY=()
		return
	fi

	local f=$1 # func(string) string
	_gen() {
		local idx=$1
		shift
		local words=("$@")
		local curr_fragment=${words[idx]}

		# for a func with 1 arg, only this func needs to change
		f "$curr_fragment"
	}

	# COMP_CWORD: number of "completely typed" words (e.g. `$ foo b|` == 1 word, but `$ foo b |` == 2 words)
	# COMP_WORDS: all words currently typed

	# local raw
	# mapfile -t raw < <(_gen "$COMP_CWORD" "${COMP_WORDS[@]}") # SC2207
	# local matches=("${raw[@]}")
	# if ((${#raw[@]} == 1)); then # 1 match, autocomplete
	# 	# matches+=("${raw[0]%%:*}")  # strip from : onwards (could use \t, for example)
	# 	matches+=("${raw[0]}")
	# fi

	local IFS=$'\n'
	local matches
	mapfile -t matches < <(_gen "$COMP_CWORD" "${COMP_WORDS[@]}")

	if
		# if COMPREPLY is an array with only one unique element, the
		# completion is accepted immediately (with trailing space)
		((${#matches[@]} == 1))
	then
		COMPREPLY=("${matches[0]}")

	else
		# otherwise, the maximally left-matching prefix is
		# autocompleted (if any), and all elements in the array are
		# displayed (with the prefix highlighted)
		COMPREPLY=("${matches[@]}")
	fi

}

_complete_make() {
	f() { < ./Makefile grep -Po "^${1:-[a-z]}[a-z-]*:" | tr -d :; }
	_base_completer f
}
complete -o bashdefault -o default -F _complete_make make # not sure if option order is significant

_complete_pnpm() {
	# pnpm -h is too slow (0.2s)
	f() { < package.json jq -r '.scripts|keys[]' | grep "${1:-.}"; }
	_base_completer f
}
complete -o bashdefault -o default -F _complete_pnpm pnpm

# complete -o bashdefault -o default -F 'f() { < package.json jq -r ".scripts|keys[]" | grep "${1:-.}"; }; _base_completer f' pnpm

# startup {{{

# https://silverrainz.me/blog/2025-09-systemd-fzf-aliases.html

# https://wiki.archlinux.org/title/Systemd#Boot_time_increasing_over_time
# systemd-analyze blame | grep -P '\ds'
# systemd-analyze critical-chain
#
# sudo systemctl disable NetworkManager-wait-online.service # https://askubuntu.com/a/1018731
#
# journalctl --disk-usage                                                          # current usage
# journalctl -b -u systemd-journald | grep max                                     # current max
# sudo journalctl --vacuum-time=3d                                                 # truncate
# sudo sed -i -r 's/#SystemMaxUse.+/SystemMaxUse=100M/' /etc/systemd/journald.conf # set max (should be done on arch install)

# TODO: SystemMaxUse only affects system.journal? does not prevent
# /var/log/journal from filling up

# docker is disabled for now, because i literally never use it
# sudo systemctl disable docker.service

if [[ -f /tmp/updates ]] && ! pgrep pacman > /dev/null; then

	cat /tmp/updates

	if
		< /tmp/updates grep -q '^python ' &&
			! < /tmp/updates grep -Pq 'python (3\.\d+)\S+ -> \1'
	then
		echo -e "WARNING: major Python update\n"
		# TODO: update globally installed pips? (scrobblerh)
	fi

	if
		< /tmp/updates grep -q '^postgresql ' &&
			! < /tmp/updates grep -Pq 'postgresql (\d+)\S+ -> \1'
	then
		echo -e "WARNING: major postgresql update\n"
	fi

	if sudo pacman -Syu; then
		rm /tmp/updates

		# may get unset after update? not sure what causes it
		setxkbmap -layout us -option -option compose:rctrl #,caps:menu

	elif
		# if pacman hasn't been run in a long time, keys in keyring
		# will expire. pacman -Syyu OR updating archlinux-keyring
		# should fix this
		command -v expac > /dev/null &&
			last_update=$(expac --timefmt '%s' "%l" | sort -n | tail -n1) &&
			# https://stackoverflow.com/a/6948865
			[[ $(((last_update - $(date +%s)) / (60 * 60 * 24))) -gt 14 ]]
	then
		sudo pacman -Sy archlinux-keyring

	fi
fi

ps --pid "$PPID" | grep -Fq wezterm &&
	[[ -s /tmp/verse ]] &&
	cat /tmp/verse

[[ -d $SLSK ]] &&
	# i like the idea of BASH_REMATCH, but it is unfortunate that
	# \S (et al) is not supported. there is no noticeable performance
	# difference
	# https://www.bashsupport.com/bash/variables/bash_rematch/
	[[ $(du -csh "$SLSK"/complete | tail -n1) =~ ^([0-9]+).*G ]] &&
	# [0] = full line (like awk)
	# [@] = full line + all matches
	((BASH_REMATCH[1] >= 3)) &&
	echo -e "\n${BASH_REMATCH[0]}"

if
	# note: ls foo bar fails if any arg does not exit
	x=$(! ls /tmp/ssh-XXXXXX*/agent.* &&
		# openssh v10.1
		# https://www.openssh.org/txt/release-10.1
		! ls ~/.ssh/agent/s.*.agent.*)
then
	# pkill ssh-agent # deletes all existing sockets
	eval "$(ssh-agent -s)" > /dev/null

elif [[ -z $SSH_AUTH_SOCK ]]; then
	SSH_AUTH_SOCK=$(<<< "$x" head -n1)
	export SSH_AUTH_SOCK
	find ~/.ssh -name 'gitlab*' | grep -v .pub | \xargs ssh-add -q

fi
unset x

[[ -f ~/jira.txt ]] && < ~/jira.txt cut -f1,3

# }}}
# aliases {{{

# alias dr=discogs_rate
# alias lc=leetcode.py # shadows lc binary (who?)
# alias mb=musicbrainz
# alias trk=trackratings.py
# alias wd=waitdie
alias ex=extract
alias gm=getmail
alias met=metronome
alias ns=notify-send
alias sk=slock
alias tt=taptempo
alias xo=xdg-open

alias rab='exec yazi "$HDD/books"'
alias rad='exec yazi "$SLSK/complete"' # TODO: investigate `ya pub`
alias rag='exec yazi "$HDD/guitar"'
alias ram='exec yazi "$MU"'
alias rat='exec yazi "$HDD/movies"' # "$HDD/torrent"

# alias dA="dc artist:"
# alias dc="discogs_collection filter"
# alias dt="discogs_collection top"
# alias lock="[[ -d /sys/class/power_supply/BAT0 ]] && systemctl suspend && slock"
# alias mem='top -b -n1 -o %MEM | grep -m10 $USER'
# alias mem='top -bn1 | sed -rn "/PID/,$p" | sort -k10 -n | tail'
# alias pq="~/plaque/plaque"
# alias tx="tectonic -X"
# top -bn1 | sed -rn '/PID/,$p' | sed 1d | awk '{print $10}' | sum
alias au="audacious -H"
alias bh="vb -b"
alias cam="ls /dev/video* && exec mpv --fs av://v4l2:/dev/video0 --profile=low-latency --untimed" # TODO: handle >1 video device (just increment n until file not exist)
alias cdnp='cd "$(files mpv | grep mp3 | largs dirname)"'
alias ci="chromium --incognito"
alias colt="column -t -s$'\t'" # align tab-containing output -- https://unix.stackexchange.com/a/57235
alias cpu='top -b -n1 -o %CPU | grep -m10 $USER'
alias ctz='sudo timedatectl set-timezone $(timedatectl list-timezones | grep / | fzf)' # TODO: geolocate
alias cv='exec $EDITOR ~/cv/cv.typ'
alias datez='date -u +%FT%TZ' # utc (i.e. ignore current timezone)
alias eb="exec bash"
alias fzh="fzf --reverse --height=~33%" # height=~X% means min(input rows, window height * X%);
alias fzr="fzf --reverse --preview='bat --color=always --style=auto {}' --preview-window='right,60%,border'"
alias inw="inotifywait --monitor --recursive"
alias li="exec chromium --incognito 'https://www.linkedin.com/notifications/?midToken=AQECUGJ6GKhRSg'"
alias or="bash ~/gripts/oar/run.sh"
alias ports="netstat -tunlp | grep -Pw '^(udp|tcp)' | sort -k4 -V" # https://linuxize.com/post/check-listening-ports-linux/#check-listening-ports-with-netstat
alias pss="ps -e --format=lstart,pid,cmd --sort=start_time | grep -Fv -e '[' -e '('"
alias synctime="sudo ntpd --quit --panicgate"
alias tf="waitdie con; fix_tags"
alias trizen="trizen --aur-results-sort-by=votes --aur-results-sort-order=ascending"
alias tz=trizen # if gpg fail, gpg --recv-keys <key>

mem() {
	# https://unix.stackexchange.com/a/261252
	: calc free memory in kb
	low=$(< /proc/zoneinfo grep low |
		awk '{print $NF}' |
		sum)
	a=$(
		# TODO: why 12?
		cat <<- EOF
			{a[\$1]=\$2} END { print a["MemFree:"]+a["Active(file):"]+a["Inactive(file):"]+a["SReclaimable:"]-(12*$low); }
		EOF
	)
	< /proc/meminfo awk "$a" |
		awk '{print $0/1000000}' # bc does not handle floats
}

# alias y="bash ~/gripts/disq/ytm.sh"

y() { bash ~/gripts/disq/ytm.sh; }

EXA_ARGS=(

	# https://github.com/search?type=code&q=path:dot_config/eza
	# xdg dir is only for theme...?

	# --dereference # this actually undoes symlink `-> ...`
	--all # show dot files
	--color=always
	--git                     # status porcelain
	--group-directories-first # debatable
	--links                   # inode count
	--long                    # note: long names will not be wrapped
	--no-permissions
	--no-user
	--octal-permissions
	--time-style=iso

	--level=2
	--tree # will be slow in large (wide) dirs

	# --sort=modified
)

alias ls='exa ${EXA_ARGS[*]}'
alias lsl="ls --sort=modified"

vv() {

	# # shellcheck disable=SC2329
	# f() {
	# 	line=$1
	# 	f=$(<<< "$line" cut -d: -f1)
	# 	line=$(<<< "$line" cut -d: -f2)
	# 	((start = line - 10))
	# 	((start < 0)) && ((start = 0))
	#
	# 	echo "$f"
	# 	echo
	# 	bat --color always --style=auto --line-range "$start": "$f"
	# }
	# export -f f
	# line=$(rgl --line-number . | fzf --preview='f {}' --preview-window='right,60%,border')
	# unset f

	# TODO: exclude pnpm lock, etc

	f=$(rg --line-number --no-heading . |
		# https://news.ycombinator.com/item?id=45677142
		fzf -d: -n 2.. --preview-window "right:50%:+{2}" --preview "bat --color=always --highlight-line {2} {1}")

	[[ -z $line ]] && return

	f=$(<<< "$line" cut -d: -f1)
	line=$(<<< "$line" cut -d: -f2)
	nvim +"$line" +"norm zt" "$f"
}

# }}}
# frequent {{{

# # copy cmd to clipboard
# alias yc="history | fzf --tac | awk '{\$1=\"\"; print \$0}' | xclip -sel c"

# # show contents of most recent self-sent msg
# notmuch show --limit=1 from:hejops1 |
# 	grep -Po 'id:\S+' |
# 	xargs notmuch show --part=2

# < ~/.config/mpv/library fzf |
# 	prepend "$MU"/ |
# 	largs mpv

m() {
	{
		find "$HDD/movies" -type f
		cat ~/to_watch
	} | fzf --preview=
}

da() {
	local args=()
	[[ $# -eq 1 ]] && args+=(-artist "$1")
	~/disq/disq "${args[@]}"
}

cm() {
	if [[ $# -eq 0 ]]; then
		# note: files added to cm via `add -f <symlink>` are not
		# automatically updated when the src file (target of the
		# symlink) is modified. the symlink targets must always be
		# re-added. this will no longer be necessary when the scripts
		# repo is deprecated.
		chezmoi status |
			grep -Po '\.local/bin/.+' |
			largs chezmoi add -f 2> /dev/null

		# TODO: when updating ~/scripts/foo (and having run `links`),
		# the symlink at ~/.local/bin/foo is always updated. however,
		# cm apply will replace the symlink with an actual file?
		#
		# chezmoi source-path .local/bin/mail | xargs chezmoi
		# target-path | xargs realpath

		chezmoi cd
	else
		chezmoi "$@"
	fi
}

bx() { [[ $# -gt 0 ]] && bash -x "$@"; }

replace() {
	_in_git_repo || return

	# check correct rep binary (not the lisp thing)
	if ! command -v rep | grep -Fq .cargo; then
		cargo install rep-grep
		return
	fi

	search=$1
	replace=$2
	_rg() {
		# --hidden will cause .git to be included!
		rg --hidden --glob='!.git/**' "$@"
	}

	if ! _rg -q -- "$search"; then
		echo "Pattern not found"
		return
	fi

	# note: backreferences use $1, not \1
	_rg --line-number -- "$search" | rep -- "$search" "$replace"
	read -r -p 'OK?' || return
	_rg --line-number -- "$search" | rep --write -- "$search" "$replace"

	# git diff
	gapat "$replace"
}

rge() {
	: edit files matching pattern
	staged=$(rg --hidden --files-with-matches "$@" | sort -u)
	if [[ $(<<< "$staged" wc -l) -gt 10 ]]; then
		echo "More than 10 files found"

	fi

	# pat="${@[-1]}" # invalid syntax
	pat="${@: -1}" # last arg of array https://unix.stackexchange.com/a/503475
	if [[ -f $pat || -d $pat ]]; then
		x=("$@")
		pat="${x[-2]}"
	fi

	echo "$staged" |
		head |
		xargs nvim -p +"/\v$pat"

}

sd() {
	: shutdown
	# uptime | grep hour || return/reboot

	waitdie mpv pacman curl #python

	if [[ -n $HDD ]]; then

		if
			files firefox | grep "$HDD"
		then
			inotifywait -e moved_to "$HDD"/movies
		fi
		killall firefox

		while
			f=$(files python | grep "$SLSK")
		do
			echo "$f" | largs -n1 inotifywait -e move_self
		done
		killall nicotine

	fi

	echo "Shutting down..."
	sleep 3
	shutdown now
}

rt() {
	: pass an array of relative paths to tagfix
	# note: dead symlinks are still displayed as if they exist

	< ~/.config/mpv/library fzf --multi --reverse --preview="ls \"$MU\"/{}" |
		prepend "$MU/" |
		while read -r d; do
			files mpv | grep -Fq "$d" && waitdie mpv >&2
			echo "$d"
		done |
		# to preserve the old behaviour (>1 args), remove -n1
		largs -o fix_tags

}

ytm() {
	f=$(mktemp)
	"$EDITOR" +startinsert "$f"

	waitdie mpv

	all_ids=
	while read -r query; do
		echo "$query"
		curl -sL 'https://music.youtube.com/youtubei/v1/search' \
			-H 'Content-Type: application/json' \
			--data-raw '{"context":{"client":{"clientName":"WEB_REMIX","clientVersion":"1.20240904.01.01"}},"query":"'"$query"'","params":"EgWKAQIIAWoSEAMQBBAJEA4QChAFEBEQEBAV"}' |
			gron |
			grep videoId |
			cut -d'"' -f2 |
			uniq |
			while read -r id; do # deduplicate across queries; somewhat useful i guess?
				<<< "$all_ids" grep -Fxq -- "$id" && continue
				all_ids+=$'\n'$id
				echo "$id"
			done |
			prepend 'https://youtube.com/watch?v=' |
			xargs mpv --video=no
	done < "$f"

	exit
}

# }}}

# git

# alias e=v
# alias ga=_git_commit
# alias gr=git_root
alias b=_git_branch_fzf
alias cr=git_root
alias gb=_git_branch
alias gl=git_log
alias i=b
alias s=_git_commit # should increasingly be done in vim

# discouraged due to double index keypresses: gt gf gb

# alias ga="git add"
# alias gdnw="git diff --color-words --no-index"
alias g..="git push --force-with-lease origin \$(_git_current_branch)"
alias g.="git push"
alias gC="git show HEAD | cat; git reset --soft HEAD~1"                                         # un-commit, but keep changes staged
alias gCH="git show --oneline HEAD | cat; echo; read -r -p 'confirm?'; git reset --hard HEAD~1" # un-commit, and discard changes
alias gdn="git diff --no-index"                                                                 # https://stackoverflow.com/a/17433969 -- TODO: handle symlinks
alias gdnc="git diff --color-words=. --no-index"                                                # diff by char; may be replaced with delta
alias gig='$EDITOR $(_get_repo_root)/.gitignore'
alias gm,='_git_branch && gmm'
alias gx='git log --author=$(git config --get user.email) --branches --format="%h%x09%S%x09%s" --pickaxe-regex -S' # TODO: colt would be nice, but then it can't be an alias anymore

gdns() { gdn -U0 <(sort -u "$1") <(sort -u "$2"); } # sort lines and diff

# git info {{{
# functions that only report info

gls() { git ls-files "${1:-.}"; }

_get_remote() { git config --get remote.origin.url; }
_git_current_branch() { git branch --show-current; }
_in_git_repo() { git rev-parse --is-inside-work-tree > /dev/null 2> /dev/null; }

_get_repo_root() {
	if [[ $(basename "$PWD") == .git ]]; then
		realpath ..
	else
		git rev-parse --show-toplevel 2> /dev/null
	fi
}

_gmaster() {
	: get default branch, e.g. master
	# https://stackoverflow.com/a/44750379
	# default_branch=$(git symbolic-ref refs/remotes/origin/HEAD | sed 's|^refs/remotes/origin/||')
	git symbolic-ref refs/remotes/origin/HEAD 2> /dev/null | cut -d/ -f4
}

git_root() {
	if _in_git_repo; then
		cd "$(_get_repo_root)" || :
	elif [[ -n $REPO ]]; then
		cd "$REPO" || :
	fi
}

_git_http() {
	url=$1
	if [[ $url == http* ]]; then
		echo "$url"
	else
		tr <<< "$url" : / | sed -r 's|git@|https://|; s|.git$||'
	fi

}

gauthors() {
	: show authorship of file
	git blame --line-porcelain "$1" |
		sed -rn 's/^author (.+)/\1/p' |
		sort |
		uniq -c |
		sort -n
}

gh() {
	: open remote url

	if ! repo=$(_get_remote); then
		echo "Current repo has no remote"
		return
	fi

	# better handled in vim

	# if [[ -f $1 ]] && git ls-files --error-unmatch "$1" &> /dev/null; then
	# 	# view file at its most recent commit
	# 	hash=$(git log --max-count=1 --pretty=format:%h -- "$1")
	# 	url="$repo/blob/$hash/$1"
	#
	# elif [[ -n $1 ]]; then # view repo at specific commit
	# 	h=$(git rev-parse --short --verify HEAD)
	# 	url="$repo/commit/$h"
	# fi

	url=${repo%*.git}
	url=$(_git_http "$url")
	echo "$url"
	xdg-open "$url"
}

# }}}
# git history {{{

_git_log_fzf() { # {{{
	_in_git_repo || return

	# TODO: heads may be 'cleared'
	# https://stackoverflow.com/a/30143136

	if ! ls "$(_get_repo_root)"/.git/refs/heads/* > /dev/null 2> /dev/null; then
		echo "no commits yet" >&2
		return 1
	fi

	# stat always suppresses the diff, so --patch must be specified again.
	# i generally prefer --numstat, if only because --stat uses a weird ---
	# separator
	#
	# i don't mind always showing a stat in git show, but there seems to be
	# no config option for this
	prv_cmd="echo {} | cut -d' ' -f1 | xargs git show --numstat --patch --color=always"

	args=()

	if
		[[ -f $1 || -d $1 ]]
	then
		args+=("$@")
		prv_cmd="echo {} | cut -d' ' -f1 | xargs -I{} git show --color=always {} $1" # restrict diff to selected file/dir

	elif
		<<< "$1" grep -Fq ... # from...to
	then
		args+=("$@")

	elif
		[[ $# -gt 1 ]] # probably arbitrary options to git log
	then
		# TODO: allow arbitrary options to fzf (this is a can of worms)
		args+=("$@")

	elif
		[[ $# -eq 1 ]] &&
			[[ $1 == $(_gmaster) ]]
	then
		# git does not allow flag overrides (i.e. --merges will not
		# work), and merge commits are always after. thus, we just show
		# child commit in preview
		# https://stackoverflow.com/a/9870218
		prv_cmd="echo {} | cut -d' ' -f1 | xargs -I{} git log --reverse --ancestry-path {}..$(_gmaster) --oneline 2>/dev/null | head -n1 | cut -d' ' -f1 | xargs git show"

	elif
		# other dev branch
		[[ $# -eq 1 ]] &&
			git branch --remote | grep -Fqx "  origin/$1"
	then
		git pull > /dev/null 2> /dev/null
		args+=("origin/$1")

	elif
		m=$(_gmaster) && [[ $(_git_current_branch) == "$m" ]]
	then
		: on master

	elif [[ -n $m ]]; then # dev branch
		# note: use origin/master, because i tend to not actually
		# update my local master

		# note: .. and ... are NOT synonymous!
		#
		# A..B = raw diff between A and B
		#
		# A...B = diff between B and "last shared ancestor of A and B"
		# (almost always master); this is usually what we want
		#
		# https://i.sstatic.net/PboEt.png
		# https://stackoverflow.com/a/24186641

		args+=(--first-parent "origin/$m...HEAD")

	else
		: no remote yet
	fi

	# there is literally nothing to see in merge commits (Merge branch 'x'
	# into 'master'), so --no-merges is generally a good idea.
	#
	# however, commits that are the -result- of a merge are still included.
	# these merges can be further ignored with --first-parent, although
	# ignoring them may not always be desirable.
	#
	# alternatively, it may be good to indicate whether the commit was
	# committed in this branch, or simply pulled from remote.

	git log --decorate --oneline --no-merges "${args[@]}" |
		# we always only want the git hash
		fzf -m --preview="$prv_cmd" --preview-window='right,60%,border' --ansi \
			--accept-nth=1
}     # }}}
v() { # {{{
	: open recently modified files

	_in_git_repo || return

	# bat can keep up with rapid renders; pygmentize can't
	#
	# chezmoi/ > time cat dot_config/nvim/init.lua >/dev/null
	# real    0m0.001s
	#
	# chezmoi/ > time bat --color=always --style=auto --paging=never dot_config/nvim/init.lua >/dev/null
	# real    0m0.028s
	#
	# chezmoi/ > time pygmentize dot_config/nvim/init.lua >/dev/null
	# real    0m0.118s

	# on ubuntu:
	# ln -s /usr/bin/batcat ~/.local/bin/bat
	prv_cmd="bat --color always --style=auto {} 2>/dev/null || cat {}"

	# https://github.com/wezterm/wezterm/issues/4287#issuecomment-3289326309
	readarray -t f < <({
		# git diff --name-only --ignore-submodules "$(_gmaster)...HEAD" | grep . #||
		git log --no-merges --first-parent --name-only --pretty= "$(_gmaster)...HEAD" | grep .
		git ls-files --full-name # . is implicit
	} |
		prepend "$(_get_repo_root)"/ |
		largs realpath --relative-to=. 2> /dev/null |
		sort -u |
		largs ls -1t 2> /dev/null |
		# TODO: 50 is often too few
		head -n50 |
		# height=~X% is not suitable because preview is usually longer
		# than input rows, and preview must always be shown to a reasonable
		# extent
		#
		# --no-sort should only be used when fuzzy matching is strict
		# enough to remove most rows
		fzf --no-sort -m --prompt="$(_git_current_branch): " \
			--height=50% --reverse --preview-window='right,50%,border' \
			--preview="$prv_cmd")
	((${#f} > 0)) && nvim -p "${f[@]}"
}       # }}}
gdm() { # {{{
	: diff against master, like in a PR

	# caveat: due to git internals, it is not trivial to produce a diff
	# that is both 'cumulative' and completely excludes merges.
	#
	# https://stackoverflow.com/q/25403705
	#
	# this gets reasonably close, but if a file was changed in the current
	# branch as well as in a merge, both changes will be shown. for the
	# purpose of fast diffing (i.e. without network), this is usually fine.

	span="origin/$(_gmaster)...HEAD" # origin/ is important
	root=$(_get_repo_root)
	git log --diff-filter=d --no-merges --first-parent --name-only --oneline --pretty= "$span" |
		sort -u |
		# HACK: --diff-filter excludes files deleted by us, but does
		# not exclude files deleted during a merge
		while read -r f; do
			[[ -f "$root/$f" ]] && echo "$root/$f"
		done |
		# TODO: xargs: git: terminated by signal 13
		xargs git diff "$span" 2> /dev/null

	# https://gitlab.com/gitlab-org/cli/-/issues/7704

} # }}}

gbe() {
	: match pattern in current branch, like rge
	pat=$1
	git log --name-only --pretty= origin/"$(_gmaster)"...HEAD |
		seen |
		xargs rg -l "$pat" |
		xargs nvim -p +'/\v'"$pat"
}

git_log() {
	: browse git log, showing each commit\'s diff in fzf preview
	_git_log_fzf "$@" | xargs git show
}

gxx() {
	: show commits whose changes contain a pattern
	# TODO: git show --color=always breaks grepdiff?
	prv_cmd="echo {} | cut -f1 | xargs git show -U1 | grepdiff \"$1\" --output-matching=hunk"
	git log --branches --format="%h%x09%S%x09%s" --pickaxe-regex -S "$1" | # WARN: slow with large histories
		fzf -m --preview="$prv_cmd" --preview-window='right,60%,border'
}

gcoup() {
	: for a given file, show which files changed together
	# https://adamtornhill.com/articles/crimescene/codeascrimescene.htm
	git log --pretty=%h "$1" |
		xargs git show --name-only --pretty= |
		count
}

clocd() {
	: diff current repo state against a date in the past
	git log --until="$(date -I --date="$1")" -n1 --oneline |
		awk '{print $1}' |
		xargs -I{} cloc --diff {} HEAD
}

gsdel() {
	: show last state of a deleted file
	# https://stackoverflow.com/a/19727752
	f=$1
	git show "$(git rev-list --max-count=1 --all -- "$f")^:$f"
}

gly() {
	: yesterday\'s log
	git -C "${REPO:-.}" log --all --format="%S|%cI|%h|%s" --since="$(date --date='1 days ago' -I)" \
		--author="$(
			# not reliable yet:
			# git config get --local user.email
			# git config get --local user.name
			<<< "$USER" sed -r 's/^\w/\U&/'
		)" --no-merges |
		sort |
		sed 's|refs[^ ]*/||' |
		tr '|' '\t' |
		colt |
		grep -v ^master
}

# git diff blame
# inherently, this means git diff must operate on a time range that spans more
# than commits, typically a (big) diff of a PR. by extension, this means that
# git diff blame is only useful when multiple authors have worked on the same
# PR, which tends to not happen very often IME.
# https://gist.github.com/maxrothman/d27bbc36f7c150924de6c6e54965de4d py
# https://github.com/eantoranz/difflame py
# https://github.com/dmnd/git-diff-blame pl

# GitBlameOpenFileURL
# $url/-/blob/$branch/$path

# }}}
# git staging -- functions that modify files or the index {{{
#
# TODO: most of these would be more convenient if done in vim

_commit_or_discard() {
	: returns 0 if committed

	committed=1

	while read -r f; do
		f=$(_get_repo_root)/$f
		[[ -f $f ]] || continue
		if
			git commit -v --untracked-files=no "$f"
		then
			committed=0
		else
			# TODO: checkout fails if f is staged; must gA
			git checkout -- "$f"
		fi
	done < /dev/stdin

	# xargs git commit is not useful, because we need to know the result of
	# each git checkout

	return "$committed"
}

gA() {
	: un-add, unstage
	# i usually want restore more often (?)
	set -x
	git restore --staged "$@" \
		2> /dev/null || # committed; without --staged, changes are discarded!
		git reset "$@"  # not committed yet
	set +x
}

gc() {
	: commit

	local cmd=(git commit -v --untracked-files=no)

	if [[ $# -gt 0 ]]; then

		# 1. specified files, but excluding untracked files
		# note: this loop commits renamed files, but does not commit
		# their old names

		# arr=()
		# for f in "$@"; do
		# 	[[ ! -f $f ]] && continue
		# 	realpath "$f" | xargs git ls-files | grep -q . && arr+=("$f")
		# done
		# git commit -v "${arr[@]}"

		for f in "$@"; do
			[[ ! -f $f ]] && continue
			realpath "$f" |
				xargs git ls-files |
				grep -q . && echo "$f"
		done |
			largs "${cmd[@]}"

	# note: git commit -av stages -all- changes in the entire repo. this is
	# almost never what i want

	elif
		rd=$(git diff --diff-filter=RD --name-only --staged | grep .)
	then
		"${cmd[@]}"

	elif
		# 2. file(s) that have been renamed/deleted
		# this behaviour may not be desirable when modified files
		# should also be included in the commit
		# TODO: also check --staged
		rd=$(git diff --diff-filter=RD --name-only | grep .)
	then
		echo "$rd" |
			prepend "$(_get_repo_root)/" |
			xargs "${cmd[@]}"

	elif
		# 3. all staged changes
		# [git diff] "exits with 1 if there were differences"
		! git diff --staged --diff-filter=AMD --quiet
	then
		: committing staged changes
		"${cmd[@]}"

	else
		# 4. all files that have changed in the current dir
		git diff --name-only . |
			prepend "$(_get_repo_root)/" |
			grep -v .gitignore |
			xargs "${cmd[@]}"

	fi

}

_git_commit() {
	: like gl, for files to stage/commit

	# should be replaced by gs in vim, but i still find myself doing this
	# often

	# # porcelain v1 is -always- relative to repo root, which makes
	# # relativising to cwd needlessly tedious (this would probably involve
	# # splitting each line, prepending repo root to the latter part,
	# # relativising, and then rejoining!)
	# files=$(git status --porcelain)

	prv_cmd=$(
		cat <<- EOF
			echo {} | awk '{print \$NF}' | xargs git diff --color=always | grep . ||
			echo {} | awk '{print \$NF}' | xargs bat --color always --style=auto 2>/dev/null
		EOF
	)

	status=$(git status --porcelain=2 --untracked-files=all)

	[[ -z $status ]] && return

	# by default, git status does not enter dirs containing only 1
	# (untracked) file
	sel=$(
		# 1 .M N... 100644 100644 100644 <hash> <hash> package.json
		#   $2					       $NF
		# ? README.md
		#
		# $2 is more useful for tracked files (since it more closely maps to v1
		# labels), but for untracked files this duplicates the file path, so we
		# stick to $1
		#
		# https://git-scm.com/docs/git-status#_changed_tracked_entries
		#
		# HACK: i have no idea how to 'return' multiple columns inside
		# a ternary, so concat with a space as an ugly workaround
		<<< "$status" awk '{print ($1=="?") ? $0 : $2" "$NF}' |
			fzf --multi --reverse --preview="$prv_cmd" --preview-window='right,60%,border' --ansi
	)
	# fzh --multi --preview="$prv_cmd" --preview-window='right,60%,border' --ansi)

	# add untracked files first
	echo "$sel" | grep -P '^\?' | awk '{print $NF}' | xargs git add
	echo "$sel" | awk '{print $NF}' | xargs git commit -v
}

gsq() {
	: squash last n commits, starting from a given commit -- rewrites history!
	# https://stackoverflow.com/a/5201642
	sha=$(_git_log_fzf)
	# `git reset <sha>` brings us back to the commit -after- <sha>. this
	# means we need to select the commit before the 'target', which is
	# unintuitive. so we just go back 1 more commit with ~
	git reset --soft "$sha~"
	git commit --edit -m"$(git log --format=%B --reverse "HEAD..HEAD@{1}")"
	git push --force-with-lease origin "$(_git_current_branch)"
}

gcf() {
	: like gc, but squash the new commit with an earlier one

	# https://jordanelver.co.uk/blog/2020/06/04/fixing-commits-with-git-commit-fixup-and-git-rebase-autosquash/
	old_sha=$(_git_log_fzf .)
	[[ -z $old_sha ]] && return

	# --fixup associates a new commit with an existing commit so that when
	# you do an interactive rebase, you don't have to re-order any commits
	# in order to squash them. And you don't have to change any commit
	# messages
	git commit -v --fixup "$old_sha" # "$new_sha"

	# with no arg, defaults to curr branch (NEVER use gmaster; to avoid
	# losing work, git rebase --abort immediately)
	# --autostash required to avoid 'unstaged changes present'
	git rebase --autosquash --autostash || gC
}

# use gap in vim instead
# gapat() { # {{{
# 	: stage hunks matching some pattern
#
# 	# TODO: error: No valid patches in input (allow with "--allow-empty")
#
# 	for patt in "$@"; do
# 		# grepdiff is more reliable than git diff -S/-G
# 		# https://choly.ca/post/git-programmatic-staging/
# 		# https://blog.paddlefish.net/git-tip-stage-lines-matching-a-regular-expression/
# 		# https://old.reddit.com/r/git/comments/p1vltk
# 		git diff -U0 |
# 			grepdiff --output-matching=hunk -E "$patt" |
# 			# "By default, git apply expects that the patch being applied
# 			# is a unified diff with at least one line of context."
# 			git apply --cached --unidiff-zero
# 	done
#
# 	# # https://stackoverflow.com/a/52394658
# 	# git diff --unified=1 --pickaxe-regex -S "$1" |
# 	# 	grepdiff --output-matching=hunk --extended-regexp "$1" |
# 	# 	git apply --cached
#
# 	# see also:
# 	# http://www.philandstuff.com/2014/02/09/git-pickaxe.html
# 	# https://git-scm.com/docs/gitdiffcore#_diffcore_pickaxe_for_detecting_additiondeletion_of_specified_string
#
# 	git commit -v
#
# 	# # unstage hunks that were unnecessarily added
# 	# git reset -p
# } # }}}

grev() {
	: revert single commit in isolation
	_git_log_fzf "$@" | xargs git revert
}

gRev() {
	: rollback entire index to a known good commit -- check ci first
	sha=$(_git_log_fzf "$@")
	git checkout -f "$sha" -- .
	git commit -av
}

gu() {
	if
		(($# == 0)) ||
			[[ $(_git_current_branch) == $(_gmaster) ]] && [[ $1 == . ]]
	then
		echo "cannot reset on master"
		return
	fi

	git diff "$@" | cat
	git checkout -- "$@"
	echo "undid ${#@} files" # TODO: if ., determine how many files changed?
}

guns() {
	: revert file to its state in a previous commit
	(($# != 1)) && return

	f=$1
	prv_cmd="echo {} | cut -d' ' -f1 | xargs -I{} git show --color=always {} $1"

	# _git_log_fzf "$1" |
	git log --oneline "$1" |
		fzf -m --preview="$prv_cmd" --preview-window='right,60%,border' --ansi --accept-nth=1 |
		xargs -I{} git checkout {} -- "$f"

}

gpick() {
	: cherry pick commit from other branch
	# i only use this when a commit was accidentally made in another
	# branch. the wrongly made commit is not undone.
	(($# != 1)) && return
	prv_cmd="echo {} | cut -d' ' -f1 | xargs git show --color=always"
	sha=$(git log --branches --remotes --tags --oneline --decorate "$1" |
		fzf --preview="$prv_cmd" --preview-window='right,60%,border' --ansi --accept-nth=1)
	[[ -n $sha ]] && git cherry-pick --edit "$sha"
}

# }}}
# git branch # {{{

# create new branch, basing off current branch (this is the default behaviour of switch)
alias gbc="git switch --create"

gbr() {
	: switch to remote branch
	git fetch
	git branch --remotes |
		seen |
		# TODO: filter out branches that exist locally
		fzf |
		cut -d/ -f2 |
		# --guess (default) switches to remote branch if found, but must remove origin/
		xargs git switch # --create
}

_git_branch() { # {{{
	: switch to new branch, or existing branch. with no arg, switches to master

	[[ -z $1 ]] && return

	# new branches are always based off latest master; the default
	# behaviour of git switch -c is to base off the current branch, but
	# this is generally not useful (in the rare cases that basing off
	# current branch is required, call gbc instead)

	# regardless of the start point, it is common to be prevented from
	# switching branches due to the presence of unstaged/uncommitted
	# changes, which is highly disruptive:
	#
	# error: Your local changes to the following files would be overwritten
	# by checkout: ... Please commit your changes or stash them before you
	# switch branches.
	#
	# most unstaged changes are usually throwaway code that was never meant
	# to be committed (and could thus be discarded with git switch
	# --discard-changes). but some unstaged changes are wips that -do- need
	# to be committed before switching, so we ask for every file.
	#
	# note that git switch --conflict brings uncommitted changes into
	# master, causing conflict markers to appear. this is never desired
	# (because we want to start from a clean slate), so conflicts must be
	# resolved in the current branch, -before- the checkout

	commit_unstaged_changes() {

		# we always compare the current branch to the current state of
		# master (-before- fetch)

		# presumably, ' M	' can be safely ignored?
		# git diff-tree HEAD "$target"
		# git diff-index "$target"
		# git diff --numstat "$target"...HEAD

		git diff-index "$start_branch" |
			grep -P '00000 [AM]	' |
			cut -f2 |
			_commit_or_discard && git push
	}

	start_branch=$(_gmaster)

	if [[ $# -eq 0 ]]; then
		if [[ $(_git_current_branch) == "$start_branch" ]]; then
			echo "Already on $start_branch"
		else
			# relatively uncommon, and there are probably better ways to update master
			# func retval is not propagated to parent
			git checkout "$start_branch" || return 1
			timeout 30 git pull
		fi
		return
	fi

	# if
	# 	! git branch | grep -qPx "[ *] $target" &&
	# 		timeout 30 git pull &&
	# 		git branch -r | grep -q "origin/$target"
	# then
	# 	# note: git hook stdout cannot be suppressed
	# 	echo "Switching to remote branch $target"
	# 	git switch "$target" > /dev/null || return 1

	# if
	# 	commit_unstaged_changes "$start_branch" #&&
	# 	git switch --create "$new_branch" "$start_branch" > /dev/null 2> /dev/null
	# then
	# 	# for some reason, newly created branches don't know
	# 	# which repo to pull from
	# 	git pull "$(_get_remote)" "$start_branch"
	# else
	# 	commit_unstaged_changes "$new_branch"
	# 	git switch "$new_branch"
	# fi

	set -x

	# TODO: does this pull?
	commit_unstaged_changes "$start_branch"

	new_branch=$1

	# TODO: if this is stable, this should be simple enough to port into vim

	if
		# existing local branch
		git branch | grep -Fqw "$new_branch"
	then
		git switch "$new_branch"
	else
		# new local branch
		# TODO: why do we appear to merge master into curr branch?

		# + git pull origin master:master
		# remote: Enumerating objects: 62, done.
		# remote: Counting objects: 100% (62/62), done.
		# remote: Compressing objects: 100% (30/30), done.
		# remote: Total 32 (delta 24), reused 0 (delta 0), pack-reused 0 (from 0)
		# Unpacking objects: 100% (32/32), 8.71 KiB | 222.00 KiB/s, done.
		# From gitlab.novum-engineering.com:external-services/novum-cloud
		#    bb8fec7eb..c1572ba64  master     -> master
		#    bb8fec7eb..c1572ba64  master     -> origin/master
		# Merge made by the 'ort' strategy.
		# + git switch --create v2-storage-bulk-create master

		# --no-edit skips commit msg (?)
		git pull --commit --no-edit origin "$start_branch:$start_branch" # https://stackoverflow.com/a/16560695
		git switch --create "$new_branch" "$start_branch"
	fi

	set +x

	# check if (dev) branch is behind remote
	# rev-list probably wouldn't be useful if we don't fetch though
	# note: rev-list errors if branch has no remote yet
	if
		behind=$(git rev-list --left-right --count "origin/$new_branch...HEAD" 2> /dev/null | cut -f1 | grep .) &&
			((behind > 0))
	then
		git pull
	fi

} # }}}

_git_branch_fzf() {
	: switch interactively to existing branch, aliased to b
	# does not handle existing remote branch; use gbr instead

	# https://stackoverflow.com/a/1441062
	# --pretty=format:'%h%x09%an%x09%ad%x09%s' # no color

	_in_git_repo || return
	if (($(git branch | wc -l) == 1)); then
		echo "No other branches; create one with gb <branch>"
		return
	fi

	prv_cmd=$(
		# if branch, show log starting from master
		# if master, the range `master..master` fails, so show entire git log
		# TODO: branch with no commits = empty preview
		cat <<- EOF
			echo {} |
				sed -r 's/^/$(_gmaster)../' |
				xargs git log --oneline --color=always |
				grep . ||
			git log --oneline  --color=always {}
		EOF
	)
	branch=$(git branch --sort=-committerdate |
		awk '{print $NF}' |
		fzf --preview="$prv_cmd" --preview-window='right,80%,border' --ansi)
	# [[ -z $branch ]] && return
	_git_branch "$branch"

}

gbd() {
	: prune local branches that no longer exist on remote -- unstaged changes will be lost!
	# this should generally not be run automatically
	# https://stackoverflow.com/a/46192689
	git branch -vv |
		grep ': gone]' |
		grep -v "^\*" | # TODO: this means we cannot delete current branch; consider sed s/^*//
		awk '{print $1}' |
		xargs -r git branch -D
}

# }}}
# git remote -- functions that involve remote repository {{{

_gssh() { # {{{
	: init github ssh key
	# https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent#generating-a-new-ssh-key
	#
	# note: this key must still be added to github!
	# https://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account#adding-a-new-ssh-key-to-your-account

	# password not strictly necessary
	ssh-keygen -t ed25519 -C hejops1@gmail.com -f "$HOME/.ssh/github_$(date -I)"
	ssh -T git@github.com 2>&1 | grep -q success && echo ok

} # }}}

gmm() {
	: merge master into dev branch
	[[ $(_git_current_branch) == $(_gmaster) ]] && return
	# https://stackoverflow.com/a/20103414
	git fetch origin
	# TODO: for forks, need to sync fork (in gh), then git pull
	git merge "origin/$(_gmaster)"
}

g,() {
	git pull && return
	git diff --name-only "$(_gmaster)..origin/$(_gmaster)" | _commit_or_discard
	git pull && git push
}

gcon() { # {{{
	# https://nitaym.github.io/ourstheirs/

	# cd novum-api
	# make db-up && make db-vet && make db-generate
	# cr
	# gcon

	: resolve conflicts, if any, and merge

	markers='^[<=>|]{7}'

	_git_has_conflicts() {
		rg -q --hidden "$markers"
		return $?
	}

	_git_get_conflicts() {
		# submodule conflicts don't really need to be resolved?
		git status --porcelain --ignore-submodules=all |
			grep -P '^([A-Z])\1 ' |
			sort -u |
			cut -c3-
	}

	# not up to date with master yet
	if
		! _git_has_conflicts &&
			(("$(git rev-list --left-right --count "origin/$(_gmaster)...HEAD" | cut -f1)" > 0))
	then
		gmm || return
		gcon
	fi

	# only conflict is lock file
	if ! git status --porcelain |
		grep ^UU |
		grep -vx 'UU pnpm-lock.yaml'; then

		pnpm install
		_git_get_conflicts | xargs git add
		git commit -v

	elif ! git status --porcelain |
		grep ^UU |
		grep -v 'go.sum$'; then

		cd "$(git status --porcelain |
			grep ^UU |
			cut -d' ' -f2 |
			xargs dirname)"
		go mod tidy
		cd -

		_git_get_conflicts | xargs git add
		git commit -v

	fi

	# git diff --name-only --diff-filter=U --relative

	# in case of submodule conflict:
	# cd $submodule
	# gu .
	# git merge $hash (git should tell you which hash -- how to script?)
	# git add $submodule
	# git commit

	while _git_has_conflicts; do
		if [[ -f .abort ]]; then
			git merge --abort
			return
		fi
		echo "Unresolved conflicts remaining!"
		_git_get_conflicts | xargs nvim -p +'/\v'"$markers"
	done

	# _git_get_conflicts | xargs git add
	# git commit -v

	_git_get_conflicts | xargs git commit -iv
}        # }}}
gnew() { # {{{
	: push to newly created remote

	if _get_remote; then
		return

	elif [[ ! -d .git ]]; then
		git init
		return

	elif
		! git log > /dev/null 2> /dev/null &&
			! git status --porcelain | grep -Fv '??'
	then
		echo 'no commits made yet'
		return

	else
		# WARN: this may not be desired
		git commit -m "initial commit"
	fi

	git branch -M master # don't call _gmaster!
	xdg-open https://github.com/new &
	read -rp 'Repo name (not URL!): ' repo

	# https://kbroman.org/github_tutorial/pages/init.html
	git remote add origin "https://github.com/hejops/$repo"
	git push -u origin master
	git status
	git remote set-head origin --auto

} # }}}

# grbr() {
# 	: rebase to remote, discarding all local changes that conflict with remote
# 	# use case:
# 	# - our branch was started at the same time as another branch
# 	# - rewriting is simpler than resolving conflicts
# 	# - the other branch is much larger
# 	# - the other branch has been merged to master
# 	cr
# 	# first preserve files that were only added to in our branch
# 	# (this is a looser definition than just 'new files')
# 	git diff --numstat master...HEAD |
# 		grep -P '^\d+\t0\t' |
# 		cut -f3 |
# 		xargs git diff master...HEAD > tmp.diff
# 	# equivalent to `git rebase origin/master; git rebase --skip (repeatedly)`
# 	git rebase --strategy-option=theirs "origin/$(_gmaster)"
# 	git apply tmp.diff
# 	# git push -f
# }

review() {
	# https://news.ycombinator.com/item?id=44968785
	if
		[[ -n "$(git status -s)" ]]
	then
		echo 'must start with clean tree!'
		return 1
	fi

	[[ $# -eq 1 ]] && return

	git checkout pristine # a branch that I never commit to
	git rebase origin/master

	branch="$1"
	git branch -D "$branch"
	git checkout "$branch"

	git rebase origin/master
	git reset --soft origin/master
	git reset

	nvim -c ':G'

	git reset --hard
	git status -s | awk '{ print $2 }' | xargs 'rm' # seems dangerous...
	git checkout pristine
	git branch -D "$branch"

}

# }}}

# gitlab {{{

# TODO: run after clone
# git config set --local user.email "$EMAIL"
# git config set --local user.name "$NAME"

# json output requires v1.37 (apt is 1.36 smh)
# https://gitlab.com/gitlab-org/cli/-/commit/893f5c945a50cb8a6d674eb05923f87e46fa6150

# https://gitlab.xyz.com/-/user_settings/personal_access_tokens
# glab auth login

alias gld=gldiff

# all mrs made by me
alias gmer='seq 1 2 | parallel -n1 glab mr list --output=json --assignee=@me --merged --per-page=9999 -p | jq .[] | jqt iid source_branch title | sort -n'

# # similar to b (but slower)
# glab mr list --author=@me --output=json |
# 	jq -r .[] |
# 	jqt detailed_merge_status source_branch title |
# 	sort

gmw() {
	: mrs merged in the last week
	glab mr list --merged --output=json |
		# jq -r 'sort_by(.merged_at)[]|select(.merged_at>="'"$(date --date='1 week ago' -I)"'")|["- !"+(.iid|tostring),.title]|@tsv'
		jq -r 'sort_by(.merged_at)[]|select(.merged_at>="'"$(date --date='1 week ago' -I)"'")|[.iid,.title]|@tsv'
}

# apt 1.36
# snap 1.43/1.54, but cannot read config file (lol)

gldiff() {
	# note: to see diff of current branch, just use gdm
	[[ $PWD != *$REPO* ]] && cd "$REPO"

	if <<< "$1" grep -Pqx '\d+'; then
		glab mr diff "$n" | sed '/Subproject commit/d' | delta
		return
	fi

	prv_cmd="echo {} | awk '{print \$NF}' | xargs -I{} git log --oneline origin/{}"
	branch=$(glab mr list --output=json --reviewer=@me | #--not-draft |
		jq '.[:25][]' |
		jqt updated_at iid source_branch title assignee.username |
		sort -r |
		fzh -0 -1 --preview="$prv_cmd" --accept-nth=3)
	[[ -z $branch ]] && return

	if (($# == 1)); then
		git fetch
		git diff "$1...origin/$branch"
	else
		git diff "origin/$(_gmaster)...origin/$branch"
	fi

}

gci() { watch -n 30 'glab ci list -P 10 | grep -P "^\(" | column -t'; }

gmrc() {
	: find recent mr that is most likely the predecessor of the current mr

	# current mr numstat
	curr=$(git diff --numstat "$(_gmaster)"..HEAD | # not sure if ... better
		grep -Fvw -e 0 -e '=>' |
		sort -rn)

	# based on numstat of previous mrs, find max similarity (in terms of
	# files changed)
	git log --oneline --since="$(date -I --date='1 month ago')" |
		grep 'Merge branch' |
		cut -d' ' -f1 |
		head |
		while read -r sha; do

			xx=$(git show --format= --numstat "$sha" |
				sort -rn |
				# cut -f3 | xargs grep |
				while read -r _ _ f; do <<< "$curr" grep "$f" || :; done |
				wc -l)

			echo "$xx $sha"

		done |
		sort -rn |
		head -n1 |
		cut -d' ' -f2 |
		xargs git show |
		grep -Po '!\d+'
}

alias bf=gmrf

gmrf() {
	# branches with ci fail
	branch=$(glab mr list --author=@me --output=json |
		# jq -r '.[]|select(.detailed_merge_status=="ci_must_pass")|.source_branch' # or "conflict"
		jq -r .[] |
		jqt iid source_branch title[:30] detailed_merge_status |
		fzr --preview="echo {} | awk '{print \$2}' | xargs git log --oneline --color=always" --accept-nth=2)
	_git_branch "$branch"
}

glj() {
	: view job logs of current mr
	f() {
		id=$1
		glab ci get --output=json --pipeline-id "$1" |
			jq ".jobs[]|select(.name==\"$2\")|.web_url" |
			xargs --verbose -I{} curl -sL \
				-H "Cookie: _gitlab_session=$GL_SESSION" '{}/raw' |
			sed -n '/GRPC/,$p'
	}
	export -f f
	job=$1
	if [[ -z $job ]]; then
		echo "no job specified"
		return
	fi
	glab ci list --output=json |
		jq ".[]|select(.ref==\"$(_git_current_branch)\")|.id" |
		fzf --preview="f {} $job" --preview-window='right,95%,border' --reverse --tac
	unset f
}

# }}}

# rust {{{

# alias sqp='cargo sqlx prepare --workspace; ga .sqlx; gc' # postgres only
# cargo +nightly udeps
alias cb="cargo build"
alias cbr='cargo build --release && cp target/release/$(basename $PWD) .'
alias cn="cargo new"
alias ct="cargo test"
alias cwr="cargo watch -x run" # web servers only

cw() { cargo watch -x check -x "test $1"; }

# }}}
# go {{{

# https://gist.githubusercontent.com/alexedwards/3b40775846535d0014ab1ff477e4a568/raw/15f15b499f626a6e3949c237d52a3e8aace1b05b/Makefile

alias gobe="go test -bench=. -run=^$ ./..." # run benchmarks only -- https://stackoverflow.com/a/16161605

gop() {
	# https://go.dev/blog/pprof
	# https://github.com/google/pprof/blob/a8630aee4ab/internal/driver/commands.go#L125
	go tool pprof -web -nodefraction=0.1 ./*.prof 2> /dev/null
}

gopk() {
	: move foo.go to foo/foo.go
	# parent must then import from foo; goimports should fix this?
	f=$1
	pkg=${f/.go/}
	[[ -d $pkg ]] && return
	mkdir "$pkg"
	sed -i -r "s/^package main/package $pkg/" "$f"
	mv "$f" "$pkg"
}

gon() {
	if (($# == 0)); then
		pkg=foo
		tmp
	else
		pkg=$1
	fi

	[[ -d $pkg ]] && return

	if [[ -f ./go.mod ]]; then
		mkdir "$pkg"
		echo -e "package $pkg\nfunc foo(){\n}" > "$pkg/$pkg.go"
		vim + "$pkg/$pkg.go"
	else
		mcd "$pkg"
		go mod init "$pkg"
		echo "$pkg" > .gitignore
		echo -e "func main(){\n}" > main.go
		go build # generate go.mod
		vim + main.go
	fi
}

gob() { # build and run
	name=$(< go.mod head -n1 | cut -d' ' -f2 | xargs basename)
	go build && ./"$name" "$@"
}

# https://leg100.github.io/en/posts/building-bubbletea-programs/
gowr() { while :; do gob "$@" || break; done; } # in foreground, continously run app

gorep() {
	patt=$1
	repl=$2

	# # see matches
	# rg -IN "$patt" ./*.go
	# read -r -p 'press enter to preview changes'

	# preview changes
	# note: gofmt can only modify expressions, not func declarations!
	gofmt -r "$patt -> $repl" ./*.go | less
	read -r -p 'press enter to accept changes'

	# execute
	gofmt -r "$patt -> $repl" -w ./*.go
	# TODO: gapat
}

god() {
	: generate documentation for file
	# godoc is only for generating stdlib docs?
	# https://pkg.go.dev/golang.org/x/tools/cmd/godoc

	pushd "$(dirname "$1")" || return
	< "$(basename "$1")" grep -P '^(type|func)' |
		grep -Pow '[A-Z]\w+' |
		sort -u |
		xargs -n1 go doc 2> /dev/null |
		grep -Pv '^package'
	popd || :
}

god2() {
	# TODO: label arrows by number of connections
	gomod=$(find . -name go.mod | head -n1)
	basedir=$(dirname "$gomod" | sed -r 's|^\./||')
	modname=$(< "$gomod" grep ^module | cut -d' ' -f2) # foo/bar/baz
	rgl -x "\t(\w+ )?\"${modname}[^\"]+\"" |
		sed -r "
			s@($basedir|$modname)/?@@g	# strip lhs path and rhs modname
			s/\t[^\"]+/\t/			# remove import aliases
			s/:/ ->/			# d2 arrow (space required)
			s|/[^ /]+\.go||			# strip filename (else too many boxes)
		" |
		sort -u |
		d2 - foo.svg
}

# }}}
# js {{{

tsc() {
	local cmd
	cmd=$(ls ./node_modules/.bin/tsc || which tsc)
	"$cmd" --version
	"$cmd" "$@"
}

jimp() {
	: add all found dependencies -- use with caution
	rg -t ts -Io ' from "[^:/]+";$' |
		sort -u |
		cut -d'"' -f2 |
		while read -r pkg; do
			< package.json grep -Fq "\"$pkg\"" || echo "$pkg"
		done |
		xargs pnpm add
}

jx() {
	pkgmgr() {
		if [[ -f yarn.lock ]]; then
			echo yarn
		elif [[ -f $(_get_repo_root)/pnpm-lock.yaml ]]; then
			echo pnpm
		else
			echo npm
		fi

	}

	cmd=$(< package.json jq -r .scripts | grep : | fzh | cut -d'"' -f2)
	[[ -n $cmd ]] && "$(pkgmgr)" "$cmd"
}

jmake() {
	: convert scripts to Makefile

	keys=$(< package.json jq -r '.scripts | keys[]')

	cmds=$(echo "$keys" |
		while read -r cmd; do
			echo "${cmd//:/-}:" # make targets cannot contain :
			< package.json jq -r '.scripts."'"$cmd"'"' |
				sed 's/&& /\n/g; s/\"/"/g' |
				prepend '\t'
			echo
		done)

	cat <<- EOF | tee -a Makefile
		.PHONY: $(<<< "$keys" tr : - | xargs)
		$cmds
	EOF
}

jup() {
	# https://stackoverflow.com/a/47948461
	_js_pkgs() { < package.json jq -r '[.dependencies, .devDependencies] | add | keys[]'; }
	_js_pkg_ver() { < package.json jq -r "[.dependencies, .devDependencies] | add | .$1" | tr -d '^~'; }

	: upgrade npm package
	pkg=$(_js_pkgs | fzf)
	curr_ver=$(_js_pkg_ver "$pkg")
	target_ver=$(c "https://www.npmjs.com/package/$pkg?activeTab=versions" |
		grep -Po '\d+?\.\d+?\.\d+?</a></td><td class="downloads">[0-9,]+' |
		sed -r 's|</a></td><td class="downloads">|\t|' |
		sort -rV |
		sed "/^$curr_ver/,\$d; /\t0$/d" | # filter to versions newer than current
		sort -k2n |                       # sort by downloads
		fzf --tac --prompt="$pkg (current: $curr_ver)" --accept-nth=1)
	# npm install (update?) / yarn upgrade
	echo yarn upgrade "$pkg@^$target_ver"
}

# pnpm depcheck --ignore-bin-package --json |
# 	jq .devDependencies[] |
# 	xargs pnpm remove

# }}}
# c {{{

x() {
	\ls ./*.c 2> /dev/null || return
	n=$(basename "$(realpath .)")
	gcc -o "$n" ./*.c && "./$n"
}

mch() {
	# f=$1

	: [re]generate header files
	# TODO: should be vim autocmd?
	for f in *.c; do
		[[ $f == main.c ]] && continue

		h="${f/.c/.h}"
		if [[ -f $h ]]; then
			# for merge to work, fn decls must all be placed at the
			# bottom of the .h file. includes, macros, structs
			# should be placed at the top. (is there a recommended
			# order?)
			{
				< "$h" grep -Pv '\);$' # discard existing fn decls
				cproto "$f" | sed 1d   # cproto only generates fn decls
			} | sponge "$h"
		else
			cproto "$f" > "$h"
		fi
	done
}

chemo() {
	# TODO: integrate into vim exec (scanning all files may be tricky though)
	: determine module of c header file
	find /usr/include |  # all header files live here (hopefully)
		grep "$1$" |        # curl/curl.h
		xargs pacman -Qoq | # owner of file
		xargs pacman -Qlq | # files owned by pkg
		grep -m1 pc$ |
		xargs basename |
		cut -d. -f1 |
		xargs pkg-config --cflags --libs
}

# }}}
# sql {{{

if [[ -n $POSTGRES_URL ]]; then
	alias psql='psql $POSTGRES_URL'
fi

sq() {
	: sq file.sql sql-command
	{
		if [[ -f $1-wal ]]; then
			cp "$1" tmp.db > /dev/null
			echo "$2" | sqlite3 tmp.db
		elif [[ -f $1 ]]; then
			echo "$2" | sqlite3 "$1"
		fi
	} | jq '.[]'
}

psqlj() {
	: convert psql output to jq
	# useful for times when it is easier to write jq than sql
	# https://www.pgcasts.com/episodes/generating-json-from-sql
	psql -c "select row_to_json(t) from ($1) t" |
		grep -Po '\{.+' |
		jq
}

sqt() {
	: list tables

	prv_cmd="rg -m1 --line-number --multiline --multiline-dotall '{}.+?;$' | grep -Pv ':(\s*(--)?)$'" # horrendous

	# if `CREATE TABLE` statements are guaranteed to be on one line,
	# this multiline hackery can be removed
	rgml -I 'CREATE TABLE.+?\(' |
		sed -rz 's/\n/ /g; s/\( /\n/g' |
		awk '{print $NF}' |
		fzf --preview="$prv_cmd" --preview-window='right,60%,border' --ansi
}

psch() {

	# psql \d+ is too verbose, so we must use pg_dump

	# use subshell to avoid persisting sourced vars
	(
		f=$(rg -l --hidden '^POSTGRES_URL' "$REPO" | grep -v -e template -e Makefile) # inner
		source "$f"

		# env has all the correct values, but domain:port is wrong. the
		# mapping is found in a docker-compose.yml

		inner_port=$(<<< "$POSTGRES_URL" grep -Po '\d+')
		outer_port=$(rg -Iom1 "\d+:$inner_port" "$REPO" | # one can only hope the correct file is selected
			head -n1 |
			cut -d: -f1)
		POSTGRES_URL=$(<<< "$POSTGRES_URL" sed -r "s|@[^/]+|@localhost:$outer_port|")

		# getting the quoting right is extremely difficult, so just
		# dump to file
		pg_dump --schema-only "$POSTGRES_URL" > /tmp/s

		# TODO: sqruff would be nice...
		prefix='CREATE TABLE public'
		prv_cmd="cat /tmp/s | sed -rn '/$prefix.{} /,/\);/p' | bat --color always --style=auto --language=sql 2>/dev/null"

		tbl=$(psql "$POSTGRES_URL" -c '\dt' |
			awk 'NR>3{print $3}' |
			grep . |
			fzf --preview="$prv_cmd" \
				--preview-window='right,60%,border' --ansi)

		rg -l "$prefix\.$tbl" "$REPO" |
			head -n1 |
			xargs nvim +'/\v'"$prefix\.$tbl"

	)

}

sqq() {
	: view sqlc queries
	# TODO: this needs to be in vim

	cd "$REPO"

	# shellcheck disable=SC2329
	f() {
		# we cannot inherit REPO, too bad
		# novum-api/src/sql/query/users.sql:-- name: FindUserByEmail :one
		l=$(< /dev/stdin)
		f=$(<<< "$l" cut -d: -f1)
		s=$(<<< "$l" cut -d: -f2-)
		< "$f" sed -rn "/^$s/,/;/p"
	}
	export -f f
	rgl -t sql '^-- name:' | fzr --preview='echo {} | f'
	unset f
}

# }}}
# jq {{{

alias jqc="jq -c" # basically just colors output

jqk() {
	: https://gist.github.com/pedroxs/f0ee8c515eea0dbce2e23eea7c048e10#file-jq-filters-sh-L2
	jq < /dev/stdin -r '.. | objects | with_entries(select(.key | contains("'"$1"'"))) | select(. != {}) | .'"$1"
}

jqt() {
	: select jq fields from a flat sequence of objects and format as tsv with alignment
	fields=()
	for x in "$@"; do
		fields+=(".$x")
	done
	query="$(ajoin "${fields[@]}")" # .foo,.bar,.baz

	# query="[$(echo "$@" | sjoin ,)]"

	>&2 echo "${fields[@]}" | tr ' ' '\t'

	# note: jq knows how to if read from stdin if no file passed

	# this is the 'pure' way to do it (select and format are 2 different steps)
	# < /dev/stdin jq "[$query]" |
	# 	jq -r 'map(tostring) | @tsv'

	< /dev/stdin jq -r "[$query] | @tsv" |
		colt

}

# }}}
# docker {{{

alias dolf='docker logs --tail=1 -f'

dps() {
	# # docker ps adds too much padding, and cannot truncate long values
	# docker ps -a --format "table {{.Names}}\t{{.State}}\t{{.Status}}\t{{.ID}}\t{{.RunningFor}}" |
	# 	sort

	docker ps -a --format=json |
		# note: ID is usually just visual noise, but placing it any
		# later in the seq will make it hard to extract (with cut/awk)
		jqt 'Names[0:50]' State ID Status RunningFor Ports 2>&1 |
		sort |
		colt
}

docl() {
	docker system df || return
	docker system prune --all
	docker volume ls -f dangling=true -q | xargs docker volume rm # usually not important
}

dolc() {
	: clear logs of docker image without restart
	# https://stackoverflow.com/a/42510314
	[[ $# -eq 0 ]] && return
	name=$1
	json="$(docker inspect --format='{{.LogPath}}' "$name")"
	# [[ ! -f $json ]] && return
	sudo "$(command ls)" "$json" > /dev/null || return
	# doesn't work for go binary? file -is- cleared, but `docker logs` still produces old output
	: | sudo tee "$json"
	sudo du "$json"
	echo "cleared $name $json"

	# remove lines with null bytes
	# https://stackoverflow.com/a/77907885
	sudo grep -r -l -a -P '\x00' /var/lib/docker/containers/ |
		while read -r f; do
			sudo perl -pi -e 's/\x00//g' "$f"
		done

	# dolf "$name"
}

doslow() {
	: list slowest steps in a docker log

	if [[ $# -eq 0 ]]; then
		# devc logs
		grep -RPh '\d+/\d+\]' .config/Code/logs/*/window1/exthost/ms-vscode-remote.remote-containers |
			grep -P '\d{3,}\.\ds$' |
			cut -d= -f2- |
			sort -nr |
			sort -u |
			# dedup by step
			while read -r line; do
				step=$(<<< "$line" cut -d' ' -f2)
				if ! <<< "$prev" grep -Fq "$step"; then
					echo "$prev"
				fi
				prev=$line
			done |
			awk '{print $NF,$0}' |
			sort -nr |
			cut -f2- -d' '

		return
	fi

	if
		steps=$(< "$1" grep -P '^#\d+ DONE' |
			sort -Vu |
			awk '!a[$1]++') &&
			[[ -n $steps ]]
	then
		paste <(echo "$steps") \
			<(<<< "$steps" cut -d' ' -f1 |
				while read -r n; do
					< "$1" grep "$n" |
						tac |
						grep -Pm1 "$n \[" |
						cut -d' ' -f2-
				done)
	else
		echo all ok
	fi
}

dostop() { docker ps --all --quiet | xargs docker stop; }

donuke() {
	: stop and remove all containers
	mapfile -t containers < "$(docker ps --all --quiet)"
	docker stop "${containers[@]}"
	docker rm "${containers[@]}"
}

dodu() {
	: inspect size of image
	docker image history --no-trunc --format=json "$1" |
		jqt Size CreatedBy
}

# # list docker containers responsible for a given high-memory/cpu process
# top -bn1 |
# 	grep -m5 python |
# 	cut -d' ' -f1 |
# 	xargs -n1 pstree -as |
# 	grep moby |
# 	sort -u |
# 	grep -Po '[0-9a-f]{64}' |
# 	xargs -I{} sudo docker ps -f id={}

# }}}
# ssh {{{

# rsync ~/.config/readline/inputrc "$remote:$HOME/.inputrc"
# ssh "$remote" 'touch ~/.hushlogin' # suppress annoying ubuntu login msg

# sget() {
# 	remote=$1
# 	if [[ -f $1 ]]; then
# 		rsync --no-relative --files-from="$1" "$remote:/" .
# 	else
# 		rsync --exclude=".*/" "$remote:$1" .
# 	fi
# }

# sget() { rsync --exclude=".*/" "$1:$2" .; }
# sput() { rsync --exclude=".*/" "$2" "$1:~/"; }

# https://gist.github.com/cmbaughman/6a2ae275e0c0f39f42d95a728e07f796
# https://www.redhat.com/sysadmin/ssh-automation-sshpass

# }}}
# files, navigation {{{

zd() { zip -jr "${1%/}" "${1%/}"; }                         # zip directory (flat); stripping trailing slash is important
zin() { < /dev/stdin zip --junk-paths --names-stdin "$1"; } # pipe files from stdin to zip

mcd() {
	: mkdir any number of paths, cd to last
	# it is uncommon for >1 arg to be passed, so this is more for cd
	# [[ $# -eq 0 ]] && return
	local p
	for p in "$@"; do mkdir -p "$p" || :; done
	# shellcheck disable=SC2164
	[[ -d $p ]] && cd "$p"
}

if [[ -n $MU ]]; then
	: wrap rm in a python check to prevent accidental deletion of some dir
	rm() {
		# parsing arbitrary args with bash is nonsense

		if [[ $* == *"$MU"* ]]; then
			python3 -c "
import sys
if \"$MU\" in {x.rstrip('/') for x in sys.argv}:
    print('FATAL')
    raise Exception
" "$@"
		fi

		command rm -v "$@"
	}
fi

files() {
	: list files in use by a process
	pidof "$1" |
		tr ' ' , |
		xargs lsof -p 2> /dev/null |
		grep -Po '/[a-z].+' |
		sort -u |
		grep -P --color=never '^/(home|run)'
}

mi() {
	mediainfo --Output=JSON "$@" |
		jq '.[] | {x:.media.track[0].OverallBitRate, y: .media.track[1].Height//0|tonumber, z:.media."@ref"}' |
		jqt x y z |
		sort -rn |
		grep -v -e srt -e vtt

}

ffconcat() {
	# cat *mp4 > out.mp4 does not work
	# https://trac.ffmpeg.org/wiki/Concatenate#Automaticallygeneratingtheinputfile
	ext=$(<<< "$1" awk -F. '{print $NF}')
	files=$(for f in "$@"; do
		echo "file '$(realpath "$f")'" # single quotes must be preserved
	done |
		sort)
	ffmpeg -f concat -safe 0 -i <(echo "$files") -c copy output."$ext"
}

# }}}
# stdout manipulation {{{

# ljoin() { < /dev/stdin tr '\n' , | sed 's/,$//'; } # lines to comma-delimited str (rare?)
append() { < /dev/stdin awk "{print \$0 \"$1\"}"; }
count() { < /dev/stdin sort | uniq -c | sort -n; }           # i have done this too many times
desec() { < /dev/stdin sed -r 's/:[0-9]{2}\.[0-9]{8,}Z//'; } # remove seconds, for ease of filtering logs
join2() { < /dev/stdin paste -d " " - -; }
largs() { < /dev/stdin xargs --delimiter='\n' "$@"; } # split xargs by newline instead of space
line() { < /dev/stdin sed -n "${1}p"; }
mean() { < /dev/stdin awk '{ sum += $0; n++ } END { if (n > 0) print sum / n; }'; } # https://stackoverflow.com/a/19149931
paren() { < /dev/stdin prepend '(' | append ')'; }
prepend() { < /dev/stdin awk "{print \"$1\" \$0}"; }
seen() { < /dev/stdin awk '!a[$0]++'; } # https://paweldu.dev/posts/awk-clever-way-to-remove-duplicate-lines/
sum() { < /dev/stdin paste -sd+ | bc; }
surround() { < /dev/stdin awk "{print \"$1\" \$0 \"$1\"}"; }
tojson() { node --eval "console.log(JSON.stringify($(< /dev/stdin)))" | jq; }
urldec() { node --eval "console.log(decodeURIComponent(process.argv[1]))" "$1"; }
urlenc() { node --eval "console.log(encodeURIComponent(process.argv[1]))" "$1"; }

# highlight query, but output the entire file
# grep "$query\|$"

ajoin() {
	: join space-delimited array
	# ljoin takes lines (via stdin), this takes array (via arg)
	# https://stackoverflow.com/a/9429887

	input=("$@")
	IFS=, # cannot be inlined into echo
	echo "${input[*]}"
}

dehtml() {
	< /dev/stdin perl -MHTML::Entities -pe '
			binmode(STDOUT, ":encoding(UTF-8)");	# https://stackoverflow.com/a/47940728
			s/<br[^>]*>/\n/g; s/<[^>]*>//g;		# https://stackoverflow.com/a/19878198
			decode_entities($_);			# https://stackoverflow.com/a/13161719
		'
}

plot() {
	: plot latency from json logs
	script=$(
		# https://unix.stackexchange.com/a/754698
		# https://superuser.com/a/108380
		cat <<- EOF
			show terminal;
			set ylabel 'ms';
			set xdata time;
			set timefmt '%Y-%m-%dT%H:%M';
			plot '-' using 1:(\$2/1000000)
		EOF
	)
	# echo "$script"
	< "$1" grep latency |
		grep -Fv -e null -e '={' | # remove invalid nested json
		# tail -n10000 |
		jqt time[0:19] latency |
		time gnuplot --persist -e "$script"
}

# }}}
# web {{{

upload() {
	: upload file to catbox.moe, copy link to clipboard

	# https://github.com/Allypost/bash-scripts/blob/fa4b1006a1c022484c3d48a05ec0ff1c94b9a541/catbox#L116
	# https://github.com/mananapr/dotfiles/blob/9dc9196224c2c84e4265e517dc36af1c79637eb7/bin/catbox
	# https://github.com/search?type=code&q=curl+catbox.moe+language%3AShell+fileupload

	[[ ! -f $1 ]] && return
	link=$(
		curl -s --form "reqtype=fileupload" \
			--form "fileToUpload=@$1" \
			https://catbox.moe/user/api.php #| tee /dev/null
	)

	echo -en "Uploaded to: \e[1m$link\n" # idk what that escape does
	echo -n "$link" | xclip -sel c
}

wifi() {
	: connect to wifi network without nmtui
	ssid=$(nmcli --terse device wifi list |
		fzf --reverse |
		cut -d: -f8)
	nmcli --ask device wifi connect "$ssid" < /dev/tty # password $password
}

getmail() {
	mail 2>&1 | grep 'No new mail.'
	[[ $(notmuch count tag:inbox and tag:unread and date:today) -eq 0 ]] && return
	exec neomutt
	# neomutt -z
}

get_cookie() {
	\cp ~/.mozilla/firefox/*default/cookies.sqlite tmp.db
	if <<< "$1" grep -q ' '; then
		sql="select value from moz_cookies where $1 order by id desc"
	else
		sql="select value from moz_cookies where name = '$1' order by id desc limit 1"
	fi
	sqlite3 tmp.db "$sql" 2> /dev/null
	rm tmp.db > /dev/null
}

sunpos() {
	# azimuth 1.7 - 1.8(?)
	# sun enters window as low as 1.35
	{
		curl -sL https://raw.githubusercontent.com/mourner/suncalc/refs/heads/master/suncalc.js |
			sed -rn '$d; /easier/,$p'
		echo "console.log(JSON.stringify(SunCalc.getPosition(new Date(), $(curl -sL "https://ipinfo.io" | jq -r .loc))))"
	} | node
}

subs() {
	# https://www.azsubtitles.com/restful-api
	f=$(fzf)
	c "https://www.azsubtitles.com/api/search?q=${1// /+}" | # TODO: fname -> infer title
		jq -er '.Items[0] | .UID' |
		prepend 'https://www.azsubtitles.com/api/movie' |
		xargs curl -sL |
		# File can contain a list of episodes, but we usually just want the first element
		jq -er '.AllSubs[] | select(.Language.Title == "English") | .File[0].Url' |
		sort |
		# head -n1 |
		fzf -0 --preview="curl -sL --globoff {} | head -n50" |
		sed -r 's/ /%20/g' |            # url must be encoded
		xargs curl --globoff > "$f".srt # but also need globoff to ignore {}[]

	# # requires unzip
	# c 'https://subf2m.co/subtitles/parivaar' |
	# 	grep -Po "/subtitles/[^/]+/english/\d+" |
	# 	prepend https://subf2m.co |
	# 	append /download

}

inci() {
	inci.js "$1" |
		jq '.data.items[]' |
		jqt year title director[0]
}

rewe() {
	# https://ss64.com/bash/mapfile.html
	zip=$1
	# TODO: watch 10 s
	readarray -t x < <(notmuch show 'subject:Vielen Dank fr deine Bestellung!' |
		grep -Fm1 http |
		xargs curl -sL |
		grep -Pom1 '[A-Z]-[A-Z0-9]{3}[^<]+' |
		xargs -I{} curl --fail-with-body -sL 'https://wannkommt.rewe.de/api/delivery/{}' \
			-X POST \
			-H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:142.0) Gecko/20100101 Firefox/142.0' \
			-H 'Content-Type: application/json' \
			--data-raw '{"zipCode":"'"$zip"'"}' |
		jq '
			.address.latitude,
			.mapDetails.driverLocation.latitude,
			.address.longitude,
			.mapDetails.driverLocation.longitude
		')
	echo "${x[@]}"
	if [[ ${x[1]} == null ]]; then
		echo 'driver location not yet available'
		return
	fi
	if [[ ${x[0]} == null ]]; then return; fi # delivery over
	# unit unclear; value starts at about 1.4, ends at 0.1
	echo "sqrt( (${x[0]}-${x[1]})^2 + (${x[2]}-${x[3]})^2 )" | bc
}

# }}}

de() {
	while true; do
		read -r w < /dev/tty
		# TODO: if jq fail, try uppercase
		w1=$(urlenc "${w:0:1}")
		w2=$(urlenc "${w:0:2}")
		url="https://kaikki.org/dictionary/German/meaning/$w1/$w2/$w.jsonl"
		# echo "$url"
		c "$url" |
			jq -er .senses[].glosses[] 2> /dev/null |
			uniq
		echo
	done
}

bb() {
	# bw config server

	j=$(bw list items)
	export j

	# shellcheck disable=SC2329
	f() { <<< "$j" jq --color-output ".[]|select(.name==\"$1\")"; }
	export -f f

	name=$(<<< "$j" jq -r '.[]|select(.login.password)|.name' |
		fzf --preview='f {}' --preview-window='right,60%,border')
	unset f

	[[ -z $name ]] && return
	<<< "$j" jq -r ".[]|select(.name==\"$name\")|.login.password" |
		xclip -selection clipboard
	echo "copied password for $name"
	unset j
}

e() {
	: open recent command in dummy sh file
	cmd=$(history | fzf --reverse --tac | awk '{$1="";print $0}')
	# WARN: sed -i wipes undo history
	# sed -i "1s/^/$cmd\n/" ~/foo.sh
	# sed -i "1 i\\$cmd" ~/foo.sh
	{
		echo "$cmd"
		cat ~/foo.sh
	} | sponge ~/foo.sh
	nvim +1 ~/foo.sh
}

sleep_until() {
	now=$(date +%s)
	end=$(date --date="$1" +%s)
	sleep $((end - now))
}

wn() {
	: wiki news of the month
	# shellcheck disable=SC2329
	f() {
		# https://news.ycombinator.com/item?id=12292723
		# https://old.reddit.com/r/commandline/comments/mty60c
		< /dev/stdin cut -d/ -f3 |
			\xargs -I{} curl -sL 'https://en.wikipedia.org/w/api.php?format=json&action=query&titles={}&prop=extracts&explaintext=true' |
			jq -r .query.pages[].extract |
			fold -sw75
	}
	export -f f
	c 'https://en.wikipedia.org/wiki/Portal:Current_events/September_2025' |
		grep -Po '/wiki/[^"]+' |
		count |
		awk '$1>=7{print $2}' |
		sort |
		fzr --preview='echo {} | f'

	unset f
}

nmsr() {
	(($# == 0)) && return
	# notmuch search is always word-based, never partial
	notmuch search --format=json "$1" |
		jq -r '.[]|[.timestamp,.thread,.authors,.subject]|@tsv' |
		while read -r l; do
			<<< "$l" cut -f1 | \xargs -I{} date --date=@{} -Im | tr '\n' '\t'
			<<< "$l" cut -f2-
		done |
		# this is all because 1) notmuch show --part is so annoying,
		# and 2) json output is unstructured and cannot be relied on
		# (need the first `content` field that is a string (not array))
		# json[0][0][0].body[0].content
		# json[0][0][0].body[0].content[0].content
		# json[0][0][0].body[0].content[0].content[0].content
		fzr --preview='echo {} | cut -f2 | xargs notmuch show --format=json | gron | grep -Pm1 "\]\.content = \"" | cut -d" " -f3- | tr -d ";" | jq -r | fold -sw80'
	# TODO: on select, reply to email?
}

# rgf redirect ~/.local/state/mpv/watch_later |
# 	xargs rm

# < ~/dwm/config.h grep -Pv '^\s*//' |
# 	grep -Pow '\{MODKEY, XK_[a-z]' |
# 	sort |
# 	cut -d_ -f2 |
# 	tr -d '\n'
# 	TODO: xargs tr -d abcdefghijklmnopqrstuvwxyz

# seq 1 10 |
# 	while read -r i; do
# 		curl -sL "https://vimcolorschemes.com/i/new/b.dark/$( ((i > 1)) && echo "p.$i")" |
# 			grep -Po 'href="[^"]+' |
# 			tail -n20
# 	done |
# 	cut -d/ -f2- |
# 	sort -u |
# 	while read -r x; do
# 		< ~/.local/share/chezmoi/dot_config/nvim/lua/plugins.lua grep -Fq "$x" || echo "$x"
# 	done

# nvim --headless "+Lazy! clean" +qa ; vim foo.{sh,js,py,lua,ts}

fftabs() {
	# aur/mozlz4-bin
	mozlz4 -x ~/.mozilla/firefox/*default/sessionstore-backups/recovery.jsonlz4 |
		jq -r '.windows[0].tabs[].entries[-1].url' |
		grep ^http |
		sort -u
}

topa() {
	# TODO: confusingly, there are still 2 different disq dirs:
	# ~/gripts/disq is older, ~/disq is newer and uses sqlc. both use the
	# same db (hardlinked). no attempt has been made to unify the two

	# shellcheck disable=SC2329
	f() {
		# because what's stopping me from just making another sqlite
		# call?
		artist=$(< /dev/stdin)
		q=$(< ~/disq/queries/artists.sql sed -rn '/GetAlbums/,/;/p' | # extract the query we want
			sed -r "s/\?/'$artist'/")                                    # inject the arg
		# xargs -I{} sqlite3 -- ~/disq/collection2.db '{}'
		sqlite3 -tabs -- ~/disq/collection2.db "$q" 2> /dev/null |
			colt
	}
	export -f f

	< ~/gripts/disq/queries/top_artists_by_avg_rating.sql sqlite3 -tabs \
		~/gripts/disq/collection2.db 2> /dev/null |
		sort -k2 -t$'\t' -k1 |
		fzf --tac --reverse --no-sort --preview='echo {} | cut -f1 | f' --preview-window='right,60%,border'

	# fzf --preview='echo {} | cut -f1 | xargs -d"\n" ~/disq/disq -artist' --preview-window='right,60%,border'

	unset f
}

randalb() { # {{{
	# generate list of random albums rated >=3 amounting to 50 GB
	set -euo pipefail
	sql=$(
		# note: unlike select_random.sql, the ORDER BY random() is used
		# in the outer query
		cat <<- EOF
			WITH rand AS (
			    SELECT
			        albums.id,
			        albums.title
			    FROM albums
			    WHERE albums.rating >= 3
			)

			SELECT
			    group_concat(artists.name, ' ') AS artist,
			    rand.title AS album
			FROM
			    rand
			INNER JOIN albums_artists
			    ON rand.id = albums_artists.album_id
			INNER JOIN artists
			    ON albums_artists.artist_id = artists.id
			GROUP BY album
			ORDER BY random();
		EOF
	)

	# size=0
	((size = 0, max = 50 * 1024 ** 2)) # 50 GB
	db=~/disq/collection2.db
	dirs=()

	rows=$(sqlite3 -json "$db" "$sql" 2> /dev/null | jq -c .[])

	while read -r row; do

		# TODO: bash_rematch
		artist=$(<<< "$row" jq -r .artist | sed -r 's/ \([0-9]+\)$//')
		album=$(<<< "$row" jq -r .album)

		# double find: 1m40
		# try: 30s (3x)
		# lazy: 8s (4x)

		# d=$(find "$MU/$artist" -mindepth 1 -iname "$album*" |
		# 	grep . |
		# 	head -n1) || continue

		d=$({
			if [[ -d $MU/$artist ]]; then
				find "$MU/$artist" -mindepth 1 -iname "$album*"
			else
				find "$MU" -maxdepth 1 -iname "$artist" -print0 |
					xargs -0 -I{} find {} -mindepth 1 -iname "$album*"
			fi
		} |
			grep . |
			head -n1) || continue

		dirs+=("$d")
		((size += $(du -cs "$d" | tail -n1 | cut -f1)))
		((size >= max)) && break

	done <<< "$rows"

	printf "%s\n" "${dirs[@]}" | sort

} # }}}

lba() {
	# curl -sL --fail "https://letterboxd.com/hejops$url" > /dev/null && continue

	curl -sL 'https://letterboxd.com/ajax/activity-pagination/hejops/following/' |
		grep -P 'rated-(8|9|10)' |
		grep -Po '/film/[^/]+' |
		sort -u |
		while read -r x; do
			curl -sL --fail "https://letterboxd.com/hejops$x" > /dev/null && continue
			echo "https://letterboxd.com$x"
		done |
		fzf -m |
		xargs -n1 xdg-open
}

tsg() {
	token=$(get_cookie remember_user_token)

	pgs=$(curl -sL "https://app.thestorygraph.com/books-read/hejops" \
		-H "Cookie: remember_user_token=$token" |
		grep search-results-count |
		grep -Pom1 '\d+' |
		tail -n1)

	seq 1 $((pgs / 10)) |
		parallel -q -I{} curl -sL "https://app.thestorygraph.com/books-read/hejops?page={}" \
			-H "Cookie: remember_user_token=$token" |
		grep 'rounded-sm shadow-lg dark:shadow-darkerGrey/40' |
		# uniq |
		cut -d'"' -f2 |
		awk '{print $NF, $0}' |
		sort -u |
		awk '{$1="";print $0}' |
		sed -r 's/(.+) by (.+)/\2\t\1/'
}

imm() {
	notmuch show from:noreply@immobilienscout24.de |
		grep -Po 'Adresse: [^(]+' |
		sed -r 's/([a-z])([A-Z])/\1\t\2/' |
		sort -u |
		fzf --accept-nth=2 |
		xargs -I{} notmuch show "from:noreply@immobilienscout24.de and body:{}" |
		grep -Fm1 'Scout-ID' |
		awk '{print $NF}' |
		prepend https://www.immobilienscout24.de/expose/ |
		xargs xdg-open

}

# curl -sL 'https://www.geoguessr.com/api/v3/users/6118c9f48db3190001c6d471' | jq
# curl -sL 'https://www.geoguessr.com/api/v3/users/6118c9f48db3190001c6d471/stats' | jq
# curl -sL 'https://www.geoguessr.com/api/v4/ranked-system/best/6118c9f48db3190001c6d471' | jq
# curl -sL 'https://www.geoguessr.com/api/v4/ranked-system/progress/6118c9f48db3190001c6d471' | jq

georank() {
	curl -sL 'https://www.geoguessr.com/api/v4/ranked-team-duels/me/teams/6097bf310e78f000019d9747' \
		--cookie "_ncfa=$(get_cookie _ncfa)" |
		jq -e '
		def cutoff: .bucket.promotionIndex;
		def current: .bucket.teams[] | select(.teamId == "6097bf310e78f000019d9747-6118c9f48db3190001c6d471") | .position;
		if .bucket then current<cutoff end
	' > /dev/null && echo ok
}

# < ~/geo/geo.csv shuf -n3 | cut -d, -f-2

# could replace xfer with this
# python3 -m http.server -d .

# echo ${files[@]} | entr -cr $cmd

kb() {
	if lsusb | grep -iq ergo; then
		# https://en.akkogear.com/faq/how-do-i-get-hold-tap-keys-by-via/
		# https://github.com/gabrielmscampos/ergodash-fw
		# https://github.com/AndrewKlement/ErgoDash_VIA/blob/main/ErgodashVia/keymap.json

		# pass env vars to dbus via systemd?
		# required for file picker; only once per boot (?)
		# https://bbs.archlinux.org/viewtopic.php?pid=2161602#p2161602
		source /etc/X11/xinit/xinitrc.d/50-systemd-user.sh

		ci https://usevia.app/design

	elif lsusb | grep -qw Elora; then
		/opt/vial-appimage/vial-appimage.AppImage

	elif lsusb | grep -q Kinesis; then
		f=/run/media/"$USER"/ADV360/layouts/layout1.txt
		if [[ ! -f $f ]]; then
			echo 'connect first'
			inotifywait -e create "/run/media/$USER"
		fi
		vim "$f"

	fi
}

_unused() {
	: list unused functions
	< ~/.bash_aliases grep -Po '^[a-z]\w+\(\)' |
		tr -d '()' |
		while read -r cmd; do
			< ~/.bash_history grep -wq "$cmd" && continue
			< ~/.bash_aliases grep -Pq "^$cmd\(\) \{.+; \}" && continue # ignore one-liners
			# len=$(< ~/.bash_aliases sed -rn "/^$cmd\(/,/^\}/p" | wc -l)
			len=$(type "$cmd" | sed '1,3d;$d' | wc -l) # more compact, 'neutralises' linebreaks
			echo -e "$len\t$cmd"
		done |
		sort -n |
		colt

	# # scripts explicitly called from cli
	# \ls ~/scripts | while read -r f; do
	# 	history | grep -wq "$f" && [ -x ~/scripts/"$f" ] && echo "$f"
	# done

	# # scripts accessed within the last 3 days (don't ask me why 3)
	# find ~/scripts -maxdepth 1 -type f -atime -3 -exec basename {} \; |
	# 	sort -u |
	# 	grep -v gitignore |
	# 	prepend "$HOME"/.local/bin/ #| largs chezmoi add -f

}

# rng() { for _ in "$(seq "${2:-1}")"; do echo $((1 + RANDOM % ${1:-100})); done; }
,pgrep() { \pgrep "$1" | xargs ps; } # ps for runtime
pk() { pgrep "$1" | fzf -m --tac --accept-nth=1 | xargs kill -9; }
pkill1() { \pgrep "$1" | sed 1d | xargs kill; }                                            # kill all procs except 1st
rng() { while read -r _; do echo $((1 + RANDOM % ${1:-100})); done < "$(seq "${2:-1}")"; } # shellharden
ya() { mpv --video=no "ytdl://ytsearch10:'$*'"; }
yi() { yt-dlp --dump-single-json --skip-download "$1" 2> /dev/null | jq -r '{title, description, webpage_url, channel_url}'; }
yt() { mpv --force-window "ytdl://ytsearch10:'$*'"; }

ys() { # read youtube subs in less
	yt-dlp -j "$1" |
		jq . |
		grep '=vtt' |
		grep -v tlang |
		tail -n1 | # auto subs are listed first
		cut -d'"' -f4 |
		xargs curl -sL |
		dehtml |
		grep -v -- '-->' |
		grep -Pvx '\s*' |
		tr '\n' ' ' |
		fold --spaces |
		less
}

nico() {
	# set -x
	# TODO: investigate --headless mode
	: launch searches in nicotine
	[[ ! -f $1 ]] && return
	xdotool key super+8
	# ensure window is focused!
	i=0
	while read -r line; do
		[[ -z $line ]] && break

		# slsk blocks all searches after a while
		# TODO: where are logs written to?
		((i++))
		[[ $i -ge 68 ]] && break

		echo "$i: $line"
		echo "$line" | xclip -sel c
		xdotool key ctrl+2 F6 ctrl+v enter
		sleep 3
	done < "$1"

	notify-send 'done'
}

epk() {
	: fix malformed epubs

	# according to the spec, `mimetype` must be the first listed file. note
	# that malformed epubs are still readable in zathura, so this is mainly
	# to prevent yazi from treatting malformed epubs as zip.

	for f in *.epub; do
		{
			# tmpdir=tmp
			# tmpname=foo
			tmpdir="$f.tmp"
			tmpname="$f.tmpf"

			# https://github.com/ikrukov/epub/blob/c663821de66d57b3d138dc9125251f40ea755c2c/script/pack_epub#L25
			# https://www.mobileread.com/forums/showthread.php?t=299415

			unzip -l "$f" > /dev/null 2> /dev/null || return                 # corrupt (unreadable)
			file --mime-type "$f" | grep -q 'application/epub+zip' && return # ok

			unzip "$f" -d "$tmpdir"
			cd "$tmpdir" || :
			echo 'application/epub+zip' > mimetype
			zip -X -0 --quiet "$tmpname" mimetype
			zip -X -9 --quiet --no-dir-entries --recurse-paths "$tmpname" META-INF OEBPS
			cd ..
			\mv "$tmpdir/$tmpname.zip" "$f"
			\rm -rf "$tmpdir"
			echo "fixed $f"
		} #&
	done

	# wait
}

gev() {
	: get env var
	find . -type f -name '.*env' -print0 |
		# probably better to force upper, but whatever
		\xargs -0 grep -Pi "$1" |
		awk -F: '!a[$2]++' |
		sed -r 's/:/	/' |
		colt
}

scan() {
	cd ~/scores || return
	f=$1
	n=1
	echo 'type x to exit'
	res=600
	while true; do
		echo -n "$n: "
		read -r ans < /dev/tty
		[[ $ans == x ]] && break
		# 600: 30 sec, 4.4 MB
		# 2400: 8 min, 48 MB
		scanimage --format=pdf --progress --resolution="$res" \
			--output-file "$f-$n-$res.pdf"
		((n++))
	done
	pdfunite "$(find . -name "$f-*" | sort -V)" "$f.pdf"
	rm -I "$f"-*
}

gcpd() {
	# german cities by population density
	curl -sL https://www.citypopulation.de/en/germany/cities/ |
		grep City |
		sed -r 's|td>|&\t|g' |
		dehtml | #2> /dev/null |
		tr -d , |
		awk -F$'\t' '{print $8/$9,$3,$1,$8,$9}' |
		sort -n |
		colt
}
