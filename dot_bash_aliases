# shellcheck shell=bash
# vim:ft=bash
# if possible, this file should remain under 1000 LOC. interactive shell
# startup time should remain under 0.02 s

_base_completer() {
	# https://mill-build.org/blog/14-bash-zsh-completion.html#_conclusion
	# https://www.gnu.org/software/bash/manual/html_node/A-Programmable-Completion-Example.html

	local f=$1                   # func(string) string
	((COMP_CWORD > 1)) && return # actual func should only accept 1 arg

	_gen() {
		local idx=$1
		shift
		local words=("$@")
		local curr_fragment=${words[idx]}

		# for a func with 1 arg, only this func needs to change
		f "$curr_fragment"
	}

	# COMP_CWORD: number of "completely typed" words (e.g. `$ foo b|` == 1 word, but `$ foo b |` == 2 words)
	# COMP_WORDS: all words currently typed

	# local raw
	# mapfile -t raw < <(_gen "$COMP_CWORD" "${COMP_WORDS[@]}") # SC2207
	# local matches=("${raw[@]}")
	# if ((${#raw[@]} == 1)); then # 1 match, autocomplete
	# 	# matches+=("${raw[0]%%:*}")  # strip from : onwards (could use \t, for example)
	# 	matches+=("${raw[0]}")
	# fi

	local IFS=$'\n'
	local matches
	mapfile -t matches < <(_gen "$COMP_CWORD" "${COMP_WORDS[@]}")

	if
		# if COMPREPLY is an array with only one unique element, the
		# completion is accepted immediately (with trailing space)
		((${#matches[@]} == 1))
	then
		COMPREPLY=("${matches[0]}")

	else
		# otherwise, the maximally left-matching prefix is
		# autocompleted (if any), and all elements in the array are
		# displayed (with the prefix highlighted)
		COMPREPLY=("${matches[@]}")
	fi

}

# startup {{{

# https://wiki.archlinux.org/title/Systemd#Boot_time_increasing_over_time
# systemd-analyze blame | grep -P '\ds'
# systemd-analyze critical-chain
#
# sudo systemctl disable NetworkManager-wait-online.service # https://askubuntu.com/a/1018731
#
# journalctl --disk-usage                                                          # current usage
# journalctl -b -u systemd-journald | grep max                                     # current max
# sudo journalctl --vacuum-time=3d                                                 # truncate
# sudo sed -i -r 's/#SystemMaxUse.+/SystemMaxUse=100M/' /etc/systemd/journald.conf # set max (should be done on arch install)

# docker is disabled for now, because i literally never use it
# sudo systemctl disable docker.service

if [[ -f /tmp/updates ]] && ! pgrep pacman > /dev/null; then

	cat /tmp/updates

	if
		< /tmp/updates grep -q '^python ' &&
			! < /tmp/updates grep -Pq 'python (3\.\d+)\S+ -> \1'
	then
		echo -e "WARNING: major Python update\n"
		# TODO: update globally installed pips? (scrobblerh)
	fi

	if
		< /tmp/updates grep -q '^postgresql ' &&
			! < /tmp/updates grep -Pq 'postgresql (\d+)\S+ -> \1'
	then
		echo -e "WARNING: major postgresql update\n"
	fi

	if sudo pacman -Syu; then
		rm /tmp/updates

		# may get unset after update? not sure what causes it
		setxkbmap -layout us -option -option compose:rctrl #,caps:menu

	elif
		# if pacman hasn't been run in a long time, keys in keyring
		# will expire. pacman -Syyu OR updating archlinux-keyring
		# should fix this
		command -v expac > /dev/null &&
			last_update=$(expac --timefmt '%s' "%l" | sort -n | tail -n1) &&
			# https://stackoverflow.com/a/6948865
			[[ $(((last_update - $(date +%s)) / (60 * 60 * 24))) -gt 14 ]]
	then
		sudo pacman -Sy archlinux-keyring

	fi
fi

if ps --pid "$PPID" | grep -Fq wezterm; then

	[[ -f /tmp/verse ]] && [[ -s /tmp/verse ]] && cat /tmp/verse

	if [[ -d $SLSK ]]; then
		if
			# x=$(du -csh "$SLSK/complete" | head -n1 | grep G) &&
			# 	<<< "$x" grep -Po '^\d+' | \xargs -I{} test {} -ge 3

			# i like the idea of BASH_REMATCH, but it is
			# unfortunate that \S (et al) is not supported. there
			# is no noticeable performance difference
			# https://www.bashsupport.com/bash/variables/bash_rematch/
			[[ $(du -csh "$SLSK"/complete | tail -n1) =~ ^([0-9]+).+G ]] &&
				# [0] = full line
				# [@] = full line + all matches
				((BASH_REMATCH[1] >= 3))
		then
			echo -e "\n${BASH_REMATCH[0]}"
		fi
		unset x
	fi

fi

if ! ls /tmp/ssh-XXXXX* > /dev/null; then
	# pkill ssh-agent # deletes all existing sockets
	eval "$(ssh-agent -s)"

elif [[ -z $SSH_AUTH_SOCK ]]; then
	SSH_AUTH_SOCK=$(\ls /tmp/ssh-XXXXXX*/agent.*)
	export SSH_AUTH_SOCK
	find ~/.ssh -name 'gitlab*' | grep -v .pub | \xargs ssh-add -q

fi

[[ -f ~/jira.txt ]] && < ~/jira.txt cut -f1,3

# }}}
# aliases {{{

# alias dr=discogs_rate
# alias lc=leetcode.py # shadows lc binary (who?)
# alias mb=musicbrainz
# alias trk=trackratings.py
# alias wd=waitdie
alias ex=extract
alias gm=getmail
alias met=metronome
alias ns=notify-send
alias tt=taptempo
alias xo=xdg-open

alias rab='exec yazi "$HDD/books"'
alias rad='exec yazi "$SLSK/complete"' # TODO: investigate `ya pub`
alias rag='exec yazi "$HDD/guitar"'
alias ram='exec yazi "$MU"'
alias rat='exec yazi "$HDD/torrent" "$HDD/movies"'

# alias dA="dc artist:"
# alias dc="discogs_collection filter"
# alias dt="discogs_collection top"
# alias lock="[[ -d /sys/class/power_supply/BAT0 ]] && systemctl suspend && slock"
# alias mem='top -b -n1 -o %MEM | grep -m10 $USER'
# alias mem='top -bn1 | sed -rn "/PID/,$p" | sort -k10 -n | tail'
# alias pq="~/plaque/plaque"
# alias tx="tectonic -X"
# top -bn1 | sed -rn '/PID/,$p' | sed 1d | awk '{print $10}' | sum
alias au="audacious -H"
alias bh="vb -b"
alias cam="ls /dev/video* && exec mpv --fs av://v4l2:/dev/video0 --profile=low-latency --untimed" # TODO: handle >1 video device (just increment n until file not exist)
alias cdnp='cd "$(files mpv | grep mp3 | largs dirname)"'
alias ci="chromium --incognito"
alias colt="column -t -s$'\t'" # align tab-containing output -- https://unix.stackexchange.com/a/57235
alias cpu='top -b -n1 -o %CPU | grep -m10 $USER'
alias ctz='sudo timedatectl set-timezone $(timedatectl list-timezones | grep / | fzf)' # TODO: geolocate
alias cv='exec $EDITOR ~/cv/cv.typ'
alias datez='date -u +%FT%TZ' # utc (i.e. ignore current timezone)
alias eb="exec bash"
alias fzh="fzf --height=~33% --reverse" # height=~X% means min(input rows, window height * X%);
alias inw="inotifywait --monitor --recursive"
alias li="exec chromium --incognito 'https://www.linkedin.com/notifications/?midToken=AQECUGJ6GKhRSg'"
alias or="bash ~/gripts/oar/run.sh"
alias ports="netstat -tunlp | grep -P '^(udp|tcp)[^6]' | sort -k4 -V" # https://linuxize.com/post/check-listening-ports-linux/#check-listening-ports-with-netstat
alias pss="ps -e --format=lstart,pid,cmd --sort=start_time | grep -Fv -e '[' -e '('"
alias synctime="sudo ntpd --quit --panicgate"
alias tf="waitdie con; fix_tags"
alias trizen="trizen --aur-results-sort-by=votes --aur-results-sort-order=ascending"
alias tz=trizen # if gpg fail, gpg --recv-keys <key>

mem() {
	# https://unix.stackexchange.com/a/261252
	# free memory
	low=$(< /proc/zoneinfo grep low | awk '{print $NF}' | sum)
	a=$(
		cat <<- EOF
			{a[\$1]=\$2} END{ print a["MemFree:"]+a["Active(file):"]+a["Inactive(file):"]+a["SReclaimable:"]-(12*low); }
		EOF
	)
	free_mem=$(< /proc/meminfo awk -v low="$low" "$a") # kb
	echo "$free_mem" | bc
}

# alias y="bash ~/gripts/disq/ytm.sh"

y() { bash ~/gripts/disq/ytm.sh; }

EXA_ARGS=(

	# https://github.com/search?type=code&q=path:dot_config/eza
	# xdg dir is only for theme...?

	# --dereference # this actually undoes symlink `-> ...`
	--all # show dot files
	--color=always
	--git                     # status porcelain
	--group-directories-first # debatable
	--links                   # inode count
	--long                    # note: long names will not be wrapped
	--no-permissions
	--no-user
	--octal-permissions
	--time-style=iso

	--level=2
	--tree # will be slow in large (wide) dirs

	# --sort=modified
)

alias ls='exa ${EXA_ARGS[*]}'
alias lsl="ls --sort=modified"

# }}}
# frequent {{{

# copy cmd to clipboard
# history | fzf --tac | awk '{$1=""; print $0}' | xclip -sel c

# # show contents of most recent self-sent msg
# notmuch show --limit=1 from:hejops1 |
# 	grep -Po 'id:\S+' |
# 	xargs notmuch show --part=2

# < ~/.config/mpv/library fzf |
# 	prepend "$MU"/ |
# 	largs mpv

m() {
	{
		find "$HDD/movies" -type f
		cat ~/to_watch
	} | fzf --preview=
}

da() {
	local args=()
	[[ $# -eq 1 ]] && args+=(-artist "$1")
	~/disq/disq "${args[@]}"
}

cm() {
	if [[ $# -eq 0 ]]; then
		# note: files added to cm via `add -f <symlink>` are not
		# automatically updated when the src file (target of the
		# symlink) is modified. the symlink targets must always be
		# re-added. this will no longer be necessary when the scripts
		# repo is deprecated.
		chezmoi status | grep -Po '\.local/bin/.+' | largs chezmoi add -f 2> /dev/null

		chezmoi cd
	else
		chezmoi "$@"
	fi
}

bx() { [[ $# -gt 0 ]] && bash -x "$@"; }

replace() {
	_in_git_repo || return

	# check correct rep binary (not the lisp thing)
	if ! command -v rep | grep -Fq .cargo; then
		cargo install rep-grep
		return
	fi

	search=$1
	replace=$2
	_rg() {
		# --hidden will cause .git to be included!
		rg --hidden --glob='!.git/**' "$@"
	}

	if ! _rg -q -- "$search"; then
		echo "Pattern not found"
		return
	fi

	# note: backreferences use $1, not \1
	_rg --line-number -- "$search" | rep -- "$search" "$replace"
	read -r -p 'OK?' || return
	_rg --line-number -- "$search" | rep --write -- "$search" "$replace"

	# git diff
	gapat "$replace"
}

rge() {
	: edit files matching pattern
	staged=$(rg --files-with-matches "$@" | sort -u)
	if [[ $(<<< "$staged" wc -l) -gt 10 ]]; then
		echo "More than 10 files found"
	fi
	echo "$staged" |
		head |
		xargs nvim -p
}

sd() {
	: shutdown
	# uptime | grep hour || return/reboot

	waitdie mpv pacman curl #python

	if [[ -n $HDD ]]; then

		if
			files firefox | grep "$HDD"
		then
			inotifywait -e moved_to "$HDD"/movies
		fi
		killall firefox

		while
			f=$(files python | grep "$SLSK")
		do
			echo "$f" | largs -n1 inotifywait -e move_self
		done
		killall nicotine

	fi

	echo "Shutting down..."
	sleep 3
	shutdown now
}

rt() {
	: pass an array of relative paths to tagfix
	# note: dead symlinks are still displayed as if they exist

	< ~/.config/mpv/library fzf --multi --reverse --preview="ls \"$MU\"/{}" |
		prepend "$MU/" |
		while read -r d; do
			files mpv | grep -Fq "$d" && waitdie mpv >&2
			echo "$d"
		done |
		# to preserve the old behaviour (>1 args), remove -n1
		largs -o fix_tags

}

ytm() {
	f=$(mktemp)
	"$EDITOR" +startinsert "$f"

	waitdie mpv

	all_ids=
	while read -r query; do
		echo "$query"
		curl -sL 'https://music.youtube.com/youtubei/v1/search' \
			-H 'Content-Type: application/json' \
			--data-raw '{"context":{"client":{"clientName":"WEB_REMIX","clientVersion":"1.20240904.01.01"}},"query":"'"$query"'","params":"EgWKAQIIAWoSEAMQBBAJEA4QChAFEBEQEBAV"}' |
			gron |
			grep videoId |
			cut -d'"' -f2 |
			uniq |
			while read -r id; do # deduplicate across queries; somewhat useful i guess?
				<<< "$all_ids" grep -Fxq -- "$id" && continue
				all_ids+=$'\n'$id
				echo "$id"
			done |
			prepend 'https://youtube.com/watch?v=' |
			xargs mpv --video=no
	done < "$f"

	exit
}

# }}}

# git

# alias bb=gb
# alias gr=git_root
alias S=gS
alias b=git_branch
alias cr=git_root
alias e=v
alias gl=git_log
alias s=gS # should increasingly be done in vim

# discouraged due to double index keypresses: gt gf gb

# alias ga="git add"
# alias gdnw="git diff --color-words --no-index"
alias g..="git push --force-with-lease origin \$(_git_current_branch)"
alias g.="git push"
alias gC="git show HEAD | cat; git reset --soft HEAD~1"                                         # un-commit, but keep changes staged
alias gCH="git show --oneline HEAD | cat; echo; read -r -p 'confirm?'; git reset --hard HEAD~1" # un-commit, and discard changes
alias gdn="git diff --no-index"                                                                 # https://stackoverflow.com/a/17433969 -- TODO: handle symlinks
alias gdnc="git diff --color-words=. --no-index"                                                # diff by char; may be replaced with delta
alias gig='$EDITOR $(_get_repo_root)/.gitignore'
alias gx='git log --author=$(git config --get user.email) --branches --format="%h%x09%S%x09%s" --pickaxe-regex -S' # TODO: colt would be nice, but then it can't be an alias anymore

gdns() { gdn -U0 <(sort -u "$1") <(sort -u "$2"); }

# git info {{{
# functions that only report info

gls() { git ls-files "${1:-.}"; }

_get_remote() { git config --get remote.origin.url; }
_git_current_branch() { git branch --show-current; }
_in_git_repo() { git rev-parse --is-inside-work-tree > /dev/null 2> /dev/null; }

_get_repo_root() {
	if [[ $(basename "$PWD") == .git ]]; then
		realpath ..
	else
		git rev-parse --show-toplevel 2> /dev/null
	fi
}

_gmaster() {
	: get default branch, e.g. master
	# https://stackoverflow.com/a/44750379
	# default_branch=$(git symbolic-ref refs/remotes/origin/HEAD | sed 's|^refs/remotes/origin/||')
	git symbolic-ref refs/remotes/origin/HEAD 2> /dev/null | cut -d/ -f4
}

git_root() {
	if _in_git_repo; then
		cd "$(_get_repo_root)" || :
	elif [[ -n $REPO ]]; then
		cd "$REPO" || :
	fi
}

_git_http() {
	url=$1
	if [[ $url == http* ]]; then
		echo "$url"
	else
		tr <<< "$url" : / | sed -r 's|git@|https://|; s|.git$||'
	fi

}

gauthors() {
	: show authorship of file
	git blame --line-porcelain "$1" |
		sed -rn 's/^author (.+)/\1/p' |
		sort |
		uniq -c |
		sort -n
}

gL() {
	: show full history of a file/dir
	prv_cmd="echo {} | cut -d' ' -f1 | xargs -I{} git show --color=always {} $1"
	git log --oneline "$1" |
		tac |
		fzf --reverse --preview="$prv_cmd" --preview-window='right,60%,border' --ansi
}

gh() {
	: open remote url

	if ! repo=$(_get_remote); then
		echo "Current repo has no remote"
		return
	fi

	# better handled in vim

	# if [[ -f $1 ]] && git ls-files --error-unmatch "$1" &> /dev/null; then
	# 	# view file at its most recent commit
	# 	hash=$(git log --max-count=1 --pretty=format:%h -- "$1")
	# 	url="$repo/blob/$hash/$1"
	#
	# elif [[ -n $1 ]]; then # view repo at specific commit
	# 	h=$(git rev-parse --short --verify HEAD)
	# 	url="$repo/commit/$h"
	# fi

	url=${repo%*.git}
	url=$(_git_http "$url")
	echo "$url"
	# ubuntu is a pita:
	# gio: ...: Failed to find default application for content type ‘text/html’
	xdg-open "$url" ||
		firefox "$url"
}

gd() {
	if [[ $# -eq 0 ]]; then
		git diff
	elif
		# file with no local changes (or hash?)
		[[ $# -eq 1 ]] && git diff --exit-code "$1" > /dev/null
	then
		git diff HEAD^^ "$1" # check against last commit
	else
		git diff "$@"
	fi
}

# }}}
# git history {{{

_git_log_fzf() { # {{{
	_in_git_repo || return

	# TODO: heads may be 'cleared'
	# https://stackoverflow.com/a/30143136

	if ! ls "$(_get_repo_root)"/.git/refs/heads/* > /dev/null 2> /dev/null; then
		echo "no commits yet" >&2
		return 1
	fi

	prv_cmd="echo {} | cut -d' ' -f1 | xargs git show --color=always"

	args=()

	if
		[[ -f $1 ]] || [[ -d $1 ]]
	then
		args+=("$@")
		prv_cmd="echo {} | cut -d' ' -f1 | xargs -I{} git show --color=always {} $1" # restrict diff to selected file/dir

	elif
		[[ $# -gt 1 ]] # probably arbitrary options to git log
	then
		# TODO: allow arbitrary options to fzf (this is a can of worms)
		args+=("$@")

	elif
		# other dev branch
		[[ $# -eq 1 ]] &&
			git branch --remote | grep -Pqx "  origin/$1"
	then
		git pull > /dev/null 2> /dev/null
		args+=("origin/$1")

	elif
		m=$(_gmaster) && [[ $(_git_current_branch) == "$m" ]]
	then
		: on master

	elif [[ -n $m ]]; then # dev branch
		# note: use origin/master, because i tend to not actually
		# update my local master

		# note: .. and ... are NOT synonymous!
		#
		# A..B = raw diff between A and B
		#
		# A...B = diff between B and "last shared ancestor of A and B"
		# (almost always master); this is usually what we want
		#
		# https://i.sstatic.net/PboEt.png
		# https://stackoverflow.com/a/24186641

		args+=(--first-parent "origin/$m...HEAD")

	else
		: no remote yet
	fi

	# there is literally nothing to see in merge commits (Merge branch 'x'
	# into 'master'), so --no-merges is generally a good idea.
	#
	# however, commits that are the -result- of a merge are still included.
	# these merges can be further ignored with --first-parent, although
	# ignoring them may not always be desirable.
	#
	# alternatively, it may be good to indicate whether the commit was
	# committed in this branch, or simply pulled from remote.

	git log --decorate --oneline --no-merges "${args[@]}" |
		fzf -m --preview="$prv_cmd" --preview-window='right,60%,border' --ansi
}     # }}}
v() { # {{{
	: open recently modified files

	_in_git_repo || return

	# bat can keep up with rapid renders; pygmentize can't
	#
	# chezmoi/ > time cat dot_config/nvim/init.lua >/dev/null
	# real    0m0.001s
	#
	# chezmoi/ > time bat --color=always --style=auto --paging=never dot_config/nvim/init.lua >/dev/null
	# real    0m0.028s
	#
	# chezmoi/ > time pygmentize dot_config/nvim/init.lua >/dev/null
	# real    0m0.118s

	# on ubuntu:
	# ln -s /usr/bin/batcat ~/.local/bin/bat
	prv_cmd="bat --color always --style=auto {} 2>/dev/null || cat {}"

	{
		# git diff --name-only --ignore-submodules "$(_gmaster)...HEAD" | grep . #||
		git log --no-merges --first-parent --name-only --pretty= "$(_gmaster)...HEAD" | grep .
		git ls-files --full-name # . is implicit
	} |
		prepend "$(_get_repo_root)"/ |
		largs realpath --relative-to=. 2> /dev/null |
		sort -u |
		largs ls -1t 2> /dev/null |
		head -n50 |
		# height=~X% is not suitable because preview is usually longer
		# than input rows, and preview must always be shown to a reasonable
		# extent
		fzf -m --prompt="$(_git_current_branch): " \
			--height=50% --reverse --preview-window='right,50%,border' \
			--preview="$prv_cmd" |
		xargs nvim -p
}       # }}}
gdm() { # {{{
	: diff against master, like in a PR

	# caveat: due to git internals, it is not trivial to produce a diff
	# that is both 'cumulative' and completely excludes merges.
	#
	# https://stackoverflow.com/q/25403705
	#
	# this gets reasonably close, but if a file was changed in the current
	# branch as well as in a merge, both changes will be shown. for the
	# purpose of fast diffing (i.e. without network), this is usually fine.

	span="$(_gmaster)...HEAD"
	root=$(_get_repo_root)
	git log --diff-filter=d --no-merges --first-parent --name-only --oneline --pretty= "$span" |
		sort -u |
		# HACK: --diff-filter excludes files deleted by us, but does
		# not exclude files deleted during a merge
		while read -r f; do
			[[ -f "$root/$f" ]] && echo "$root/$f"
		done |
		# TODO: xargs: git: terminated by signal 13
		xargs git diff "$span" 2> /dev/null

	# https://gitlab.com/gitlab-org/cli/-/issues/7704

} # }}}

git_log() {
	: browse git log, showing each commit\'s diff in fzf preview
	_git_log_fzf "$@" | awk '{print $1}' | xargs git show
}

gxx() {
	: show commits whose changes contain a pattern
	# TODO: git show --color=always breaks grepdiff?
	prv_cmd="echo {} | cut -f1 | xargs git show -U1 | grepdiff \"$1\" --output-matching=hunk"
	git log --branches --format="%h%x09%S%x09%s" --pickaxe-regex -S "$1" | # WARN: slow with large histories
		fzf -m --preview="$prv_cmd" --preview-window='right,60%,border'
	# |     # --ansi
	# 	cut -f1 |
	# 	xargs git show
}

gcoup() {
	: for a given file, show which files changed together
	# https://adamtornhill.com/articles/crimescene/codeascrimescene.htm
	git log --pretty=%h "$1" |
		xargs git show --name-only --pretty= |
		sort |
		uniq -c |
		sort -n
}

clocd() {
	git log --until="$(date -I --date="$1")" -n1 --oneline |
		awk '{print $1}' |
		xargs -I{} cloc --diff {} HEAD
}

# gsdel() {
# 	: show last state of a deleted file
# 	# https://stackoverflow.com/a/19727752
# 	f=$1
# 	git show "$(git rev-list --max-count=1 --all -- "$f")^:$f"
# }

# git diff blame
# inherently, this means git diff must operate on a time range that spans more
# than commits, typically a (big) diff of a PR. by extension, this means that
# git diff blame is only useful when multiple authors have worked on the same
# PR, which tends to not happen very often IME.
# https://gist.github.com/maxrothman/d27bbc36f7c150924de6c6e54965de4d py
# https://github.com/eantoranz/difflame py
# https://github.com/dmnd/git-diff-blame pl

# GitBlameOpenFileURL
# $url/-/blob/$branch/$path

# }}}
# git staging -- functions that modify files or the index {{{
#
# TODO: most of these would be more convenient if done in vim

commit_or_discard() {
	: returns 0 if committed

	# TODO: fzf better
	committed=1
	while read -r f; do
		[[ -f $f ]] || continue
		if
			git commit -v --untracked-files=no "$f"
		then
			committed=0
		else
			git checkout -- "$f"
		fi
	done < /dev/stdin

	return "$committed"
}

gA() {
	: un-add, unstage
	# i usually want restore more often (?)
	set -x
	git restore --staged "$@" \
		2> /dev/null || # committed; without --staged, changes are discarded!
		git reset "$@"  # not committed yet
	set +x
}

gc() {
	: commit

	local cmd=(git commit -v --untracked-files=no)

	if [[ $# -gt 0 ]]; then

		# 1. specified files, but excluding untracked files
		# note: this loop commits renamed files, but does not commit
		# their old names

		# arr=()
		# for f in "$@"; do
		# 	[[ ! -f $f ]] && continue
		# 	realpath "$f" | xargs git ls-files | grep -q . && arr+=("$f")
		# done
		# git commit -v "${arr[@]}"

		for f in "$@"; do
			[[ ! -f $f ]] && continue
			realpath "$f" |
				xargs git ls-files |
				grep -q . && echo "$f"
		done |
			largs "${cmd[@]}"

	# note: git commit -av stages -all- changes in the entire repo. this is
	# almost never what i want

	elif
		rd=$(git diff --diff-filter=RD --name-only --staged | grep .)
	then
		"${cmd[@]}"

	elif
		# 2. file(s) that have been renamed/deleted
		# this behaviour may not be desirable when modified files
		# should also be included in the commit
		# TODO: also check --staged
		rd=$(git diff --diff-filter=RD --name-only | grep .)
	then
		echo "$rd" |
			prepend "$(_get_repo_root)/" |
			xargs "${cmd[@]}"

	elif
		# 3. all staged changes
		# [git diff] "exits with 1 if there were differences"
		! git diff --staged --diff-filter=AMD --quiet
	then
		: committing staged changes
		"${cmd[@]}"

	else
		# 4. all files that have changed in the current dir
		git diff --name-only . |
			prepend "$(_get_repo_root)/" |
			grep -v .gitignore |
			xargs "${cmd[@]}"

	fi

}

gS() {
	: like gs+gl, for files to stage/commit

	# may be replaced by <leader>gS in vim

	# # porcelain v1 is -always- relative to repo root, which makes
	# # relativising to cwd needlessly tedious (this would probably involve
	# # splitting each line, prepending repo root to the latter part,
	# # relativising, and then rejoining!)
	# files=$(git status --porcelain)

	prv_cmd=$(
		cat <<- EOF
			echo {} | awk '{print \$NF}' | xargs git diff --color=always | grep . ||
			echo {} | awk '{print \$NF}' | xargs bat --color always --style=auto 2>/dev/null
		EOF
	)

	# by default, git status does not enter dirs containing only 1
	# (untracked) file
	sel=$(git status --porcelain=2 --untracked-files=all |
		# 1 .M N... 100644 100644 100644 <hash> <hash> package.json
		#   $2					       $NF
		# ? README.md
		#
		# $2 is more useful for tracked files (since it more closely maps to v1
		# labels), but for untracked files this duplicates the file path, so we
		# stick to $1
		#
		# https://git-scm.com/docs/git-status#_changed_tracked_entries
		#
		# HACK: i have no idea how to 'return' multiple columns inside
		# a ternary, so concat with a space as an ugly workaround
		awk '{print ($1=="?") ? $0 : $2" "$NF}' |
		fzf --multi --reverse --preview="$prv_cmd" --preview-window='right,60%,border' --ansi)
	# fzh --multi --preview="$prv_cmd" --preview-window='right,60%,border' --ansi)

	# add untracked files first
	echo "$sel" | grep -P '^\?' | awk '{print $NF}' | xargs git add
	echo "$sel" | awk '{print $NF}' | xargs git commit -v
}

gsq() {
	: squash last n commits, starting from a given commit -- rewrites history!
	# https://stackoverflow.com/a/5201642
	sha=$(_git_log_fzf | cut -d' ' -f1)
	# `git reset <sha>` brings us back to the commit -after- <sha>. this
	# means we need to select the commit before the 'target', which is
	# unintuitive. so we just go back 1 more commit with ~
	git reset --soft "$sha~"
	git commit --edit -m"$(git log --format=%B --reverse "HEAD..HEAD@{1}")"
	git push --force-with-lease origin "$(_git_current_branch)"
}

gcf() {
	: like gc, but squash the new commit with an earlier one

	# https://jordanelver.co.uk/blog/2020/06/04/fixing-commits-with-git-commit-fixup-and-git-rebase-autosquash/
	old_sha=$(_git_log_fzf . | cut -d' ' -f1)
	[[ -z $old_sha ]] && return

	# --fixup associates a new commit with an existing commit so that when
	# you do an interactive rebase, you don't have to re-order any commits
	# in order to squash them. And you don't have to change any commit
	# messages
	git commit -v --fixup "$old_sha" # "$new_sha"

	# with no arg, defaults to curr branch (NEVER use gmaster; to avoid
	# losing work, git rebase --abort immediately)
	# --autostash required to avoid 'unstaged changes present'
	git rebase --autosquash --autostash || gC
}

gapat() { # {{{
	: stage hunks matching some pattern

	for patt in "$@"; do
		# grepdiff is more reliable than git diff -S/-G
		# https://choly.ca/post/git-programmatic-staging/
		# https://blog.paddlefish.net/git-tip-stage-lines-matching-a-regular-expression/
		# https://old.reddit.com/r/git/comments/p1vltk
		git diff -U0 |
			grepdiff --output-matching=hunk -E "$patt" |
			# "By default, git apply expects that the patch being applied
			# is a unified diff with at least one line of context."
			git apply --cached --unidiff-zero
	done

	# # https://stackoverflow.com/a/52394658
	# git diff --unified=1 --pickaxe-regex -S "$1" |
	# 	grepdiff --output-matching=hunk --extended-regexp "$1" |
	# 	git apply --cached

	# see also:
	# http://www.philandstuff.com/2014/02/09/git-pickaxe.html
	# https://git-scm.com/docs/gitdiffcore#_diffcore_pickaxe_for_detecting_additiondeletion_of_specified_string

	git commit -v

	# # unstage hunks that were unnecessarily added
	# git reset -p
} # }}}

grev() {
	: revert single commit in isolation
	_git_log_fzf "$@" | awk '{print $1}' | xargs git revert
}

gRev() {
	: rollback entire index to a known good commit -- check ci first
	sha=$(_git_log_fzf "$@" | awk '{print $1}')
	git checkout -f "$sha" -- .
	git commit -av
}

gu() {
	if
		[[ $# -eq 0 ]] ||
			[[ $(_git_current_branch) == $(_gmaster) ]] && [[ $1 == . ]]
	then
		echo "cannot reset on master"
		return
	fi

	git diff "$@" | cat
	git checkout -- "$@"
	echo "undid ${#@} files" # TODO: if ., determine how many files changed?
}

guns() {
	: revert file to its state in a previous commit
	[[ $# -ne 1 ]] && return

	f=$1
	prv_cmd="echo {} | cut -d' ' -f1 | xargs -I{} git show --color=always {} $1"

	# _git_log_fzf "$1" |
	git log --oneline "$1" |
		fzf -m --preview="$prv_cmd" --preview-window='right,60%,border' --ansi |
		awk '{print $1}' |
		xargs -I{}git checkout {} -- "$f"

}

gpick() {
	: cherry pick commit from other branch
	[[ $# -ne 1 ]] && return
	prv_cmd="echo {} | cut -d' ' -f1 | xargs git show --color=always"
	sha=$(git log --branches --remotes --tags --oneline --decorate "$1" |
		fzf --preview="$prv_cmd" --preview-window='right,60%,border' --ansi |
		awk '{print $1}')
	[[ -n $sha ]] && git cherry-pick --edit "$sha"
}

# }}}
# git branch # {{{
gb() { # {{{
	: switch to new branch, or existing branch

	default_local_branch=$(_gmaster)
	current_local_branch=$(_git_current_branch)

	commit_unstaged_changes() {
		# it is common to be prevented from switching branches due to
		# the presence of uncommitted changes, which is highly
		# disruptive.
		#
		# preserving currently unstaged changes in the new branch is
		# just annoying, because these unstaged changes are usually
		# throwaway code that was never meant to be committed. but
		# --discard-changes is also unsafe, so ask for every file.

		# presumably, ' M	' can be safely ignored?
		# git diff-tree HEAD "$target"
		# git diff-index "$target"
		# git diff --numstat "$target"...HEAD

		git diff-index "$1" |
			grep -P '00000 [AM]	' |
			cut -f2 |
			commit_or_discard && git push
	}

	if [[ $# -eq 0 ]]; then
		if [[ $default_local_branch == "$current_local_branch" ]]; then
			echo "Already on $default_local_branch"
		else
			# func retval is not propagated to parent
			git checkout "$default_local_branch" || return 1
			timeout 30 git pull
		fi
	else

		target=$1

		# generally, new branches should target master. however, this
		# may not always be the case, so accept an optional 2nd arg to
		# specify target branch (should be current)

		# --conflict will cause conflict markers to appear in master.
		# this is never desired, so conflicts should be resolved in the
		# current branch (i.e. -before- the checkout)

		# existing remote branch > create local branch > existing local branch
		if
			! git branch | grep -qPx "[ *] $target" &&
				timeout 30 git pull &&
				git branch -r | grep -q "origin/$target"
		then
			# note: git hook stdout cannot be suppressed
			echo "Switching to remote branch $target"

			# TODO: --guess?
			git switch "$target" > /dev/null || return 1

		elif
			commit_unstaged_changes "$default_local_branch" #&&
			git switch --create "$target" "$default_local_branch" > /dev/null 2> /dev/null
		then
			# for some reason, newly created branches don't know
			# which repo to pull from
			git pull "$(_get_remote)" "$default_local_branch"

		else

			# plain git switch can fail, if 'files would be
			# overwritten by checkout'. with --conflict, switch
			# always succeeds, but may result in conflicts which
			# must be resolved in the new branch

			commit_unstaged_changes "$target"
			git switch "$target"

			# # alternatively, revert all unstaged changes, then
			# # switch. this is probably more fragile
			# git switch "$branch" 2>&1 |
			# 	grep '^\s' |
			# 	xargs git checkout --

		fi
	fi

	# check if (dev) branch is behind remote
	# rev-list probably wouldn't be useful if we don't fetch though
	# note: rev-list errors if branch has no remote yet
	if [[ "$(git rev-list --left-right --count \
		"origin/$target...HEAD" 2> /dev/null | cut -f1)" -gt 0 ]]; then
		git pull
	fi

} # }}}

_complete_gb() {
	f() {
		# shellcheck disable=SC2317
		git branch --list "$1*" 2> /dev/null |
			grep -Po '[a-z].+'
	}
	_base_completer f
}

complete -F _complete_gb gb

git_branch() {
	: switch to existing branch, aliased to b
	# https://stackoverflow.com/a/1441062
	# --pretty=format:'%h%x09%an%x09%ad%x09%s' # no color

	_in_git_repo || return
	if [[ $(git branch | wc -l) -eq 1 ]]; then
		echo "No other branches; create one with gb <branch>"
		return
	fi

	prv_cmd=$(
		cat <<- EOF
			echo {} | sed -r 's/^[ *]+/$(_gmaster)../' | xargs git log --oneline --color=always | grep . ||
				git log --oneline  --color=always {}
		EOF
	)
	branch=$(git branch --sort=-committerdate |
		fzf --preview="$prv_cmd" --preview-window='right,80%,border' --ansi |
		sed -r 's/^[ *]+//')
	[[ -z $branch ]] && return
	gb "$branch"

}

gbd() {
	: prune local branches that no longer exist on remote -- unstaged changes will be lost!
	# https://stackoverflow.com/a/46192689
	git branch -vv |
		grep ': gone]' |
		grep -v "\*" |
		awk '{ print $1; }' |
		xargs -r git branch -D
}

# }}}
# git remote -- functions that involve remote repository {{{

_gssh() { # {{{
	: init github ssh key
	# https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent#generating-a-new-ssh-key
	#
	# note: this key must still be added to github!
	# https://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account#adding-a-new-ssh-key-to-your-account

	# password not strictly necessary
	ssh-keygen -t ed25519 -C hejops1@gmail.com -f "$HOME/.ssh/github_$(date -I)"
	ssh -T git@github.com 2>&1 | grep -q success && echo ok

} # }}}

gmm() {
	: merge master into dev branch
	[[ $(_git_current_branch) == $(_gmaster) ]] && return
	# https://stackoverflow.com/a/20103414
	git fetch origin
	# TODO: for forks, need to sync fork (in gh), then git pull
	git merge "origin/$(_gmaster)"
}

g,() {
	git pull && return
	git diff --name-only "$(_gmaster)..origin/$(_gmaster)" | commit_or_discard
	git pull && git push
}

gcon() { # {{{
	# https://nitaym.github.io/ourstheirs/

	: resolve conflicts, if any, and merge

	_git_has_conflicts() {
		rg -q --hidden '^[<=>]{7}'
		return $?
	}

	_git_get_conflicts() {
		# submodule conflicts don't really need to be resolved?
		git status --porcelain --ignore-submodules=all |
			grep -P '^([A-Z])\1 ' |
			sort -u |
			cut -c3-
	}

	# git diff --name-only --diff-filter=U --relative

	if ! conflicts=$(_git_get_conflicts); then
		echo "No conflicts detected"
		return
	fi

	# all conflicts are due to lock files
	if ! <<< "$conflicts" grep -v yarn.lock; then
		<<< "$conflicts" cut -c3- |
			xargs dirname |
			while read -r d; do
				pushd "$d" || return
				yarn install || return
				git add yarn.lock
				popd || return
			done
		_git_has_conflicts && return
		git commit -v
		return
	fi

	# in case of submodule conflict:
	# cd $submodule
	# gu .
	# git merge $hash (git should tell you which hash -- how to script?)
	# git add $submodule
	# git commit

	while _git_has_conflicts; do
		if [[ -f .abort ]]; then
			git merge --abort
			return
		fi
		echo "Unresolved conflicts remaining!"
		_git_get_conflicts | xargs nvim -p
	done

	_git_get_conflicts | xargs git add
	git commit -v
}        # }}}
gnew() { # {{{
	: push to newly created remote

	if _get_remote; then
		return

	elif [[ ! -d .git ]]; then
		git init
		return

	elif
		! git log > /dev/null 2> /dev/null &&
			! git status --porcelain | grep -Fv '??'
	then
		echo 'no commits made yet'
		return

	else
		# WARN: this may not be desired
		git commit -m "initial commit"
	fi

	git branch -M master # don't call _gmaster!
	xdg-open https://github.com/new &
	read -rp 'Repo name (not URL!): ' repo

	# https://kbroman.org/github_tutorial/pages/init.html
	git remote add origin "https://github.com/hejops/$repo"
	git push -u origin master
	git status
	git remote set-head origin --auto

} # }}}

# grbr() {
# 	: rebase to remote, discarding all local changes that conflict with remote
# 	# use case:
# 	# - our branch was started at the same time as another branch
# 	# - rewriting is simpler than resolving conflicts
# 	# - the other branch is much larger
# 	# - the other branch has been merged to master
# 	cr
# 	# first preserve files that were only added to in our branch
# 	# (this is a looser definition than just 'new files')
# 	git diff --numstat master...HEAD |
# 		grep -P '^\d+\t0\t' |
# 		cut -f3 |
# 		xargs git diff master...HEAD > tmp.diff
# 	# equivalent to `git rebase origin/master; git rebase --skip (repeatedly)`
# 	git rebase --strategy-option=theirs "origin/$(_gmaster)"
# 	git apply tmp.diff
# 	# git push -f
# }

# }}}

# gitlab {{{

# json output requires v1.37 (apt is 1.36 smh)
# https://gitlab.com/gitlab-org/cli/-/commit/893f5c945a50cb8a6d674eb05923f87e46fa6150

# https://gitlab.xyz.com/-/user_settings/personal_access_tokens
# glab auth login

alias gld=gldiff
alias gmer='seq 1 2 | parallel -n1 glab mr list --output=json --assignee=@me --merged --per-page=9999 -p | jq .[] | jqt iid source_branch title | sort -n'

# apt 1.36
# snap 1.43/1.54, but cannot read config file (lol)

gldiff() {
	# note: to see diff of current branch, just use gdm
	if [[ $# -eq 0 ]]; then
		prv_cmd="echo {} | awk '{print \$NF}' | xargs -I{} git log --oneline origin/{}"
		n=$(glab mr list --output=json --reviewer=@me | #--not-draft |
			jq '.[:25][]' |
			jqt updated_at iid title assignee.username source_branch |
			sort -r |
			fzh -0 -1 --preview="$prv_cmd" |
			# fzf --preview="$prv_cmd" |
			awk '{print $2}')
		[[ -z $n ]] && return
	else
		n=$1
	fi

	glab mr diff "$n" | sed '/Subproject commit/d' | delta

}

gci() { watch -n 30 'glab ci list -P 10 | grep -P "^\(" | column -t'; }

gmrc() {
	: find recent mr that is most likely the predecessor of the current mr

	# current mr numstat
	curr=$(git diff --numstat master..HEAD |
		grep -Fvw -e 0 -e '=>' |
		sort -rn)

	# based on numstat of previous mrs, find max similarity (in terms of
	# files changed)
	git log --oneline --since="$(date -I --date='1 month ago')" |
		grep 'Merge branch' |
		cut -d' ' -f1 |
		head |
		while read -r sha; do

			x=$(git show --format= --numstat "$sha" |
				sort -rn |
				# cut -f3 | xargs grep |
				while read -r _ _ f; do <<< "$curr" grep "$f" || :; done |
				wc -l)

			echo "$x $sha"

		done |
		sort -rn |
		head -n1 |
		cut -d' ' -f2 |
		xargs git show |
		grep -Po '!\d+'
}

# }}}

# rust {{{

# alias sqp='cargo sqlx prepare --workspace; ga .sqlx; gc' # postgres only
# cargo +nightly udeps
alias cb="cargo build"
alias cbr='cargo build --release && cp target/release/$(basename $PWD) .'
alias cn="cargo new"
alias ct="cargo test"
alias cwr="cargo watch -x run" # web servers only

cw() { cargo watch -x check -x "test $1"; }

# }}}
# go {{{

# https://gist.githubusercontent.com/alexedwards/3b40775846535d0014ab1ff477e4a568/raw/15f15b499f626a6e3949c237d52a3e8aace1b05b/Makefile

alias gobe="go test -bench=. -run=^$ ./..." # run benchmarks only -- https://stackoverflow.com/a/16161605

gop() {
	# https://go.dev/blog/pprof
	# https://github.com/google/pprof/blob/a8630aee4ab/internal/driver/commands.go#L125
	go tool pprof -web -nodefraction=0.1 ./*.prof 2> /dev/null
}

gopk() {
	: move foo.go to foo/foo.go
	# parent must then import from foo; goimports should fix this?
	f=$1
	pkg=${f/.go/}
	[[ -d $pkg ]] && return
	mkdir "$pkg"
	sed -i -r "s/^package main/package $pkg/" "$f"
	mv "$f" "$pkg"
}

gon() {
	if (($# == 0)); then
		pkg=foo
		tmp
	else
		pkg=$1
	fi

	[[ -d $pkg ]] && return

	if [[ -f ./go.mod ]]; then
		mkdir "$pkg"
		echo -e "package $pkg\nfunc foo(){\n}" > "$pkg/$pkg.go"
		vim + "$pkg/$pkg.go"
	else
		mcd "$pkg"
		go mod init "$pkg"
		echo "$pkg" > .gitignore
		echo -e "func main(){\n}" > main.go
		go build # generate go.mod
		vim + main.go
	fi
}

gob() { # build and run
	name=$(< go.mod head -n1 | cut -d' ' -f2)
	go build && ./"$name" "$@"
}

# https://leg100.github.io/en/posts/building-bubbletea-programs/
gowr() { while :; do gob "$@" || break; done; } # in foreground, continously run app

gorep() {
	patt=$1
	repl=$2

	# # see matches
	# rg -IN "$patt" ./*.go
	# read -r -p 'press enter to preview changes'

	# preview changes
	# note: gofmt can only modify expressions, not func declarations!
	gofmt -r "$patt -> $repl" ./*.go | less
	read -r -p 'press enter to accept changes'

	# execute
	gofmt -r "$patt -> $repl" -w ./*.go
	# TODO: gapat
}

god() {
	: generate documentation for file
	# godoc is only for generating stdlib docs?
	# https://pkg.go.dev/golang.org/x/tools/cmd/godoc

	pushd "$(dirname "$1")" || return
	< "$(basename "$1")" grep -P '^(type|func)' |
		grep -Pow '[A-Z]\w+' |
		sort -u |
		xargs -n1 go doc 2> /dev/null |
		grep -Pv '^package'
	popd || :
}

# }}}
# js {{{

tsc() {
	local cmd
	cmd=$(ls ./node_modules/.bin/tsc || which tsc)
	"$cmd" --version
	"$cmd" "$@"
}

# https://stackoverflow.com/a/47948461
_js_pkg_ver() { < package.json jq -r "[.dependencies, .devDependencies] | add | .$1" | tr -d '^~'; }
_js_pkgs() { < package.json jq -r '[.dependencies, .devDependencies] | add | keys[]'; }

jimp() {
	rg -t ts -Io ' from "[^:/]+";$' |
		sort -u |
		cut -d'"' -f2 |
		while read -r pkg; do
			< package.json grep -Fq "\"$pkg\"" || echo "$pkg"
		done |
		xargs pnpm add
}

jx() {
	pkgmgr() {
		if [[ -f yarn.lock ]]; then
			echo yarn
		elif [[ -f $(_get_repo_root)/pnpm-lock.yaml ]]; then
			echo pnpm
		else
			echo npm
		fi

	}

	cmd=$(< package.json jq -r .scripts | grep : | fzh | cut -d'"' -f2)
	[[ -n $cmd ]] && "$(pkgmgr)" "$cmd"
}

jmake() {
	: convert scripts to Makefile

	keys=$(< package.json jq -r '.scripts | keys[]')

	cmds=$(echo "$keys" |
		while read -r cmd; do
			echo "${cmd//:/-}:" # make targets cannot contain :
			< package.json jq -r '.scripts."'"$cmd"'"' |
				sed 's/&& /\n/g; s/\"/"/g' |
				prepend '\t'
			echo
		done)

	cat << EOF | tee -a Makefile
.PHONY: $(<<< "$keys" tr : - | xargs)
$cmds
EOF
}

jup() {
	: upgrade npm package
	pkg=$(_js_pkgs | fzf)
	curr_ver=$(_js_pkg_ver "$pkg")
	target_ver=$(c "https://www.npmjs.com/package/$pkg?activeTab=versions" |
		grep -Po '\d+?\.\d+?\.\d+?</a></td><td class="downloads">[0-9,]+' |
		sed -r 's|</a></td><td class="downloads">|\t|' |
		sort -rV |
		sed "/^$curr_ver/,\$d; /\t0$/d" | # filter to versions newer than current
		sort -k2n |                       # sort by downloads
		fzf --tac --prompt="$pkg (current: $curr_ver)" |
		cut -f1)
	# npm install (update?) / yarn upgrade
	echo yarn upgrade "$pkg@^$target_ver"
}

# pnpm depcheck --ignore-bin-package --json |
# 	jq .devDependencies[] |
# 	xargs pnpm remove

# }}}
# c {{{

x() {
	\ls ./*.c 2> /dev/null || return
	n=$(basename "$(realpath .)")
	gcc -o "$n" ./*.c && "./$n"
}

mch() {
	# f=$1

	: [re]generate header files
	# TODO: should be vim autocmd?
	for f in *.c; do
		[[ $f == main.c ]] && continue

		h="${f/.c/.h}"
		if [[ -f $h ]]; then
			# for merge to work, fn decls must all be placed at the
			# bottom of the .h file. includes, macros, structs
			# should be placed at the top. (is there a recommended
			# order?)
			{
				< "$h" grep -Pv '\);$' # discard existing fn decls
				cproto "$f" | sed 1d   # cproto only generates fn decls
			} | sponge "$h"
		else
			cproto "$f" > "$h"
		fi
	done
}

# }}}
# sql {{{

if [[ -n $POSTGRES_URL ]]; then
	alias psql='psql $POSTGRES_URL'
fi

sq() {
	: sq file.sql sql-command
	{
		if [[ -f $1-wal ]]; then
			cp "$1" tmp.db > /dev/null
			echo "$2" | sqlite3 tmp.db
		elif [[ -f $1 ]]; then
			echo "$2" | sqlite3 "$1"
		fi
	} | jq '.[]'
}

psqlj() {
	: convert psql output to jq
	# useful for times when it is easier to write jq than sql
	# https://www.pgcasts.com/episodes/generating-json-from-sql
	psql -c "select row_to_json(t) from ($1) t" |
		grep -Po '\{.+' |
		jq
}

# }}}
# jq {{{

alias jqc="jq -c" # basically just colors output

jqk() {
	: https://gist.github.com/pedroxs/f0ee8c515eea0dbce2e23eea7c048e10#file-jq-filters-sh-L2
	jq < /dev/stdin -r '.. | objects | with_entries(select(.key | contains("'"$1"'"))) | select(. != {}) | .'"$1"
}

jqt() {
	: select jq fields from a flat sequence of objects and format as tsv with alignment
	fields=()
	for x in "$@"; do
		fields+=(".$x")
	done
	query="$(ajoin "${fields[@]}")" # .foo,.bar,.baz

	# query="[$(echo "$@" | sjoin ,)]"

	# note: jq knows how to if read from stdin if no file passed
	{
		echo "${fields[@]}" | tr ' ' '\t'

		# this is the 'pure' way to do it (select and format are 2 different steps)
		# < /dev/stdin jq "[$query]" |
		# 	jq -r 'map(tostring) | @tsv'

		< /dev/stdin jq -r "[$query] | @tsv"
	} | colt

}

# }}}

# docker {{{

alias dolf='docker logs --tail=1 -f'

dps() {
	# # docker ps adds too much padding, and cannot truncate long values
	# docker ps -a --format "table {{.Names}}\t{{.State}}\t{{.Status}}\t{{.ID}}\t{{.RunningFor}}" |
	# 	sort

	docker ps -a --format=json |
		# note: ID is usually just visual noise, but placing it any
		# later in the seq will make it hard to extract (with cut/awk)
		jqt 'Names[0:50]' State ID Status RunningFor |
		sort |
		colt
}

docl() {
	docker system df || return
	docker system prune --all
	docker volume ls -f dangling=true -q | xargs docker volume rm # usually not important
}

dolc() {
	: clear logs of docker image without restart
	# https://stackoverflow.com/a/42510314
	[[ $# -eq 0 ]] && return
	name=$1
	json="$(docker inspect --format='{{.LogPath}}' "$name")"
	# [[ ! -f $json ]] && return
	sudo "$(command ls)" "$json" > /dev/null || return
	# doesn't work for go binary? file -is- cleared, but `docker logs` still produces old output
	: | sudo tee "$json"
	sudo du "$json"
	echo "cleared $name $json"

	# remove lines with null bytes
	# https://stackoverflow.com/a/77907885
	sudo grep -r -l -a -P '\x00' /var/lib/docker/containers/ |
		while read -r f; do
			sudo perl -pi -e 's/\x00//g' "$f"
		done

	# dolf "$name"
}

# alias dps='docker ps -a --format "table {{.Names}}\t{{.State}}\t{{.Status}}\t{{.ID}}\t{{.RunningFor}}" | sort'

dps() {
	# docker ps adds too much padding, and cannot truncate long values
	docker ps -a --format=json |
		# note: ID is usually just visual noise, but placing it any
		# later in the seq will make it hard to extract (with cut/awk)
		jqt 'Names[0:50]' State ID Status RunningFor Ports |
		sort |
		colt
}

doslow() {
	: list slowest steps in a docker log

	if [[ $# -eq 0 ]]; then
		# devc logs

		# prev=''
		grep -RPh '\d+/\d+\]' .config/Code/logs/*/window1/exthost/ms-vscode-remote.remote-containers |
			grep -P '\d{3,}\.\ds$' |
			cut -d= -f2- |
			sort -nr |
			sort -u |
			# dedup by step
			while read -r line; do
				step=$(<<< "$line" cut -d' ' -f2)
				if ! <<< "$prev" grep -Fq "$step"; then
					echo "$prev"
				fi
				prev=$line
			done |
			awk '{print $NF,$0}' |
			sort -nr |
			cut -f2- -d' '

		return
	fi

	if
		steps=$(< "$1" grep -P '^#\d+ DONE' |
			sort -Vu |
			awk '!a[$1]++') &&
			[[ -n $steps ]]
	then
		paste <(echo "$steps") \
			<(<<< "$steps" cut -d' ' -f1 |
				while read -r n; do
					< "$1" grep "$n" |
						tac |
						grep -Pm1 "$n \[" |
						cut -d' ' -f2-
				done)
	else
		echo all ok
	fi
}

dostop() { docker ps --all --quiet | xargs docker stop; }

donuke() {
	: stop and remove all containers
	mapfile -t containers < "$(docker ps --all --quiet)"
	docker stop "${containers[@]}"
	docker rm "${containers[@]}"
}

dodu() {
	: inspect size of image
	docker image history --no-trunc --format=json "$1" |
		jqt Size CreatedBy
}

# # list docker containers responsible for a given high-memory/cpu process
# top -bn1 |
# 	grep -m5 python |
# 	cut -d' ' -f1 |
# 	xargs -n1 pstree -as |
# 	grep moby |
# 	sort -u |
# 	grep -Po '[0-9a-f]{64}' |
# 	xargs -I{} sudo docker ps -f id={}

# }}}
# ssh {{{

# rsync ~/.config/readline/inputrc "$remote:$HOME/.inputrc"
# ssh "$remote" 'touch ~/.hushlogin' # suppress annoying ubuntu login msg

# sget() {
# 	remote=$1
# 	if [[ -f $1 ]]; then
# 		rsync --no-relative --files-from="$1" "$remote:/" .
# 	else
# 		rsync --exclude=".*/" "$remote:$1" .
# 	fi
# }

# sget() { rsync --exclude=".*/" "$1:$2" .; }
# sput() { rsync --exclude=".*/" "$2" "$1:~/"; }

# https://gist.github.com/cmbaughman/6a2ae275e0c0f39f42d95a728e07f796
# https://www.redhat.com/sysadmin/ssh-automation-sshpass

# }}}
# files, navigation {{{

zd() { zip -jr "${1%/}" "${1%/}"; }                         # zip directory (flat); stripping trailing slash is important
zin() { < /dev/stdin zip --junk-paths --names-stdin "$1"; } # pipe files from stdin to zip

seconds_since() {
	case $1 in

	n | new | mtime) find "${2:-.}" -maxdepth 1 -type f -printf "%T+\t%p\n" |
		sort |
		cut -f2 ;;

	# https://unix.stackexchange.com/a/22448
	s | sz | size) find "${2:-.}" -type f -exec du -a {} + |
		sort -n ;;

	esac
}

mcd() {
	: mkdir any number of paths, cd to last
	# it is uncommon for >1 arg to be passed, so this is more for cd
	# [[ $# -eq 0 ]] && return
	local p
	for p in "$@"; do mkdir -p "$p" || :; done
	# shellcheck disable=SC2164
	[[ -d $p ]] && cd "$p"
}

if [[ -n $MU ]]; then
	: wrap rm in a python check to prevent accidental deletion of some dir
	rm() {
		# parsing arbitrary args with bash is nonsense

		if [[ $* == *"$MU"* ]]; then
			python3 -c "
import sys
if \"$MU\" in {x.rstrip('/') for x in sys.argv}:
    print('FATAL')
    raise Exception
" "$@"
		fi

		command rm -v "$@"
	}
fi

files() {
	: list files in use by a process
	pidof "$1" |
		tr ' ' , |
		xargs lsof -p 2> /dev/null |
		grep -Po '/[a-z].+' |
		sort -u |
		grep -P --color=never '^/(home|run)'
}

mi() {
	mediainfo --Output=JSON "$@" |
		jq '.[] | {x:.media.track[0].OverallBitRate, y: .media.track[1].Height//0|tonumber, z:.media."@ref"}' |
		jqt x y z |
		sort -rn |
		grep -v -e srt -e vtt

}

ffconcat() {
	# cat *mp4 > out.mp4 does not work
	# https://trac.ffmpeg.org/wiki/Concatenate#Automaticallygeneratingtheinputfile
	glob=$1
	# TODO: determine file ext
	ffmpeg -f concat -safe 0 -i <(find . -name "$glob" -printf "file '$PWD/%p'\n" | sort) -c copy output.mp4
}

# }}}
# stdout manipulation {{{

append() { < /dev/stdin awk "{print \$0 \"$1\"}"; }
desec() { < /dev/stdin sed -r 's/:[0-9]{2}\.[0-9]{8,}Z//'; } # for ease of filtering logs
largs() { < /dev/stdin xargs --delimiter='\n' "$@"; }        # split xargs by newline instead of space
line() { < /dev/stdin sed -n "${1}p"; }
ljoin() { < /dev/stdin tr '\n' , | sed 's/,$//'; } # lines to comma-delimited str
paren() { < /dev/stdin prepend '(' | append ')'; }
prepend() { < /dev/stdin awk "{print \"$1\" \$0}"; }
sum() { < /dev/stdin paste -sd+ | bc; }
surround() { < /dev/stdin awk "{print \"$1\" \$0 \"$1\"}"; }
tojson() { node --eval "console.log(JSON.stringify($(< /dev/stdin)))" | jq; }
urldec() { node --eval "console.log(decodeURIComponent(process.argv[1]))" "$1"; }
urlenc() { node --eval "console.log(encodeURIComponent(process.argv[1]))" "$1"; }

# highlight query, but output the entire file
# grep "$query\|$"

ajoin() {
	: join space-delimited array
	# ljoin takes lines (via stdin), this takes array (via arg)
	# https://stackoverflow.com/a/9429887

	input=("$@")
	IFS=, # cannot be inlined into echo
	echo "${input[*]}"
}

dehtml() {
	# https://stackoverflow.com/a/19878198
	< /dev/stdin sed -e 's/<br[^>]*>/\n/g; s/<[^>]*>//g' |
		# recode xml..utf8 |
		# https://stackoverflow.com/a/13161719
		perl -MHTML::Entities -pe 'decode_entities($_);'
}

plot() {
	: plot latency from json logs
	script=$(
		# https://unix.stackexchange.com/a/754698
		# https://superuser.com/a/108380
		cat <<- EOF
			show terminal;
			set ylabel 'ms';
			set xdata time;
			set timefmt '%Y-%m-%dT%H:%M';
			plot '-' using 1:(\$2/1000000)
		EOF
	)
	# echo "$script"
	< "$1" grep latency |
		grep -Fv -e null -e '={' | # remove invalid nested json
		# tail -n10000 |
		jqt time[0:19] latency |
		time gnuplot --persist -e "$script"
}

# }}}
# web {{{

upload() {
	: upload file to catbox.moe, copy link to clipboard

	# https://github.com/Allypost/bash-scripts/blob/fa4b1006a1c022484c3d48a05ec0ff1c94b9a541/catbox#L116
	# https://github.com/mananapr/dotfiles/blob/9dc9196224c2c84e4265e517dc36af1c79637eb7/bin/catbox
	# https://github.com/search?type=code&q=curl+catbox.moe+language%3AShell+fileupload

	[[ ! -f $1 ]] && return
	link=$(
		curl -s --form "reqtype=fileupload" \
			--form "fileToUpload=@$1" \
			https://catbox.moe/user/api.php #| tee /dev/null
	)

	echo -en "Uploaded to: \e[1m$link\n" # idk what that escape does
	echo -n "$link" | xclip -sel c
}

wifi() {
	: connect to wifi network without nmtui
	ssid=$(nmcli --terse device wifi list |
		fzf --reverse |
		cut -d: -f8 |
		xargs)
	nmcli --ask device wifi connect "$ssid" # password $password
}

getmail() {
	mail 2>&1 | grep 'No new mail.'
	[[ $(notmuch count tag:inbox and tag:unread and date:today) -eq 0 ]] && return
	exec neomutt
	# neomutt -z
}

get_cookie() {
	\cp ~/.mozilla/firefox/*default/cookies.sqlite tmp.db
	if <<< "$1" grep -q ' '; then
		sql="select value from moz_cookies where $1 order by id desc"
		sqlite3 -json tmp.db "$sql" 2> /dev/null | jq
	else
		sql="select value from moz_cookies where name = '$1' order by id desc limit 1"
		sqlite3 tmp.db "$sql" 2> /dev/null
	fi
	rm tmp.db > /dev/null
}

sunpos() {
	# azimuth 1.7 - 1.8(?)
	# sun enters window as low as 1.35
	{
		curl -sL https://raw.githubusercontent.com/mourner/suncalc/refs/heads/master/suncalc.js |
			sed -rn '$d; /easier/,$p'
		echo "console.log(JSON.stringify(SunCalc.getPosition(new Date(), $(curl -sL "https://ipinfo.io" | jq -r .loc))))"
	} | node
}

subs() {
	# https://www.azsubtitles.com/restful-api
	f=$(fzf)
	c "https://www.azsubtitles.com/api/search?q=${1// /+}" | # TODO: fname -> infer title
		jq -er '.Items[0] | .UID' |
		prepend 'https://www.azsubtitles.com/api/movie' |
		xargs curl -sL |
		# File can contain a list of episodes, but we usually just want the first element
		jq -er '.AllSubs[] | select(.Language.Title == "English") | .File[0].Url' |
		sort |
		# head -n1 |
		fzf -0 --preview="curl -sL --globoff {} | head -n50" |
		sed -r 's/ /%20/g' |            # url must be encoded
		xargs curl --globoff > "$f".srt # but also need globoff to ignore {}[]

	# # requires unzip
	# c 'https://subf2m.co/subtitles/parivaar' |
	# 	grep -Po "/subtitles/[^/]+/english/\d+" |
	# 	prepend https://subf2m.co |
	# 	append /download

}

inci() {
	inci.js "$1" |
		jq '.data.items[]' |
		jqt year title director[0]
}

# }}}

# seq 1 10 |
# 	while read -r i; do
# 		curl -sL "https://vimcolorschemes.com/i/new/b.dark/$( ((i > 1)) && echo "p.$i")" |
# 			grep -Po 'href="[^"]+' |
# 			tail -n20
# 	done |
# 	cut -d/ -f2- |
# 	sort -u |
# 	while read -r x; do
# 		< ~/.local/share/chezmoi/dot_config/nvim/lua/plugins.lua grep -Fq "$x" || echo "$x"
# 	done

# nvim --headless "+Lazy! clean" +qa ; vim foo.{sh,js,py,lua,ts}

fftabs() {
	# aur/mozlz4-bin
	mozlz4 -x ~/.mozilla/firefox/*default/sessionstore-backups/recovery.jsonlz4 |
		jq -r '.windows[0].tabs[].entries[-1].url' |
		grep ^http |
		sort -u
}

topa() {
	< ~/gripts/disq/queries/top_artists_by_avg_rating.sql sqlite3 -tabs \
		~/gripts/disq/collection2.db 2> /dev/null |
		sort -k2 -t$'\t' -k1 |
		colt
}

randalb() { # {{{
	# generate list of random albums rated >=3 amounting to 50 gb
	set -euo pipefail
	sql=$(
		# note: unlike select_random.sql, the ORDER BY random() is used
		# in the outer query
		cat <<- EOF
			WITH rand AS (
			    SELECT
			        albums.id,
			        albums.title
			    FROM albums
			    WHERE albums.rating >= 3
			)

			SELECT
			    group_concat(artists.name, ' ') AS artist,
			    rand.title AS album
			FROM
			    rand
			INNER JOIN albums_artists
			    ON rand.id = albums_artists.album_id
			INNER JOIN artists
			    ON albums_artists.artist_id = artists.id
			GROUP BY album
			ORDER BY random();
		EOF
	)

	# size=0
	((size = 0, max = 50 * 1024 ** 2)) # 50 gb
	db=~/disq/collection2.db
	dirs=()

	rows=$(sqlite3 -json "$db" "$sql" 2> /dev/null | jq -c .[])

	while read -r row; do

		# TODO: bash_rematch
		artist=$(<<< "$row" jq -r .artist | sed -r 's/ \([0-9]+\)$//')
		album=$(<<< "$row" jq -r .album)

		# double find: 1m40
		# try: 30s (3x)
		# lazy: 8s (4x)

		# d=$(find "$MU/$artist" -mindepth 1 -iname "$album*" |
		# 	grep . |
		# 	head -n1) || continue

		d=$({
			if [[ -d $MU/$artist ]]; then
				find "$MU/$artist" -mindepth 1 -iname "$album*"
			else
				find "$MU" -maxdepth 1 -iname "$artist" -print0 |
					xargs -0 -I{} find {} -mindepth 1 -iname "$album*"
			fi
		} |
			grep . |
			head -n1) || continue

		dirs+=("$d")
		((size += $(du -cs "$d" | tail -n1 | cut -f1)))
		((size >= max)) && break

	done <<< "$rows"

	printf "%s\n" "${dirs[@]}" | sort

} # }}}

lba() {
	# curl -sL --fail "https://letterboxd.com/hejops$url" > /dev/null && continue

	curl -sL 'https://letterboxd.com/ajax/activity-pagination/hejops/following/' |
		grep -P 'rated-(8|9|10)' |
		grep -Po '/film/[^/]+' |
		sort -u |
		while read -r x; do
			curl -sL --fail "https://letterboxd.com/hejops$x" > /dev/null && continue
			echo "https://letterboxd.com$x"
		done |
		fzf -m |
		xargs -n1 xdg-open
}

tsg() {
	token=$(get_cookie remember_user_token)

	pgs=$(curl -sL "https://app.thestorygraph.com/books-read/hejops" \
		-H "Cookie: remember_user_token=$token" |
		grep search-results-count |
		grep -Pom1 '\d+' |
		tail -n1)

	seq 1 $((pgs / 10)) |
		parallel -q -I{} curl -sL "https://app.thestorygraph.com/books-read/hejops?page={}" \
			-H "Cookie: remember_user_token=$token" |
		grep 'rounded-sm shadow-lg dark:shadow-darkerGrey/40' |
		# uniq |
		cut -d'"' -f2 |
		awk '{print $NF, $0}' |
		sort -u |
		awk '{$1="";print $0}' |
		sed -r 's/(.+) by (.+)/\2\t\1/'
}

imm() {
	notmuch show from:noreply@immobilienscout24.de |
		grep -Po 'Adresse: [^(]+' |
		sed -r 's/([a-z])([A-Z])/\1\t\2/' |
		sort -u |
		fzf |
		cut -f2 |
		xargs -I{} notmuch show "from:noreply@immobilienscout24.de and body:{}" |
		grep -Fm1 'Scout-ID' |
		awk '{print $NF}' |
		prepend https://www.immobilienscout24.de/expose/ |
		xargs xdg-open

}

# curl -sL 'https://www.geoguessr.com/api/v3/users/6118c9f48db3190001c6d471' | jq
# curl -sL 'https://www.geoguessr.com/api/v3/users/6118c9f48db3190001c6d471/stats' | jq
# curl -sL 'https://www.geoguessr.com/api/v4/ranked-system/best/6118c9f48db3190001c6d471' | jq
# curl -sL 'https://www.geoguessr.com/api/v4/ranked-system/progress/6118c9f48db3190001c6d471' | jq

georank() {
	curl -sL 'https://www.geoguessr.com/api/v4/ranked-team-duels/me/teams/6097bf310e78f000019d9747' \
		--cookie "_ncfa=$(get_cookie _ncfa)" |
		jq -e '
		def cutoff: .bucket.promotionIndex;
		def current: .bucket.teams[] | select(.teamId == "6097bf310e78f000019d9747-6118c9f48db3190001c6d471") | .position;
		if .bucket then current<cutoff end
	' > /dev/null && echo ok
}

# < ~/geo/geo.csv shuf -n3 | cut -d, -f-2

# could replace xfer with this
# python3 -m http.server -d .

# echo ${files[@]} | entr -cr $cmd

kb() {
	if lsusb | grep -iq ergo; then
		# https://en.akkogear.com/faq/how-do-i-get-hold-tap-keys-by-via/
		# https://github.com/gabrielmscampos/ergodash-fw
		# https://github.com/AndrewKlement/ErgoDash_VIA/blob/main/ErgodashVia/keymap.json

		# pass env vars to dbus via systemd?
		# required for file picker; only once per boot (?)
		# https://bbs.archlinux.org/viewtopic.php?pid=2161602#p2161602
		source /etc/X11/xinit/xinitrc.d/50-systemd-user.sh

		ci https://usevia.app/design

	elif lsusb | grep -q Kinesis; then
		f=/run/media/"$USER"/ADV360/layouts/layout1.txt
		if [[ ! -f $f ]]; then
			echo 'connect first'
			inotifywait -e create "/run/media/$USER"
		fi
		vim "$f"

	# elif lsusb | grep -iq elora; then
	# 	exec /opt/vial-appimage/vial-appimage.AppImage

	fi
}

tvll() {
	: truncate vim lsp.log -- should be nvim autocmd, or session startup
	i=90
	while
		[[ $i -ge 60 ]] &&
			d=$(date --date="$i days ago" -I) &&
			! < ~/.local/state/nvim/lsp.log grep -q "$d"
	do
		((i--))
	done
	echo "$d"
	sed -i -r "1,/$d/d" ~/.local/state/nvim/lsp.log
}

_unused() {
	: list unused functions
	< ~/.bash_aliases grep -Po '^[a-z]\w+\(\)' |
		tr -d '()' |
		while read -r cmd; do
			< ~/.bash_history grep -wq "$cmd" && continue
			< ~/.bash_aliases grep -Pq "^$cmd\(\) \{.+; \}" && continue # ignore one-liners
			# len=$(< ~/.bash_aliases sed -rn "/^$cmd\(/,/^\}/p" | wc -l)
			len=$(type "$cmd" | wc -l) # more compact, 'neutralises' linebreaks
			echo "$len:$cmd"
		done |
		sort -n

	# # scripts explicitly called from cli
	# \ls ~/scripts | while read -r f; do
	# 	history | grep -wq "$f" && [ -x ~/scripts/"$f" ] && echo "$f"
	# done

	# # scripts accessed within the last 3 days (don't ask me why 3)
	# find ~/scripts -maxdepth 1 -type f -atime -3 -exec basename {} \; |
	# 	sort -u |
	# 	grep -v gitignore |
	# 	prepend "$HOME"/.local/bin/ #| largs chezmoi add -f

}

# rng() { for _ in "$(seq "${2:-1}")"; do echo $((1 + RANDOM % ${1:-100})); done; }
,pgrep() { \pgrep "$1" | xargs ps; } # ps for runtime
pk() { pgrep "$1" | fzf -m --tac | cut -d' ' -f1 | xargs kill -9; }
pkill1() { \pgrep "$1" | sed 1d | xargs kill; }                                            # kill all procs except 1st
rng() { while read -r _; do echo $((1 + RANDOM % ${1:-100})); done < "$(seq "${2:-1}")"; } # shellharden
ya() { mpv --video=no "ytdl://ytsearch10:'$*'"; }
yi() { yt-dlp --dump-single-json --skip-download "$1" 2> /dev/null | jq -r '.title, .description, .webpage_url, .channel_url'; }
yt() { mpv --force-window "ytdl://ytsearch10:'$*'"; }

ys() { # read youtube subs in less
	yt-dlp -j "$1" |
		jq . |
		grep '=vtt' |
		grep -v tlang |
		tail -n1 | # auto subs are listed first
		cut -d'"' -f4 |
		xargs curl -sL |
		dehtml |
		grep -v -- '-->' |
		grep -Pvx '\s*' |
		tr '\n' ' ' |
		fold --spaces |
		less
}

nico() {
	# set -x
	# TODO: investigate --headless mode
	: launch searches in nicotine
	[[ ! -f $1 ]] && return
	xdotool key super+8
	# ensure window is focused!
	i=0
	while read -r line; do
		[[ -z $line ]] && break

		# slsk blocks all searches after a while
		# TODO: where are logs written to?
		((i++))
		[[ $i -ge 68 ]] && break

		echo "$i: $line"
		echo "$line" | xclip -sel c
		xdotool key ctrl+2 F6 ctrl+v enter
		sleep 3
	done < "$1"

	notify-send 'done'
}

epk() {
	: fix malformed epubs

	# according to the spec, `mimetype` must be the first listed file. note
	# that malformed epubs are still readable in zathura, so this is mainly
	# to prevent yazi from treatting malformed epubs as zip.

	for f in *.epub; do
		{
			# tmpdir=tmp
			# tmpname=foo
			tmpdir="$f.tmp"
			tmpname="$f.tmpf"

			# https://github.com/ikrukov/epub/blob/c663821de66d57b3d138dc9125251f40ea755c2c/script/pack_epub#L25
			# https://www.mobileread.com/forums/showthread.php?t=299415

			unzip -l "$f" > /dev/null 2> /dev/null || return                 # corrupt (unreadable)
			file --mime-type "$f" | grep -q 'application/epub+zip' && return # ok

			unzip "$f" -d "$tmpdir"
			cd "$tmpdir" || :
			echo 'application/epub+zip' > mimetype
			zip -X -0 --quiet "$tmpname" mimetype
			zip -X -9 --quiet --no-dir-entries --recurse-paths "$tmpname" META-INF OEBPS
			cd ..
			\mv "$tmpdir/$tmpname.zip" "$f"
			\rm -rf "$tmpdir"
			echo "fixed $f"
		} #&
	done

	# wait
}

gev() {
	: get env var
	find . -type f -name '.*env' -print0 |
		# probably better to force upper, but whatever
		\xargs -0 grep -Pi "$1" |
		awk -F: '!a[$2]++' |
		sed -r 's/:/	/' |
		colt
}

scan() {
	cd ~/scores || return
	f=$1
	n=1
	echo 'type x to exit'
	res=600
	while true; do
		echo -n "$n: "
		read -r ans < /dev/tty
		[[ $ans == x ]] && break
		# 600: 30 sec, 4.4 MB
		# 2400: 8 min, 48 MB
		scanimage --format=pdf --progress --resolution="$res" \
			--output-file "$f-$n-$res.pdf"
		((n++))
	done
	pdfunite "$(find . -name "$f-*" | sort -V)" "$f.pdf"
	rm -I "$f"-*
}
